---
title: 集群调优
categories:
- 大数据建模
---
调优最重要的就是知道问题在哪里，所以在执行hive时将日志设置为debug，可以看到更多信息。
```
hive -hiveconf hive.root.logger=DEBUG,console
```

# 一、HDFS调优
## 1.1 core-default.xml：
- hadoop.tmp.dir：
默认值： /tmp
说明： 尽量手动配置这个选项，否则的话都默认存在了里系统的默认临时文件/tmp里。并且手动配置的时候，如果服务器是多磁盘的，每个磁盘都设置一个临时文件目录，这样便于mapreduce或者hdfs等使用的时候提高磁盘IO效率。

- fs.trash.interval：
默认值： 0
说明： 这个是开启hdfs文件删除自动转移到垃圾箱的选项，值为垃圾箱文件清除时间。一般开启这个会比较好，以防错误删除重要文件。单位是分钟。

- io.file.buffer.size：
默认值：4096
说明：SequenceFiles在读写中可以使用的缓存大小，可减少 I/O 次数。在大型的 Hadoop cluster，建议可设定为 65536 到 131072。

- io.compression.codecs
说明：设置hadoop支持的压缩模式，使用Lzop才能进行切片，但是需要创建索引，不创建索引不会进行切片效率低下。需要使用代码为文件创建Lzo切片索引。

## 1.2 hdfs-default.xml：
- dfs.blocksize：
默认值：134217728
说明： 这个就是hdfs里一个文件块的大小了，CDH5中默认128M。太大的话会有较少map同时计算，太小的话也浪费可用map个数资源，而且文件太小namenode就浪费内存多。根据需要进行设置。

- dfs.namenode.handler.count：
默认值：10
说明：设定 namenode server threads 的数量，这些 threads 會用 RPC 跟其他的 datanodes 沟通。当 datanodes 数量太多时会发現很容易出現 RPC timeout，解决方法是提升网络速度或提高这个值，但要注意的是 thread 数量多也表示 namenode 消耗的内存也随着增加。
推荐值：namenode需要接受datanode心跳、客户端请求等，根据公式20*math.log(9)，计算9个节点的集群，nn的线程池大小设置为45个线程最好。


<br>
## 1.3 其他
cloudera manager监控页面HDFS大部分机器出现类似告警"存在隐患 : DataNode 有 xxxxxx 个块。 警告阈值：500,000 块。"，cm给出的建议：
   >这是 DataNode 运行状况检查，用于检查 DataNode 是否含有过多的块。如果 DataNode 含有过多的块，可能影响 DataNode 的性能。具有大量块数的 DataNode 将需要较大的 java 堆并且可能遇到较长时间的垃圾回收暂停。另外，大量块数可能表明存在许多小文件。不会为处理许多小文件而优化 HDFS，跨许多小文件进行操作时处理时间可能受影响。
如果只有部分 DataNode 有大量块，运行 HDFS 重新平衡命令可以通过移动 DataNode 之间的数据解决该问题。如果 HDFS 重新平衡命令将群集报告为平衡，没有修复块不平衡，则问题与存在的许多小文件有关。参阅 HDFS 文档了解解决该问题的最佳做法。如果许多小文件不是您的使用案例的关注点，则考虑禁用该运行状况测试。如果所有 DataNode 都有大量块数且该问题与小文件无关，则应添加更多 DataNode。

   **思路：**确认hdfs集群中是否确实存在大量小文件，根据实际需要对小文件进行合并，对于历史数据及时清理归档。

   **获取fsimage信息:**`hdfs dfsadmin -fetchImage  /opt/data`
   **格式化fsimage为可读文本:**`hdfs oiv -i /data/fsimage_0000000000930647029 -o /data/fsimage.csv -p Delimited  -delimiter ","`
   **建立存储fsimage的表:**
   ```
   CREATE TABLE `fsimage_info_csv`(
     `path` string, 
     `replication` int, 
     `modificationtime` string, 
     `accesstime` string, 
     `preferredblocksize` bigint, 
     `blockscount` int, 
     `filesize` bigint, 
     `nsquota` string, 
     `dsquota` string, 
     `permission` string, 
     `username` string, 
     `groupname` string)
   ROW FORMAT SERDE 
     'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe' 
   WITH SERDEPROPERTIES ( 
     'field.delim'=',', 
     'serialization.format'=',') 
   STORED AS INPUTFORMAT 
     'org.apache.hadoop.mapred.TextInputFormat' 
   OUTPUTFORMAT 
     'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
   LOCATION
       'hdfs://nameservice1/user/hive/warehouse/fsimage_info_csv';
   ```
   **加载数据到hive表:**`hdfs dfs -put /data/fsimage.csv /user/hive/warehouse/fsimage_info_csv/`
   **查看文件大小分布:**`hdfs oiv -p FileDistribution  -i fsimage_0000000000930647029 -o fs_distribution`
```
$ cat fs_distribution 
Processed 0 inodes.
Processed 1048576 inodes.
Processed 2097152 inodes.
Processed 3145728 inodes.
Size    NumFiles
0       209746
2097152 2360944
4194304 184952
6291456 121774
8388608 37136
// 省略中间部分
10485760        36906
12582912        51616
14680064        19209
16777216        14617
18874368        7655
20971520        5625
23068672        26746
25165824        112429
27262976        10304
29360128        12315
31457280        11966
33554432        15739
35651584        10180
115425148928    1
totalFiles = 3472422
totalDirectories = 224875
totalBlocks = 3401315
totalSpace = 122170845300822
maxFileSize = 115423398874
```

**逐级目录统计文件数量:**
```
SELECT
    dir_path ,
    COUNT(*) AS small_file_num 
FROM
    (    SELECT
            relative_size,
            dir_path 
        FROM
            (    SELECT
                    (
                    CASE filesize < 4194304 
                        WHEN TRUE 
                        THEN 'small' 
                        ELSE 'large' 
                    END)  AS relative_size,
                    concat('/',split(PATH,'\/')[1], '/',split(PATH,'\/')[2], '/'
                    ,split(PATH,'\/')[3], '/',split(PATH,'\/')[4], '/', split(
                    PATH,'\/')[5]) AS dir_path 
                FROM
                    DEFAULT.fsimage_info_csv 
                WHERE
                    permission LIKE 'd%') t1
        WHERE
            relative_size='small') t2 
GROUP BY
    dir_path 
ORDER BY
    small_file_num
```
**相应数据脱敏后输出如下：**
```
/data/load/201905032130      1
//省略中间部分
/user/hive/warehouse/teset.db/table1  2244
/user/hive/warehouse/teset.db/table2  2244
/user/hive/warehouse/teset.db/table3  2244
/user/hive/warehouse/teset.db/table4  2246
/user/hive/warehouse/teset.db/table5  2246
/user/hive/warehouse/teset.db/table6  2248
/user/hive/warehouse/teset.db/table7  2508
/user/hive/warehouse/teset.db/table8  3427
Time taken: 53.929 seconds, Fetched: 32947 row(s)
```
**小文件处理:**
- 根据涉及目录，反向找到涉及程序，尝试优化避免小文件的产生
- 及时合并归档小文件
- 及时清理历史小文件

https://zhuanlan.zhihu.com/p/269530943

<br>
# 二、Yarn调优
![image.png](集群调优.assets