---
title: PaddlePaddle
categories:
- äººå·¥æ™ºèƒ½
---
# ä¸€ã€æ­å»º
[Windowsä¸‹çš„Condaå®‰è£…-ä½¿ç”¨æ–‡æ¡£-PaddlePaddleæ·±åº¦å­¦ä¹ å¹³å°](https://www.paddlepaddle.org.cn/documentation/docs/zh/install/conda/windows-conda.html#anchor-0)

**å®‰è£…PaddleDectionå¼€å‘å¥—ä»¶**
ä¸‹è½½PaddleDectionåŒ…ï¼Œä¸‹è½½requirementä¸­çš„æ¨¡å— `pip install -r .equirements.txt`
>å¦‚æœcython_bboxå®‰è£…å¤±è´¥ï¼Œä½¿ç”¨å¦‚ä¸‹å‘½ä»¤å®‰è£…
`python -m pip install git+https://github.com/yanfengliu/cython_bbox.git`


# äºŒã€ä½¿ç”¨
## 2.1 å®˜æ–¹demo(è¯†åˆ«å›¾ç‰‡ä¸Šçš„æ•°å­—)
[10åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹é£æ¡¨-ä½¿ç”¨æ–‡æ¡£-PaddlePaddleæ·±åº¦å­¦ä¹ å¹³å°](https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/beginner/quick_start_cn.html)

```py
import paddle
import numpy as np
from paddle.vision.transforms import Normalize

transform = Normalize(mean=[127.5], std=[127.5], data_format='CHW')
# ä¸‹è½½æ•°æ®é›†å¹¶åˆå§‹åŒ– DataSet
train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)
test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)

# æ¨¡å‹ç»„ç½‘å¹¶åˆå§‹åŒ–ç½‘ç»œ
lenet = paddle.vision.models.LeNet(num_classes=10)
model = paddle.Model(lenet)

# æ¨¡å‹è®­ç»ƒçš„é…ç½®å‡†å¤‡ï¼Œå‡†å¤‡æŸå¤±å‡½æ•°ï¼Œä¼˜åŒ–å™¨å’Œè¯„ä»·æŒ‡æ ‡
model.prepare(paddle.optimizer.Adam(parameters=model.parameters()),
              paddle.nn.CrossEntropyLoss(),
              paddle.metric.Accuracy())

# æ¨¡å‹è®­ç»ƒ
model.fit(train_dataset, epochs=5, batch_size=64, verbose=1)
# æ¨¡å‹è¯„ä¼°
model.evaluate(test_dataset, batch_size=64, verbose=1)

# ä¿å­˜æ¨¡å‹
model.save('./output/mnist')
# åŠ è½½æ¨¡å‹
model.load('output/mnist')

# ä»æµ‹è¯•é›†ä¸­å–å‡ºä¸€å¼ å›¾ç‰‡
img, label = test_dataset[0]
# å°†å›¾ç‰‡shapeä»1*28*28å˜ä¸º1*1*28*28ï¼Œå¢åŠ ä¸€ä¸ªbatchç»´åº¦ï¼Œä»¥åŒ¹é…æ¨¡å‹è¾“å…¥æ ¼å¼è¦æ±‚
img_batch = np.expand_dims(img.astype('float32'), axis=0)

# æ‰§è¡Œæ¨ç†å¹¶æ‰“å°ç»“æœï¼Œæ­¤å¤„predict_batchè¿”å›çš„æ˜¯ä¸€ä¸ªlistï¼Œå–å‡ºå…¶ä¸­æ•°æ®è·å¾—é¢„æµ‹ç»“æœ
out = model.predict_batch(img_batch)[0]
pred_label = out.argmax()
print('true label: {}, pred label: {}'.format(label[0], pred_label))
# å¯è§†åŒ–å›¾ç‰‡
from matplotlib import pyplot as plt
plt.imshow(img[0])
plt.show()
```

<br>
## 2.2 æ±‚è§£çº¿æ€§æ¨¡å‹
```
# ç°åœ¨é¢ä¸´è¿™æ ·ä¸€ä¸ªä»»åŠ¡ï¼š
# ä¹˜åå‡ºç§Ÿè½¦ï¼Œèµ·æ­¥ä»·ä¸º10å…ƒï¼Œæ¯è¡Œé©¶1å…¬é‡Œï¼Œéœ€è¦åœ¨æ”¯ä»˜æ¯å…¬é‡Œ2å…ƒ
# å½“ä¸€ä¸ªä¹˜å®¢åå®Œå‡ºç§Ÿè½¦åï¼Œè½¦ä¸Šçš„è®¡ä»·å™¨éœ€è¦ç®—å‡ºæ¥è¯¥ä¹˜å®¢éœ€è¦æ”¯ä»˜çš„ä¹˜è½¦è´¹ç”¨

def calculate_fee(distance_travelled):
    return 10 + 2 * distance_travelled


for x in [1, 3, 5, 9, 10, 20]:
    print(calculate_fee(x))

# ç»“æœä¸º
# 12
# 16
# 20
# 28
# 30
# 50

# æ¥ä¸‹æ¥ï¼ŒæŠŠé—®é¢˜ç¨å¾®å˜æ¢ä¸€ä¸‹ï¼Œç°åœ¨çŸ¥é“ä¹˜å®¢æ¯æ¬¡å‡ºè¡Œçš„å…¬é‡Œæ•°å’Œæ”¯ä»˜çš„æ€»è´¹ç”¨
# éœ€è¦æ±‚è§£ä¹˜è½¦çš„èµ·æ­¥ä»·å’Œæ¯å…¬é‡Œçš„è´¹ç”¨
import paddle

x_data = paddle.to_tensor([[1.0], [3.0], [5.0], [9.0], [10.0], [20.0]])
y_data = paddle.to_tensor([[12.0], [16.0], [20.0], [28.0], [30.0], [50.0]])

linear = paddle.nn.Linear(in_features=1, out_features=1)
w_before_opt = linear.weight.numpy().item()
b_before_opt = linear.bias.numpy().item()
print(w_before_opt, b_before_opt)  # éšæœºåˆå§‹åŒ–çš„å€¼

mse_loss = paddle.nn.MSELoss()
sgd_optimizer = paddle.optimizer.SGD(learning_rate=0.001, parameters=linear.parameters())

total_epoch = 5000
for i in range(total_epoch):
    y_predict = linear(x_data)
    loss = mse_loss(y_predict, y_data)
    loss.backward()
    sgd_optimizer.step()
    sgd_optimizer.clear_gradients()

    if i % 1000 == 0:
        print(i, loss.numpy())

print("finish training, loss = {}".format(loss.numpy()))

w_after_opt = linear.weight.numpy().item()
b_after_opt = linear.bias.numpy().item()
print(w_after_opt, b_after_opt)  # æœ€ç»ˆçš„æ‹Ÿåˆå€¼
```

<br>
## 2.3 é¢„æµ‹æ³¢å£«é¡¿æˆ¿ä»·
```
import paddle
import numpy as np


# 1. å‡†å¤‡æ•°æ®
def load_data():
    ## 1.1 ä»æ–‡ä»¶å¯¼å…¥æ•°æ®
    datafile = '../dataset/housing.data'
    data = np.fromfile(datafile, sep=' ', dtype=np.float32)
    print(len(data))

    ## 1.2 æ•°æ®è½¬æ¢
    # æ¯æ¡æ•°æ®åŒ…æ‹¬14é¡¹ï¼Œå…¶ä¸­å‰é¢13é¡¹æ˜¯å½±å“å› ç´ ï¼Œç¬¬14é¡¹æ˜¯ç›¸åº”çš„æˆ¿å±‹ä»·æ ¼ä¸­ä½æ•°
    feature_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE',
                     'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']
    feature_num = len(feature_names)

    # å°†åŸå§‹æ•°æ®è¿›è¡Œreshapeï¼Œå˜æˆ[N, 14]å½¢çŠ¶
    data = data.reshape([data.shape[0] // feature_num, feature_num])

    # å°†åŸæ•°æ®æ‹†åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†
    # è¿™é‡Œä½¿ç”¨80%çš„æ•°æ®åšè®­ç»ƒï¼Œ20%çš„æ•°æ®åšæµ‹è¯•
    # æµ‹è¯•é›†å’Œè®­ç»ƒé›†å¿…é¡»æ˜¯æ²¡æœ‰äº¤é›†çš„
    ratio = 0.8
    offset = int(data.shape[0] * ratio)

    training_data = data[:offset]

    # è®¡ç®—trainæ•°æ®é›†çš„æœ€å¤§å€¼ï¼Œæœ€å°å€¼ï¼Œå¹³å‡å€¼
    maximums, minimums, avgs = training_data.max(axis=0), training_data.min(axis=0), training_data.sum(axis=0) / \
                               training_data.shape[0]

    # è®°å½•æ•°æ®çš„å½’ä¸€åŒ–å‚æ•°ï¼Œåœ¨é¢„æµ‹æ—¶å¯¹æ•°æ®åšå½’ä¸€åŒ–
    global max_values
    global min_values
    global avg_values
    max_values = maximums
    min_values = minimums
    avg_values = avgs

    # å¯¹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–å¤„ç†
    for i in range(feature_num):
        data[:, i] = (data[:, i] - avgs[i]) / (maximums[i] - minimums[i])

    ## 1.3 è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„åˆ’åˆ†
    training_data = data[:offset]
    test_data = data[offset:]
    return training_data, test_data


# 2. æ¨¡å‹ç»„ç½‘
class Regressor(paddle.nn.Layer):
    # selfä»£è¡¨ç±»çš„å®ä¾‹è‡ªèº«
    def __init__(self):
        super(Regressor, self).__init__()
        self.linear = paddle.nn.Linear(in_features=13, out_features=1)

    # ç½‘ç»œå‰å‘è®¡ç®—
    def forward(self, inputs):
        x = self.linear(inputs)
        return x


# å£°æ˜å®šä¹‰å¥½çš„çº¿æ€§å›å½’æ¨¡å‹
model = Regressor()

# 3. æ•°æ®è®­ç»ƒ
# å¼€å¯æ¨¡å‹è®­ç»ƒæ¨¡å¼
model.train()
# åŠ è½½æ•°æ®
training_data, test_data = load_data()

# å®šä¹‰ä¼˜åŒ–ç®—æ³•,ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™SGDï¼Œå­¦ä¹ ç‡è®¾ç½®ä¸º0.01
opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())

EPOCH_NUM = 10  # è®¾ç½®å¤–å±‚å¾ªç¯æ¬¡æ•°
BATCH_SIZE = 10  # è®¾ç½®batchå¤§å°

# å®šä¹‰å¤–å±‚å¾ªç¯
for epoch_id in range(EPOCH_NUM):
    # åœ¨æ¯è½®è¿­ä»£å¼€å§‹ä¹‹å‰ï¼Œå°†è®­ç»ƒæ•°æ®çš„é¡ºåºéšæœºçš„æ‰“ä¹±
    np.random.shuffle(training_data)
    # å°†è®­ç»ƒæ•°æ®è¿›è¡Œæ‹†åˆ†ï¼Œæ¯ä¸ªbatchåŒ…å«10æ¡æ•°æ®
    mini_batches = [training_data[k:k + BATCH_SIZE] for k in range(0, len(training_data), BATCH_SIZE)]
    # å®šä¹‰å†…å±‚å¾ªç¯
    for iter_id, mini_batch in enumerate(mini_batches):
        x = np.array(mini_batch[:, :-1])  # è·å¾—å½“å‰æ‰¹æ¬¡è®­ç»ƒæ•°æ®
        y = np.array(mini_batch[:, -1:])  # è·å¾—å½“å‰æ‰¹æ¬¡è®­ç»ƒæ ‡ç­¾ï¼ˆçœŸå®æˆ¿ä»·ï¼‰
        # å°†numpyæ•°æ®è½¬ä¸ºpaddle tensorå½¢å¼
        house_features = paddle.to_tensor(x)
        prices = paddle.to_tensor(y)

        # å‰å‘è®¡ç®—
        predicts = model(house_features)

        # è®¡ç®—æŸå¤±
        loss = paddle.nn.functional.square_error_cost(input=predicts, label=prices)
        mse = paddle.mean(loss)
        if iter_id % 20 == 0:
            print("epoch: {}, iter: {}, loss is: {}".format(epoch_id, iter_id, mse.numpy()))

        # åå‘ä¼ æ’­
        mse.backward()
        # æœ€å°åŒ–lossï¼Œæ›´æ–°å‚æ•°
        opt.step()
        # æ¸…é™¤æ¢¯åº¦
        opt.clear_grad()

# 4. ä¿å­˜æ¨¡å‹å‚æ•°åˆ°å­—å…¸ä¸­ï¼Œå°†å­—å…¸è½ç›˜ä¸ºLR_model.pdparamsæ–‡ä»¶
paddle.save(model.state_dict(), 'LR_model.pdparams')

# è¯»å–æ¨¡å‹ï¼Œå‚æ•°ä¸ºä¿å­˜æ¨¡å‹å‚æ•°çš„æ–‡ä»¶åœ°å€
model_dict = paddle.load('LR_model.pdparams')
model.load_dict(model_dict)

# å°†è¯¥æ¨¡å‹åŠå…¶æ‰€æœ‰å­å±‚è®¾ç½®ä¸ºé¢„æµ‹æ¨¡å¼
model.eval()


# 5. é¢„æµ‹æ•°æ®
def load_one_example():
    # ä»ä¸Šè¾¹å·²åŠ è½½çš„æµ‹è¯•é›†ä¸­ï¼Œéšæœºé€‰æ‹©ä¸€æ¡ä½œä¸ºæµ‹è¯•æ•°æ®
    idx = np.random.randint(0, test_data.shape[0])
    idx = -10
    one_data, label = test_data[idx, :-1], test_data[idx, -1]
    # ä¿®æ”¹è¯¥æ¡æ•°æ®shapeä¸º[1,13]
    one_data = one_data.reshape([1, -1])

    return one_data, label


# å°†æ•°æ®è½¬ä¸ºåŠ¨æ€å›¾çš„variableæ ¼å¼
one_data, label = load_one_example()
one_data = paddle.to_tensor(one_data)
predict = model(one_data)

# å¯¹ç»“æœåšåå½’ä¸€åŒ–å¤„ç†
predict = predict * (max_values[-1] - min_values[-1]) + avg_values[-1]
# å¯¹labelæ•°æ®åšåå½’ä¸€åŒ–å¤„ç†
label = label * (max_values[-1] - min_values[-1]) + avg_values[-1]

print("Inference result is {}, the corresponding label is {}".format(predict.numpy(), label))

# æ‰“å°ç»“æœä¸º
epoch: 0, iter: 0, loss is: [0.2190369]
epoch: 0, iter: 20, loss is: [0.26175416]
epoch: 0, iter: 40, loss is: [0.18272282]
epoch: 1, iter: 0, loss is: [0.20169991]
epoch: 1, iter: 20, loss is: [0.25468302]
epoch: 1, iter: 40, loss is: [0.12643944]
epoch: 2, iter: 0, loss is: [0.07170647]
epoch: 2, iter: 20, loss is: [0.27606457]
epoch: 2, iter: 40, loss is: [0.0587504]
epoch: 3, iter: 0, loss is: [0.08177032]
epoch: 3, iter: 20, loss is: [0.17796104]
epoch: 3, iter: 40, loss is: [0.01438468]
epoch: 4, iter: 0, loss is: [0.14358227]
epoch: 4, iter: 20, loss is: [0.04590528]
epoch: 4, iter: 40, loss is: [0.11086401]
epoch: 5, iter: 0, loss is: [0.0784346]
epoch: 5, iter: 20, loss is: [0.06981862]
epoch: 5, iter: 40, loss is: [0.02968376]
epoch: 6, iter: 0, loss is: [0.05453171]
epoch: 6, iter: 20, loss is: [0.0677472]
epoch: 6, iter: 40, loss is: [0.00175112]
epoch: 7, iter: 0, loss is: [0.01291312]
epoch: 7, iter: 20, loss is: [0.06383369]
epoch: 7, iter: 40, loss is: [0.04227459]
epoch: 8, iter: 0, loss is: [0.01342294]
epoch: 8, iter: 20, loss is: [0.01199431]
epoch: 8, iter: 40, loss is: [0.03285793]
epoch: 9, iter: 0, loss is: [0.02604165]
epoch: 9, iter: 20, loss is: [0.037579]
epoch: 9, iter: 40, loss is: [0.01411492]
Inference result is [[19.120472]], the corresponding label is 19.700000762939453
```

<br>
## 2.4 é¢„æµ‹ç—…ç†æ€§è¿‘è§†
é€šè¿‡å¯¹è®­ç»ƒé›†è¿›è¡Œè®­ç»ƒå¾—åˆ°æ¨¡å‹å‚æ•°ã€‚è¿™é‡Œä½¿ç”¨è®­ç»ƒé›†è¿›è¡Œæµ‹è¯•ï¼Œæ‰€ä»¥å‡†ç¡®ç‡ä»…ä¾›å‚è€ƒã€‚
```
import paddle
import cv2
import numpy as np
import os
import random


# å¯¹è¯»å…¥çš„å›¾åƒæ•°æ®è¿›è¡Œé¢„å¤„ç†
def transform_img(img):
    # å°†å›¾ç‰‡å°ºå¯¸ç¼©æ”¾åˆ° 224x224
    img = cv2.resize(img, (224, 224))
    # è¯»å…¥çš„å›¾åƒæ•°æ®æ ¼å¼æ˜¯[H, W, C]
    # ä½¿ç”¨è½¬ç½®æ“ä½œå°†å…¶å˜æˆ[C, H ,W]
    img = np.transpose(img, (2, 0, 1))
    img = img.astype('float32')
    # å°†æ•°æ®èŒƒå›´è°ƒæ•´åˆ°[-1.0, 1.0]ä¹‹é—´
    img = img / 255.
    img = img * 2.0 - 1.0
    return img


# å®šä¹‰è®­ç»ƒé›†æ•°æ®è¯»å–å™¨
def data_loader(datadir, batch_size=10, mode='train'):
    # å°†datadirç›®å½•ä¸‹çš„æ–‡ä»¶åˆ—å‡ºæ¥ï¼Œæ¯æ¡æ–‡ä»¶éƒ½è¦è¯»å…¥
    filenames = os.listdir(datadir)

    def reader():
        if mode == 'train':
            # è®­ç»ƒæ—¶éšæœºæ‰“ä¹±æ•°æ®é¡ºåº
            random.shuffle(filenames)
        batch_imgs = []
        batch_labels = []

        for name in filenames:
            img_path = os.path.join(datadir, name)
            img = cv2.imread(img_path)
            img = transform_img(img)
            if name[0] == 'H' or name[0] == 'N':
                # Hå¼€å¤´çš„æ–‡ä»¶åè¡¨ç¤ºé«˜åº¦è¿‘è§†ï¼ŒNå¼€å¤´çš„æ–‡ä»¶åè¡¨ç¤ºæ­£å¸¸è§†åŠ›
                # é«˜åº¦è¿‘è§†å’Œæ­£å¸¸è§†åŠ›çš„æ ·æœ¬ï¼Œéƒ½ä¸æ˜¯ç—…ç†æ€§çš„ï¼Œå±äºè´Ÿæ ·æœ¬ï¼Œæ ‡ç­¾ä¸º0
                label = 0
            elif name[0] == 'P':
                label = 1
            else:
                raise ('NOT EXCEPTED FILE NAME')
            # æ¯è¯»å–ä¸€ä¸ªæ ·æœ¬çš„æ•°æ®ï¼Œå°±å°†å…¶æ”¾å…¥æ•°æ®åˆ—è¡¨ä¸­
            batch_imgs.append(img)
            batch_labels.append(label)
            if len(batch_imgs) == batch_size:
                # å½“æ•°æ®åˆ—è¡¨çš„é•¿åº¦ç­‰äºbatch_sizeçš„æ—¶å€™ï¼Œ
                # æŠŠè¿™äº›æ•°æ®å½“ä½œä¸€ä¸ªmini-batchï¼Œå¹¶ä½œä¸ºæ•°æ®ç”Ÿæˆå™¨çš„ä¸€ä¸ªè¾“å‡º
                imgs_array = np.array(batch_imgs).astype('float32')
                labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)
                yield imgs_array, labels_array
                batch_imgs = []
                batch_labels = []

        if len(batch_imgs) > 0:
            # å‰©ä½™æ ·æœ¬æ•°ä¸è¶³ä¸€ä¸ªbatch_sizeçš„æ•°æ®ï¼Œä¸€èµ·æ‰“åŒ…æˆä¸€ä¸ªmini-batch
            imgs_array = np.array(batch_imgs).astype('float32')
            labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)
            yield imgs_array, labels_array

    return reader


# å®šä¹‰è®­ç»ƒè¿‡ç¨‹
def train_pm(model, optimizer):
    use_gpu = True
    paddle.device.set_device('gpu:0') if use_gpu else paddle.device.set_device('cpu')

    print('start training ... ')
    # å®šä¹‰æ•°æ®è¯»å–å™¨ï¼Œè®­ç»ƒæ•°æ®è¯»å–å™¨å’ŒéªŒè¯æ•°æ®è¯»å–å™¨
    train_loader = data_loader(DATADIR, batch_size=10, mode='train')
    for epoch in range(EPOCH_NUM):
        model.train()
        for batch_id, data in enumerate(train_loader()):
            x_data, y_data = data
            imgs = paddle.to_tensor(x_data)
            labels = paddle.to_tensor(y_data)
            # è¿è¡Œæ¨¡å‹å‰å‘è®¡ç®—ï¼Œå¾—åˆ°é¢„æµ‹å€¼
            predicts = model(imgs)
            loss = paddle.nn.functional.binary_cross_entropy_with_logits(predicts, labels)
            avg_loss = paddle.mean(loss)

            if batch_id % 20 == 0:
                print('epoch: {}, batch_id: {}, loss is: {:.4f}'.format(epoch, batch_id, float(avg_loss.numpy())))
            avg_loss.backward()
            optimizer.step()
            optimizer.clear_grad()

        # è®¡ç®—å‡†ç¡®ç‡
        model.eval()
        accuracies = []
        losses = []
        eval_loader = data_loader(DATADIR, batch_size=10, mode='eval')
        for batch_id, data in enumerate(eval_loader()):
            x_data, y_data = data
            imgs = paddle.to_tensor(x_data)
            labels = paddle.to_tensor(y_data)
            # è¿›è¡Œæ¨¡å‹å‰å‘è®¡ç®—ï¼Œå¾—åˆ°é¢„æµ‹å€¼
            logits = model(imgs)
            # è®¡ç®—sigmoidåçš„é¢„æµ‹æ¦‚ç‡ï¼Œè¿›è¡Œlossè®¡ç®—
            loss = paddle.nn.functional.binary_cross_entropy_with_logits(logits, labels)
            # äºŒåˆ†ç±»ï¼Œsigmoidè®¡ç®—åçš„ç»“æœä»¥0.5ä¸ºé˜ˆå€¼åˆ†ä¸¤ä¸ªç±»åˆ«
            predicts2 = paddle.nn.functional.sigmoid(logits)
            predicts3 = predicts2 * (-1.0) + 1.0
            pred = paddle.concat([predicts2, predicts3], axis=1)
            acc = paddle.metric.accuracy(pred, paddle.cast(labels, dtype='int64'))

            accuracies.append(acc.numpy())
            losses.append(loss.numpy())
        print('[validation] accuracy/loss: {:.4f}/{:.4f}'.format(np.mean(accuracies), np.mean(losses)))

        paddle.save(model.state_dict(), '../output/pathologic_myopia/lenet/palm.pdparams')
        paddle.save(optimizer.state_dict(), '../output/pathologic_myopia/lenet/palm.pdopt')


# å®šä¹‰è¯„ä¼°è¿‡ç¨‹
def evaluation(model, params_file_path):
    # å¼€å¯0å·GPUé¢„ä¼°
    use_gpu = True
    paddle.device.set_device('gpu:0') if use_gpu else paddle.device.set_device('cpu')

    print('start evaluation ......')

    # åŠ è½½å‚æ•°æ¨¡å‹
    model_state_dict = paddle.load(params_file_path)
    model.load_dict(model_state_dict)

    # å¼€å¯è¯„ä¼°
    model.eval()
    eval_loader = data_loader(DATADIR, batch_size=10, mode='eval')

    acc_set = []
    avg_loss_set = []
    for batch_id, data in enumerate(eval_loader()):
        x_data, y_data = data
        img = paddle.to_tensor(x_data)
        label = paddle.to_tensor(y_data)
        label_64 = paddle.to_tensor(y_data.astype(np.int64))
        # è®¡ç®—é¢„æµ‹å’Œç²¾åº¦(label_64ä½œç”¨???)
        prediction, acc = model(img, label_64)
        # è®¡ç®—æŸå¤±å‡½æ•°å€¼
        loss = paddle.nn.functional.binary_cross_entropy_with_logits(prediction, label)
        avg_loss = paddle.mean(loss)
        acc_set.append(float(acc.numpy()))
        avg_loss_set.append(float(avg_loss.numpy()))

    # æ±‚å¹³å‡ç²¾åº¦
    acc_val_mean = np.array(acc_set).mean()
    avg_loss_val_mean = np.array(avg_loss_set).mean()

    print('loss={:.4f}, acc={:.4f}'.format(avg_loss_val_mean, acc_val_mean))


# å®šä¹‰æ¨¡å‹
class MyLeNet(paddle.nn.Layer):
    def __init__(self, num_classes=1):
        super(MyLeNet, self).__init__()

        # åˆ›å»ºå·ç§¯å’Œæ± åŒ–å±‚å—ï¼Œæ¯ä¸ªå·ç§¯å±‚ä½¿ç”¨Sigmoidæ¿€æ´»å‡½æ•°ï¼Œåé¢è·Ÿç€ä¸€ä¸ª2x2æ± åŒ–å±‚
        self.conv1 = paddle.nn.Conv2D(in_channels=3, out_channels=6, kernel_size=5)
        self.max_pool1 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)
        self.conv2 = paddle.nn.Conv2D(in_channels=6, out_channels=16, kernel_size=5)
        self.max_pool2 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)
        # åˆ›å»ºç¬¬ä¸‰ä¸ªå·ç§¯å±‚
        self.conv3 = paddle.nn.Conv2D(in_channels=16, out_channels=120, kernel_size=4)
        # åˆ›å»ºå…¨è¿æ¥å±‚ï¼Œç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚çš„è¾“å‡ºç¥ç»å…ƒä¸ªæ•°ä¸º64
        features_num = pow(((224 - 4) // 2 - 4) // 2 - 3, 2) * 120
        self.fc1 = paddle.nn.Linear(in_features=features_num, out_features=64)
        self.fc2 = paddle.nn.Linear(in_features=64, out_features=num_classes)

    # ç½‘ç»œå‰å‘è®¡ç®—è¿‡ç¨‹
    def forward(self, x, label=None):
        x = self.conv1(x)
        x = paddle.nn.functional.sigmoid(x)
        x = self.max_pool1(x)
        x = self.conv2(x)
        x = paddle.nn.functional.sigmoid(x)
        x = self.max_pool2(x)
        x = self.conv3(x)
        x = paddle.nn.functional.sigmoid(x)
        x = paddle.reshape(x, [x.shape[0], -1])
        x = self.fc1(x)
        x = paddle.nn.functional.sigmoid(x)
        x = self.fc2(x)
        # å¦‚æœè¾“å…¥äº†Labelï¼Œé‚£ä¹ˆè®¡ç®—acc
        if label is not None:
            acc = paddle.metric.accuracy(input=x, label=label)
            return x, acc
        else:
            return x


# æŸ¥çœ‹æ•°æ®å½¢çŠ¶
DATADIR = '../dataset/pathologic_myopia'
# è®¾ç½®è¿­ä»£è½®æ•°
EPOCH_NUM = 5
# åˆ›å»ºæ¨¡å‹
model = MyLeNet(num_classes=1)
# å¯åŠ¨è®­ç»ƒè¿‡ç¨‹
opt = paddle.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameters=model.parameters())
train_pm(model=model, optimizer=opt)
evaluation(model, params_file_path='../output/pathologic_myopia/lenet/palm.pdparams')


# æ‰“å°ç»“æœ
W1206 14:31:11.494339 42040 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.7, Runtime API Version: 11.6
W1206 14:31:11.496333 42040 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.
start training ... 
epoch: 0, batch_id: 0, loss is: 0.7955
epoch: 0, batch_id: 20, loss is: 0.6390
[validation] accuracy/loss: 0.5325/0.6913
epoch: 1, batch_id: 0, loss is: 0.6940
epoch: 1, batch_id: 20, loss is: 0.6598
[validation] accuracy/loss: 0.5325/0.6912
epoch: 2, batch_id: 0, loss is: 0.6852
epoch: 2, batch_id: 20, loss is: 0.6860
[validation] accuracy/loss: 0.5325/0.6915
epoch: 3, batch_id: 0, loss is: 0.6784
epoch: 3, batch_id: 20, loss is: 0.6789
[validation] accuracy/loss: 0.5325/0.6911
epoch: 4, batch_id: 0, loss is: 0.6837
epoch: 4, batch_id: 20, loss is: 0.6994
[validation] accuracy/loss: 0.5325/0.6911
start evaluation ......
loss=0.6911, acc=0.4675
```
å¯è§æ”¹æ¨¡å‹çš„å‡†ç¡®ç‡å¹¶ä¸é«˜

ä»¥ä¸‹åˆ†åˆ«å¯¹ **AlexNet/GoogLeNet/æ®‹å·®å—** ç½‘ç»œè¿›è¡Œæµ‹è¯•

ä½¿ç”¨ AlexNet ç½‘ç»œè¿›è¡Œæµ‹è¯•
```
# ä¼˜åŒ–æ¨¡å‹
class MyAlexNet(paddle.nn.Layer):
    def __init__(self, num_classes=1):
        super(MyAlexNet, self).__init__()
        self.conv1 = paddle.nn.Conv2D(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=5)
        self.max_pool1 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)
        self.conv2 = paddle.nn.Conv2D(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2)
        self.max_pool2 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)
        self.conv3 = paddle.nn.Conv2D(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1)
        self.conv4 = paddle.nn.Conv2D(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)
        self.conv5 = paddle.nn.Conv2D(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)
        self.max_pool5 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)

        self.fc1 = paddle.nn.Linear(in_features=12544, out_features=4096)
        self.drop_ratio1 = 0.5
        self.drop1 = paddle.nn.Dropout(self.drop_ratio1)
        self.fc2 = paddle.nn.Linear(in_features=4096, out_features=4096)
        self.drop_ratio2 = 0.5
        self.drop2 = paddle.nn.Dropout(self.drop_ratio2)
        self.fc3 = paddle.nn.Linear(in_features=4096, out_features=num_classes)

    def forward(self, x, label=None):
        x = self.conv1(x)
        x = paddle.nn.functional.relu(x)
        x = self.max_pool1(x)
        x = self.conv2(x)
        x = paddle.nn.functional.relu(x)
        x = self.max_pool2(x)
        x = self.conv3(x)
        x = paddle.nn.functional.relu(x)
        x = self.conv4(x)
        x = paddle.nn.functional.relu(x)
        x = self.conv5(x)
        x = paddle.nn.functional.relu(x)
        x = self.max_pool5(x)
        # å…¨è¿æ¥å±‚
        x = paddle.reshape(x, [x.shape[0], -1])
        x = self.fc1(x)
        x = paddle.nn.functional.relu(x)
        # åœ¨å…¨è¿æ¥ä¹‹åä½¿ç”¨dropoutæŠ‘åˆ¶è¿‡æ‹Ÿåˆ
        x = self.drop1(x)
        x = self.fc2(x)
        x = paddle.nn.functional.relu(x)
        x = self.drop2(x)
        x = self.fc3(x)

        # å¦‚æœè¾“å…¥äº†Labelï¼Œé‚£ä¹ˆè®¡ç®—acc
        if label is not None:
            acc = paddle.metric.accuracy(input=x, label=label)
            return x, acc
        else:
            return x

# æ‰“å°ç»“æœ
W1206 17:07:48.886270 34060 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.7, Runtime API Version: 11.6
W1206 17:07:48.889235 34060 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.
start training ... 
epoch: 0, batch_id: 0, loss is: 0.7389
epoch: 0, batch_id: 20, loss is: 0.4360
[validation] accuracy/loss: 0.8875/0.3465
epoch: 1, batch_id: 0, loss is: 0.4918
epoch: 1, batch_id: 20, loss is: 0.1599
[validation] accuracy/loss: 0.9100/0.2533
epoch: 2, batch_id: 0, loss is: 0.1056
epoch: 2, batch_id: 20, loss is: 0.0493
[validation] accuracy/loss: 0.8950/0.2766
epoch: 3, batch_id: 0, loss is: 0.1250
epoch: 3, batch_id: 20, loss is: 0.0829
[validation] accuracy/loss: 0.9300/0.1978
epoch: 4, batch_id: 0, loss is: 0.1520
epoch: 4, batch_id: 20, loss is: 0.3377
[validation] accuracy/loss: 0.9300/0.1779
start evaluation ......
loss=0.1779, acc=0.4675
```

ä½¿ç”¨ vggæ¨¡å‹ è¿›è¡Œæµ‹è¯•
```
# ä¼˜åŒ–æ¨¡å‹
class VGG(paddle.nn.Layer):
    def __init__(self, num_classes=None):
        super(VGG, self).__init__()

        in_channels = [3, 64, 128, 256, 512, 512]
        # å®šä¹‰ç¬¬ä¸€ä¸ªblockï¼ŒåŒ…å«ä¸¤ä¸ªå·ç§¯
        self.conv1_1 = paddle.nn.Conv2D(in_channels=in_channels[0], out_channels=in_channels[1], kernel_size=3,
                                        padding=1, stride=1)
        self.conv1_2 = paddle.nn.Conv2D(in_channels=in_channels[1], out_channels=in_channels[1], kernel_size=3,
                                        padding=1, stride=1)
        # å®šä¹‰ç¬¬äºŒä¸ªblockï¼ŒåŒ…å«ä¸¤ä¸ªå·ç§¯
        self.conv2_1 = paddle.nn.Conv2D(in_channels=in_channels[1], out_channels=in_channels[2], kernel_size=3,
                                        padding=1, stride=1)
        self.conv2_2 = paddle.nn.Conv2D(in_channels=in_channels[2], out_channels=in_channels[2], kernel_size=3,
                                        padding=1, stride=1)
        # å®šä¹‰ç¬¬ä¸‰ä¸ªblockï¼ŒåŒ…å«ä¸‰ä¸ªå·ç§¯
        self.conv3_1 = paddle.nn.Conv2D(in_channels=in_channels[2], out_channels=in_channels[3], kernel_size=3,
                                        padding=1, stride=1)
        self.conv3_2 = paddle.nn.Conv2D(in_channels=in_channels[3], out_channels=in_channels[3], kernel_size=3,
                                        padding=1, stride=1)
        self.conv3_3 = paddle.nn.Conv2D(in_channels=in_channels[3], out_channels=in_channels[3], kernel_size=3,
                                        padding=1, stride=1)
        # å®šä¹‰ç¬¬å››ä¸ªblockï¼ŒåŒ…å«ä¸‰ä¸ªå·ç§¯
        self.conv4_1 = paddle.nn.Conv2D(in_channels=in_channels[3], out_channels=in_channels[4], kernel_size=3,
                                        padding=1, stride=1)
        self.conv4_2 = paddle.nn.Conv2D(in_channels=in_channels[4], out_channels=in_channels[4], kernel_size=3,
                                        padding=1, stride=1)
        self.conv4_3 = paddle.nn.Conv2D(in_channels=in_channels[4], out_channels=in_channels[4], kernel_size=3,
                                        padding=1, stride=1)
        # å®šä¹‰ç¬¬äº”ä¸ªblockï¼ŒåŒ…å«ä¸‰ä¸ªå·ç§¯
        self.conv5_1 = paddle.nn.Conv2D(in_channels=in_channels[4], out_channels=in_channels[5], kernel_size=3,
                                        padding=1, stride=1)
        self.conv5_2 = paddle.nn.Conv2D(in_channels=in_channels[5], out_channels=in_channels[5], kernel_size=3,
                                        padding=1, stride=1)
        self.conv5_3 = paddle.nn.Conv2D(in_channels=in_channels[5], out_channels=in_channels[5], kernel_size=3,
                                        padding=1, stride=1)

        # ä½¿ç”¨Sequential å°†å…¨è¿æ¥å±‚å’Œreluç»„æˆä¸€ä¸ªçº¿æ€§ç»“æ„ (fc + relu)
        # å½“è¾“å…¥ä¸º244x244æ—¶ï¼Œç»è¿‡äº”ä¸ªå·ç§¯å—å’Œæ± åŒ–å±‚åï¼Œç‰¹å¾ç»´åº¦å˜ä¸º[512x7x7]
        self.fc1 = paddle.nn.Sequential(paddle.nn.Linear(512 * 7 * 7, 4096), paddle.nn.ReLU())
        self.drop1_ratio = 0.5
        self.dropout1 = paddle.nn.Dropout(self.drop1_ratio, mode='upscale_in_train')
        # ä½¿ç”¨Sequentialå°†å…¨è¿æ¥å±‚å’Œreluç»„æˆä¸€ä¸ªçº¿æ€§ç»“æ„(fc + relu)
        self.fc2 = paddle.nn.Sequential(paddle.nn.Linear(4096, 4096), paddle.nn.ReLU())
        self.drop2_ratio = 0.5
        self.dropout2 = paddle.nn.Dropout(self.drop2_ratio, mode='upscale_in_train')
        self.fc3 = paddle.nn.Linear(4096, 1)

        self.relu = paddle.nn.ReLU()
        self.pool = paddle.nn.MaxPool2D(stride=2, kernel_size=2)

    def forward(self, x, label=None):
        x = self.relu(self.conv1_1(x))
        x = self.relu(self.conv1_2(x))
        x = self.pool(x)

        x = self.relu(self.conv2_1(x))
        x = self.relu(self.conv2_2(x))
        x = self.pool(x)

        x = self.relu(self.conv3_1(x))
        x = self.relu(self.conv3_2(x))
        x = self.relu(self.conv3_3(x))
        x = self.pool(x)

        x = self.relu(self.conv4_1(x))
        x = self.relu(self.conv4_2(x))
        x = self.relu(self.conv4_3(x))
        x = self.pool(x)

        x = self.relu(self.conv5_1(x))
        x = self.relu(self.conv5_2(x))
        x = self.relu(self.conv5_3(x))
        x = self.pool(x)

        x = paddle.flatten(x, 1, -1)
        x = self.dropout1(self.relu(self.fc1(x)))
        x = self.dropout2(self.relu(self.fc2(x)))
        x = self.fc3(x)

        # å¦‚æœè¾“å…¥äº†Labelï¼Œé‚£ä¹ˆè®¡ç®—acc
        if label is not None:
            acc = paddle.metric.accuracy(input=x, label=label)
            return x, acc
        else:
            return x

# æ‰“å°ç»“æœä¸º
W1206 17:31:48.611086 37108 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.7, Runtime API Version: 11.6
W1206 17:31:48.650003 37108 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.
start training ... 
epoch: 0, batch_id: 0, loss is: 0.8150
epoch: 0, batch_id: 20, loss is: 0.8149
[validation] accuracy/loss: 0.8775/0.3243
epoch: 1, batch_id: 0, loss is: 0.1642
epoch: 1, batch_id: 20, loss is: 0.2195
[validation] accuracy/loss: 0.9000/0.2934
epoch: 2, batch_id: 0, loss is: 0.2956
epoch: 2, batch_id: 20, loss is: 0.8894
[validation] accuracy/loss: 0.8975/0.2357
epoch: 3, batch_id: 0, loss is: 0.3631
epoch: 3, batch_id: 20, loss is: 0.1797
[validation] accuracy/loss: 0.9125/0.2169
epoch: 4, batch_id: 0, loss is: 0.5968
epoch: 4, batch_id: 20, loss is: 0.0280
[validation] accuracy/loss: 0.9200/0.1935
start evaluation ......
loss=0.1935, acc=0.4675
```

ä½¿ç”¨ GoogLeNetæ¨¡å‹ æµ‹è¯•
```
# ä¼˜åŒ–æ¨¡å‹
# å®šä¹‰Inceptionå—
class Inception(paddle.nn.Layer):
    def __init__(self, c0, c1, c2, c3, c4, **kwargs):
        '''
        Inceptionæ¨¡å—çš„å®ç°ä»£ç 
        :param c0:
        :param c1:å›¾(b)ä¸­ç¬¬ä¸€æ¡æ”¯è·¯1x1å·ç§¯çš„è¾“å‡ºé€šé“æ•°,æ•°æ®ç±»å‹æ˜¯æ•´æ•°
        :param c2:å›¾(b)ä¸­ç¬¬äºŒæ¡æ”¯è·¯å·ç§¯çš„è¾“å‡ºé€šé“æ•°,æ•°æ®ç±»å‹æ˜¯tupleæˆ–list,å…¶ä¸­c2[0]æ˜¯1x1å·ç§¯çš„è¾“å‡ºé€šé“æ•°,c2[1]æ˜¯3x3
        :param c3:å›¾(b)ä¸­ç¬¬ä¸‰æ¡æ”¯è·¯å·ç§¯çš„è¾“å‡ºé€šé“æ•°,æ•°æ®ç±»å‹æ˜¯tupleæˆ–list,å…¶ä¸­c3[0]æ˜¯1x1å·ç§¯çš„è¾“å‡ºé€šé“æ•°,c3[1]æ˜¯3x3
        :param c4:å›¾(b)ä¸­ç¬¬ä¸€æ¡æ”¯è·¯1x1å·ç§¯çš„è¾“å‡ºé€šé“æ•°,æ•°æ®ç±»å‹æ˜¯æ•´æ•°
        :param kwargs:
        '''
        super(Inception, self).__init__()
        # ä¾æ¬¡åˆ›å»ºInceptionå—æ¯æ¡æ”¯è·¯ä¸Šä½¿ç”¨åˆ°çš„æ“ä½œ
        self.p1_1 = paddle.nn.Conv2D(in_channels=c0, out_channels=c1, kernel_size=1, stride=1)

        self.p2_1 = paddle.nn.Conv2D(in_channels=c0, out_channels=c2[0], kernel_size=1, stride=1)
        self.p2_2 = paddle.nn.Conv2D(in_channels=c2[0], out_channels=c2[1], kernel_size=3, padding=1, stride=1)

        self.p3_1 = paddle.nn.Conv2D(in_channels=c0, out_channels=c3[0], kernel_size=1, stride=1)
        self.p3_2 = paddle.nn.Conv2D(in_channels=c3[0], out_channels=c3[1], kernel_size=5, padding=2, stride=1)

        self.p4_1 = paddle.nn.MaxPool2D(kernel_size=3, stride=1, padding=1)
        self.p4_2 = paddle.nn.Conv2D(in_channels=c0, out_channels=c4, kernel_size=1, stride=1)

        # # æ–°åŠ ä¸€å±‚batchnormç¨³å®šæ”¶æ•›
        # self.batchnorm = paddle.nn.BatchNorm2D(c1+c2[1]+c3[1]+c4)

    def forward(self, x):
        # æ”¯è·¯1åªåŒ…å«ä¸€ä¸ª 1x1å·ç§¯
        p1 = paddle.nn.functional.relu(self.p1_1(x))
        # æ”¯è·¯2åŒ…å« 1x1å·ç§¯ + 3x3å·ç§¯
        p2 = paddle.nn.functional.relu(self.p2_2(paddle.nn.functional.relu(self.p2_1(x))))
        # æ”¯è·¯3åŒ…å« 1x1å·ç§¯ + 5x5å·ç§¯
        p3 = paddle.nn.functional.relu(self.p3_2(paddle.nn.functional.relu(self.p3_1(x))))
        # æ”¯è·¯4åŒ…å« æœ€å¤§æ± åŒ– + 1x1å·ç§¯
        p4 = paddle.nn.functional.relu(self.p4_2(paddle.nn.functional.relu(self.p4_1(x))))
        # å°†æ¯ä¸ªæ”¯è·¯çš„è¾“å‡ºç‰¹å¾å›¾æ‹¼æ¥åœ¨ä¸€èµ·ä½œä¸ºæœ€ç»ˆçš„è¾“å‡ºç»“æœ
        return paddle.concat([p1, p2, p3, p4], axis=1)
        # return self.batchnorm()


class GoogleNet(paddle.nn.Layer):
    def __init__(self, num_classes=None):
        super(GoogleNet, self).__init__()
        # GoogleLeNetåŒ…å«5ä¸ªæ¨¡å—ï¼Œæ¯ä¸ªæ¨¡å—åé¢ç´§è·Ÿä¸€ä¸ªæ± åŒ–å±‚
        # ç¬¬ä¸€ä¸ªæ¨¡å—åŒ…å«1ä¸ªå·ç§¯å±‚
        self.conv1 = paddle.nn.Conv2D(in_channels=3, out_channels=64, kernel_size=7, padding=3, stride=1)
        # 3x3æœ€å¤§æ± åŒ–
        self.max_pool1 = paddle.nn.MaxPool2D(kernel_size=3, stride=2, padding=1)
        # ç¬¬äºŒä¸ªæ¨¡å—åŒ…å«2ä¸ªå·ç§¯å±‚
        self.conv2_1 = paddle.nn.Conv2D(in_channels=64, out_channels=64, kernel_size=1, stride=1)
        self.conv2_2 = paddle.nn.Conv2D(in_channels=64, out_channels=192, kernel_size=3, padding=1, stride=1)
        # 3x3æœ€å¤§æ± åŒ–
        self.max_pool2 = paddle.nn.MaxPool2D(kernel_size=3, stride=2, padding=1)
        # ç¬¬ä¸‰ä¸ªæ¨¡å—åŒ…å«2ä¸ªInceptionå—
        self.block3_1 = Inception(192, 64, (96, 128), (16, 32), 32)
        self.block3_2 = Inception(256, 128, (128, 192), (32, 96), 64)
        # 3x3æœ€å¤§æ± åŒ–
        self.max_pool3 = paddle.nn.MaxPool2D(kernel_size=3, stride=2, padding=1)
        # ç¬¬å››ä¸ªæ¨¡å—åŒ…å«5ä¸ªInceptionå—
        self.block4_1 = Inception(480, 192, (96, 208), (16, 48), 64)
        self.block4_2 = Inception(512, 160, (112, 224), (24, 64), 64)
        self.block4_3 = Inception(512, 128, (128, 256), (24, 64), 64)
        self.block4_4 = Inception(512, 112, (144, 288), (32, 64), 64)
        self.block4_5 = Inception(528, 256, (160, 320), (32, 128), 128)
        # 3x3 æœ€å¤§æ± åŒ–
        self.max_pool4 = paddle.nn.MaxPool2D(kernel_size=3, stride=2, padding=1)
        # ç¬¬äº”ä¸ªæ¨¡å—åŒ…å«2ä¸ªInceptionå—
        self.block5_1 = Inception(832, 256, (160, 320), (32, 128), 128)
        self.block5_2 = Inception(832, 384, (192, 384), (48, 128), 128)
        # å…¨å±€æ± åŒ–ï¼Œç”¨çš„æ˜¯global_poolingï¼Œä¸éœ€è¦pool_stride
        self.pool5 = paddle.nn.AdaptiveAvgPool2D(output_size=1)
        self.fc = paddle.nn.Linear(in_features=1024, out_features=1)

    def forward(self, x, label=None):
        x = self.max_pool1(paddle.nn.functional.relu(self.conv1(x)))
        x = self.max_pool2(paddle.nn.functional.relu(self.conv2_2(paddle.nn.functional.relu(self.conv2_1(x)))))
        x = self.max_pool3(self.block3_2(self.block3_1(x)))
        x = self.block4_3(self.block4_2(self.block4_1(x)))
        x = self.max_pool4(self.block4_5(self.block4_4(x)))
        x = self.pool5(self.block5_2(self.block5_1(x)))
        x = paddle.reshape(x, [x.shape[0], -1])
        x = self.fc(x)

        # å¦‚æœè¾“å…¥äº†Labelï¼Œé‚£ä¹ˆè®¡ç®—acc
        if label is not None:
            acc = paddle.metric.accuracy(input=x, label=label)
            return x, acc
        else:
            return x

# æ‰“å°ç»“æœä¸º
W1206 19:02:25.166755 16624 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.7, Runtime API Version: 11.6
W1206 19:02:25.169747 16624 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.
start training ... 
epoch: 0, batch_id: 0, loss is: 1.1343
epoch: 0, batch_id: 20, loss is: 0.6439
[validation] accuracy/loss: 0.5325/0.6300
epoch: 1, batch_id: 0, loss is: 0.5812
epoch: 1, batch_id: 20, loss is: 0.5121
[validation] accuracy/loss: 0.8350/0.5007
epoch: 2, batch_id: 0, loss is: 0.5198
epoch: 2, batch_id: 20, loss is: 0.5148
[validation] accuracy/loss: 0.8975/0.4222
epoch: 3, batch_id: 0, loss is: 0.4430
epoch: 3, batch_id: 20, loss is: 0.3156
[validation] accuracy/loss: 0.9200/0.2925
epoch: 4, batch_id: 0, loss is: 0.2119
epoch: 4, batch_id: 20, loss is: 0.6766
[validation] accuracy/loss: 0.9300/0.2280
start evaluation ......
loss=0.2280, acc=0.4675
```

ä½¿ç”¨ æ®‹å·®å—ç½‘ç»œ è¿›è¡Œæµ‹è¯•
```
# ResNetä¸­ä½¿ç”¨äº†BatchNormå±‚ï¼Œåœ¨å·ç§¯å±‚çš„åé¢åŠ ä¸ŠBatchNormä»¥æå‡æ•°å€¼ç¨³å®šæ€§
# å®šä¹‰å·ç§¯æ‰¹å½’ä¸€ä½“åŒ–
class ConvBNLayer(paddle.nn.Layer):
    def __init__(self, num_channels, num_filters, filter_size, stride=1, groups=1, act=None):
        '''
        :param num_channels:å·ç§¯å±‚çš„è¾“å…¥é€šé“æ•°
        :param num_filters: å·ç§¯å±‚çš„è¾“å‡ºé€šé“æ•°
        :param filter_size:
        :param stride: å·ç§¯å±‚çš„æ­¥å¹…
        :param groups: åˆ†ç»„å·ç§¯çš„æ•°ç»„ï¼Œé»˜è®¤groups=1ä¸ä½¿ç”¨åˆ†ç»„å·ç§¯
        :param act:
        '''
        super(ConvBNLayer, self).__init__()

        # åˆ›å»ºå·ç§¯å±‚
        self._conv = paddle.nn.Conv2D(in_channels=num_channels, out_channels=num_filters, kernel_size=filter_size,
                                      stride=stride, padding=(filter_size - 1) // 2, groups=groups, bias_attr=False)

        # åˆ›å»ºBatchNormå±‚
        self._batch_norm = paddle.nn.BatchNorm2D(num_filters)

        self.act = act

    def forward(self, inputs):
        y = self._conv(inputs)
        y = self._batch_norm(y)
        if self.act == 'leaky':
            y = paddle.nn.functional.leaky_relu(x=y, negative_slope=0.1)
        elif self.act == 'relu':
            y = paddle.nn.functional.relu(x=y)

        return y


# å®šä¹‰æ®‹å·®å—
# æ¯ä¸ªæ®‹å·®å—ä¼šå¯¹è¾“å…¥å›¾ç‰‡åšä¸‰æ¬¡å·ç§¯ï¼Œç„¶åè·Ÿè¾“å…¥å›¾ç‰‡è¿›è¡ŒçŸ­æ¥
# å¦‚æœæ®‹å·®å—ä¸­ç¬¬ä¸‰æ¬¡å·ç§¯è¾“å‡ºç‰¹å¾å›¾çš„å½¢çŠ¶ä¸è¾“å…¥ä¸ä¸€è‡´ï¼Œåˆ™å¯¹è¾“å…¥å›¾ç‰‡åš1x1å·ç§¯ï¼Œå°†å…¶è¾“å‡ºå½¢çŠ¶è°ƒæ•´æˆä¸€è‡´
class BottleneckBlock(paddle.nn.Layer):
    def __init__(self, num_channels, num_filters, stride, shortcut=True):
        super(BottleneckBlock, self).__init__()
        # åˆ›å»ºç¬¬ä¸€ä¸ªå·ç§¯å±‚ 1x1
        self.conv0 = ConvBNLayer(num_channels=num_channels, num_filters=num_filters, filter_size=1, act='relu')
        # åˆ›å»ºç¬¬äºŒä¸ªå·ç§¯å±‚ 3x3
        self.conv1 = ConvBNLayer(num_channels=num_filters, num_filters=num_filters, filter_size=3, stride=stride,
                                 act='relu')
        # åˆ›å»ºç¬¬ä¸‰ä¸ªå·ç§¯1x1ï¼Œä½†æ˜¯è¾“å‡ºé€šé“æ•°ä¹˜ä»¥4
        self.conv2 = ConvBNLayer(num_channels=num_filters, num_filters=num_filters * 4, filter_size=1, act=None)

        # å¦‚æœconv2çš„è¾“å‡ºè·Ÿæ­¤æ®‹å·®å—çš„è¾“å…¥æ•°æ®å½¢çŠ¶ä¸€è‡´ï¼Œåˆ™shortcut=True
        # å¦åˆ™shortcut = Falseï¼Œæ·»åŠ 1x1çš„å·ç§¯ä½œç”¨åœ¨è¾“å…¥æ•°æ®ä¸Šï¼Œä½¿å…¶å½¢çŠ¶å˜æˆè·Ÿconv2ä¸€è‡´
        if not shortcut:
            self.short = ConvBNLayer(num_channels=num_channels, num_filters=num_filters * 4, filter_size=1,
                                     stride=stride)

        self.shortcut = shortcut
        self._num_channels_out = num_filters * 4

    def forward(self, inputs):
        y = self.conv0(inputs)
        conv1 = self.conv1(y)
        conv2 = self.conv2(conv1)

        # å¦‚æœshortcut=Trueï¼Œç›´æ¥å°†inputsè·Ÿconv2çš„è¾“å‡ºç›¸åŠ 
        # å¦åˆ™éœ€è¦å¯¹inputsè¿›è¡Œä¸€æ¬¡å·ç§¯ï¼Œå°†å½¢çŠ¶è°ƒæ•´æˆè·Ÿconv2è¾“å‡ºä¸€è‡´
        if self.shortcut:
            short = inputs
        else:
            short = self.short(inputs)

        y = paddle.add(x=short, y=conv2)
        y = paddle.nn.functional.relu(y)

        return y


# å®šä¹‰ResNetæ¨¡å‹
class ResNet(paddle.nn.Layer):
    def __init__(self, layers=50, class_dim=1):
        '''

        :param layers:ç½‘ç»œå±‚æ•°ï¼Œå¯ä»¥æ˜¯50,101æˆ–è€…152
        :param class_dim: åˆ†ç±»æ ‡ç­¾çš„ç±»åˆ«æ•°
        '''
        super(ResNet, self).__init__()
        self.layers = layers
        supported_layers = [50, 101, 152]
        assert layers in supported_layers, 'supporrted layers are {} but input layer is {}'.format(supported_layers,
                                                                                                   layers)

        if layers == 50:
            # ResNet50åŒ…å«å¤šä¸ªæ¨¡å—ï¼Œå…¶ä¸­ç¬¬2åˆ°ç¬¬5ä¸ªæ¨¡å—åˆ†åˆ«åŒ…å«3ã€4ã€6ã€3ä¸ªæ®‹å·®å—
            depth = [3, 4, 6, 3]
        elif layers == 101:
            # ResNet101åŒ…å«å¤šä¸ªæ¨¡å—ï¼Œå…¶ä¸­ç¬¬2åˆ°ç¬¬5ä¸ªæ¨¡å—åˆ†åˆ«åŒ…å«3ã€4ã€23ã€3ä¸ªæ®‹å·®å—
            depth = [3, 4, 23, 3]
        elif layers == 152:
            # ResNET152åŒ…å«å¤šä¸ªæ¨¡å—ï¼Œå…¶ä¸­ç¬¬2åˆ°ç¬¬5ä¸ªæ¨¡å—åˆ†åˆ«åŒ…å«3ã€8ã€36ã€3
            depth = [3, 8, 36, 3]

        # æ®‹å·®å—ä¸­ä½¿ç”¨åˆ°çš„å·ç§¯çš„è¾“å‡ºé€šé“
        num_filters = [64, 128, 256, 512]

        # ResNetçš„ç¬¬ä¸€ä¸ªæ¨¡å—ï¼ŒåŒ…å«1ä¸ª7x7å·ç§¯ï¼Œåé¢è·Ÿç€1ä¸ªæœ€å¤§æ± åŒ–å±‚
        self.conv = ConvBNLayer(num_channels=3, num_filters=64, filter_size=7, stride=2, act='relu')
        self.max_pool = paddle.nn.MaxPool2D(kernel_size=3, stride=2, padding=1)

        # ResNetçš„ç¬¬äºŒä¸ªåˆ°ç¬¬äº”ä¸ªæ¨¡å—c2ã€c3ã€c4ã€c5
        self.bottleneck_block_list = []
        num_channels = 64
        for block in range(len(depth)):
            shortcut = False
            for i in range(depth[block]):
                bottleneck_block = self.add_sublayer(
                    'bb_%d_%d' % (block, i),
                    BottleneckBlock(num_channels=num_channels,
                                    num_filters=num_filters[
                                        block],
                                    stride=2 if i == 0 and block != 0 else 1,
                                    shortcut=shortcut)
                )
                num_channels = bottleneck_block._num_channels_out
                self.bottleneck_block_list.append(bottleneck_block)
                shortcut = True

        # åœ¨c5çš„è¾“å‡ºç‰¹å¾å›¾ä¸Šä½¿ç”¨å…¨å±€æ± åŒ–
        self.pool2d_avg = paddle.nn.AdaptiveAvgPool2D(output_size=1)

        # stdvç”¨æ¥ä½œä¸ºå…¨è¿æ¥å±‚éšæœºåˆå§‹åŒ–å‚æ•°çš„æ–¹å·®
        import math
        stdv = 1.0 / math.sqrt(2048 * 1.0)

        # åˆ›å»ºå…¨è¿æ¥å±‚ï¼Œè¾“å‡ºå¤§å°ä¸ºç±»åˆ«æ•°ç›®ï¼Œç»è¿‡æ®‹å·®ç½‘ç»œçš„å·ç§¯å’Œå…¨å±€æ± åŒ–åï¼Œå·ç§¯ç‰¹å¾çš„ç»´åº¦æ˜¯[B, 2048, 1, 1]ï¼Œæ•…æœ€åä¸€å±‚å…¨è¿æ¥çš„è¾“å…¥ç»´åº¦æ˜¯2048
        self.out = paddle.nn.Linear(in_features=2048,
                                    out_features=class_dim,
                                    weight_attr=paddle.ParamAttr(
                                        initializer=paddle.nn.initializer.Uniform(-stdv, stdv))
                                    )

    def forward(self, inputs, label=None):
        y = self.conv(inputs)
        y = self.max_pool(y)
        for bottleneck_block in self.bottleneck_block_list:
            y = bottleneck_block(y)
        y = self.pool2d_avg(y)
        y = paddle.reshape(y, [y.shape[0], -1])
        y = self.out(y)

        # å¦‚æœè¾“å…¥äº†Labelï¼Œé‚£ä¹ˆè®¡ç®—acc
        if label is not None:
            acc = paddle.metric.accuracy(input=inputs, label=label)
            return y, acc
        else:
            return y

# æ‰“å°ç»“æœä¸º
W1206 19:58:02.451362 12844 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.7, Runtime API Version: 11.6
W1206 19:58:02.453357 12844 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.
start training ... 
F:\miniconda3nvs\paddle23\lib\site-packages\paddle
n\layer
orm.py:654: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
epoch: 0, batch_id: 0, loss is: 0.6839
epoch: 0, batch_id: 20, loss is: 0.9671
[validation] accuracy/loss: 0.5575/1.0465
epoch: 1, batch_id: 0, loss is: 0.5888
epoch: 1, batch_id: 20, loss is: 0.3879
[validation] accuracy/loss: 0.6675/0.8323
epoch: 2, batch_id: 0, loss is: 1.0331
epoch: 2, batch_id: 20, loss is: 0.1507
[validation] accuracy/loss: 0.9125/0.3006
epoch: 3, batch_id: 0, loss is: 0.7395
epoch: 3, batch_id: 20, loss is: 0.1936
[validation] accuracy/loss: 0.9200/0.2864
epoch: 4, batch_id: 0, loss is: 0.0622
epoch: 4, batch_id: 20, loss is: 0.1062
[validation] accuracy/loss: 0.8925/0.2969
start evaluation ......
loss=0.2969, acc=0.0000
```

ä¹Ÿå¯ä»¥ç›´æ¥é€šè¿‡`from paddle.vision.models import resnet50, vgg16, LeNet`æ¥ä½¿ç”¨å°è£…å¥½çš„ç½‘ç»œæ¨¡å‹
```
from paddle.vision.models import resnet50, vgg16, LeNet
......
model = resnet50(pretrained=False, num_classes=1)
```

<br>
## 2.5 PCBç”µè·¯æ¿ç¼ºé™·æ£€æµ‹(PaddleDetection)
ä½¿ç”¨PaddlePaddleçš„[PaddleDetection](https://github.com/PaddlePaddle/PaddleDetection)æ¥å®Œæˆã€‚
éœ€è¦ä¸‹è½½é¡¹ç›®ä¸­ã€‚

**å®‰è£…PaddleDectionå¼€å‘å¥—ä»¶**
ä¸‹è½½PaddleDectionåŒ…ï¼Œä¸‹è½½requirementä¸­çš„æ¨¡å— `pip install -r .equirements.txt`
>å¦‚æœcython_bboxå®‰è£…å¤±è´¥ï¼Œä½¿ç”¨å¦‚ä¸‹å‘½ä»¤å®‰è£…
`python -m pip install git+https://github.com/yanfengliu/cython_bbox.git`

åœ¨é¡¹ç›®ç›®å½•ä¸‹åˆ›å»ºworkç›®å½•ï¼Œæ”¾ç½®å¼€å‘è„šæœ¬ã€‚

<br>
**æ•°æ®é›†ä¸­çš„jsonæ–‡ä»¶æ ‡ç­¾å«ä¹‰**
COCOæ•°æ®é›†æ ‡æ³¨ä¸­çš„annotationæ ‡ç­¾å„ä¸ªå±æ€§å«ä¹‰
```
{
    "area":4012,
    "iscrowd":0,
    "bbox":[492, 500, 59, 68],
    "category_id":3,
    "ignore":0,
    "segmentation":[],
    "image_id":0,
    "id":1
}
```
>idå­—æ®µï¼šæŒ‡çš„æ˜¯è¿™ä¸ªannotationçš„ä¸€ä¸ªid
>image_idï¼šç­‰åŒäºå‰é¢imageå­—æ®µé‡Œé¢çš„idã€‚
>category_idï¼šç±»åˆ«id
>segmentationï¼š
>areaï¼šæ ‡æ³¨åŒºåŸŸé¢ç§¯
>bboxï¼šæ ‡æ³¨æ¡†ï¼Œä¾æ¬¡ä¸ºæ ‡æ³¨æ¡†å·¦ä¸Šè§’æ¨ªçºµåæ ‡ï¼Œå®½å’Œé«˜ (å³492å’Œ500ä¸ºæ ‡æ³¨æ¡†çš„å·¦ä¸Šè§’åæ ‡ï¼Œ59æ˜¯widthï¼Œ68æ˜¯height)
>iscrowdï¼šå†³å®šæ˜¯RLEæ ¼å¼è¿˜æ˜¯polygonæ ¼å¼ã€‚

é¦–å…ˆéœ€è¦æ£€æŸ¥æ ·æœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬ â‘ æ ·æœ¬ä¸­æ ‡æ³¨çš„ç§ç±»æ•°é‡æ˜¯å¦ç›¸è¿‘ â‘¡é”šæ¡†å®½é«˜æ¯” â‘¢é”šæ¡†å æ•´ä¸ªå›¾ç‰‡çš„æ¯”ä¾‹
```
import json
import collections
from matplotlib import pyplot as plt

'''
é¦–å…ˆéœ€è¦æ£€æŸ¥æ ·æœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬ â‘ æ ·æœ¬ä¸­æ ‡æ³¨çš„ç§ç±»æ•°é‡æ˜¯å¦ç›¸è¿‘ â‘¡é”šæ¡†å®½é«˜æ¯” â‘¢é”šæ¡†å æ•´ä¸ªå›¾ç‰‡çš„æ¯”ä¾‹
'''

# åŠ è½½è§£æjsonæ–‡ä»¶
with open('./PCB_DATASET/Annotations/train.json') as f:
    data = json.load(f)

# ä¿å­˜å›¾ç‰‡ä¿¡æ¯
imgs = {}
for img in data['images']:
    imgs[img['id']] = {
        'height': img['height'],
        'width': img['width'],
        'area': img['height'] * img['width']
    }

# è®¡ç®—æ ‡æ³¨ä¿¡æ¯
hw_ratios = []
area_ratios = []
cate_count = collections.defaultdict(int)
for anno in data['annotations']:
    hw_ratios.append(anno['bbox'][3] / anno['bbox'][2])
    area_ratios.append(anno['area'] / imgs[anno['image_id']]['area'])
    cate_count[anno['category_id']] += 1

print(cate_count, len(data['annotations'])/len(data['images']))

plt.hist(hw_ratios, bins=100, range=[0, 2])
plt.show()

plt.hist(area_ratios, bins=100, range=[0, 0.005])
plt.show()
```
ç¼–è¾‘é…ç½®æ–‡ä»¶
```
metric: COCO    # Labelè¯„ä»·æŒ‡æ ‡ï¼Œcoco IoU:0.5:0.95
num_classes: 7  # ç±»åˆ«æ•°é‡ï¼šcocoç±»åˆ«æ¯”å®é™…ç±»åˆ«(vocç±»åˆ«) +1

# æ•°æ®é›†çš„ä½ç½®ç­‰ä¿¡æ¯
TrainDataset:
  !COCODataSet
    image_dir: images
    anno_path: Annotations/train.json
    dataset_dir: D:\ML\Dataset\PCB_DATASET
    data_fields: ['image','gt_bbox','gt_class'] # 'è¾“å…¥å›¾ç‰‡ï¼Œå¾—åˆ°è¾“å‡ºæ¡†å’Œç±»åˆ«'

EvalDataset:
  !COCODataSet
    image_dir: images
    anno_path: Annotations/val.json
    dataset_dir: D:\ML\Dataset\PCB_DATASET

TestDataset:
  !ImageFolder
    anno_path: Annotations/val.json


use_gpu: False        # æ˜¯å¦å¼€å¯GPU
log_iter: 10          # æ—¥å¿—çª—å£çš„å°ºåº¦
save_dir: output/     # è¾“å‡ºç»“æœç½—ç›˜ä½ç½®
snapshot_epoch: 1     # ç”Ÿæˆå¿«ç…§çš„é¢‘ç‡ï¼Œå³æ¯1ä¸ªå‘¨æœŸç”Ÿæˆä¸€æ¬¡

epoch: 24             ### è®­ç»ƒå‘¨æœŸï¼š24

LearningRate:         ### å­¦ä¹ ç‡ï¼šé˜¶æ®µå­¦ä¹ 
  base_lr: 0.0025     # èµ·å§‹å­¦ä¹ ç‡ï¼š0.0025
  schedulers:
  - !PiecewiseDecay   ## é˜¶æ®µå­¦ä¹ ç‡
    gamma: 0.1        # æ¯æ¬¡å­¦ä¹ ç‡å˜åŒ–ä¸ºåŸæ¥çš„1/10
    milestones: [16, 22] # æ€»å…±è¿›è¡Œä¸¤æ¬¡å­¦ä¹ ç‡çš„é™ä½ï¼Œåˆ†åˆ«åœ¨ç¬¬16è½®å’Œ22è½®å¼€å§‹æ—¶
  - !LinearWarmup     ## æ…¢å¯åŠ¨ï¼Œå…±æ‰§è¡Œ200æ¬¡è¿­ä»£ï¼Œå­¦ä¹ ç‡ä¸ºåˆå§‹å­¦ä¹ ç‡çš„0.1
    start_factor: 0.1
    steps: 200

OptimizerBuilder:     ### å®šä¹‰ä¼˜åŒ–å™¨
  optimizer:          ## åŸºäºåŠ¨é‡çš„SGDä¼˜åŒ–å™¨
    momentum: 0.9
    type: Momentum
  regularizer:        ## å®šä¹‰æ­£åˆ™é¡¹
    factor: 0.0001
    type: L2

architecture: FasterRCNN  # æ€»æ¡†æ¶ç±»å‹

# é¢„è®­ç»ƒæ¨¡å‹ï¼šåŸºäºå·²æœ‰çš„æ¨¡å‹è¿›è¡Œè®­ç»ƒ
# pretrain_weights: https://paddledet.bj.bcebos.com/models/pretrained/ResNet50_cos_pretrained.pdparams
pretrain_weights: D:\ML\Project\PaddleDetection-release-2.3\work\output\Resnet50_cos_pretrained.pdparams

## æ£€æµ‹æ¨¡å‹çš„ä½“ç³»ç»“æ„ï¼ŒåŒ…å«éª¨å¹²ã€æ”¯è·¯ã€åŒºåŸŸå»ºè®¾ã€BBoxå¤´å’ŒBBoxåå¤„ç†
FasterRCNN:
  backbone: ResNet          # ä¸»å¹²ç½‘ç»œï¼šResNet
  neck: FPN                 # ç‰¹å¾èåˆï¼šç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ
  rpn_head: RPNHead         # åŒºåŸŸå»ºè®®å¤´ï¼šåŸºäºFPNçš„RPNHead
  bbox_head: BBoxHead       # BBoxå¤´ï¼šBBoxHead
  # post process
  bbox_post_process: BBoxPostProcess  # BBoxåå¤„ç†å™¨

## å¯¹å®šä¹‰çš„RestNetè¿›è¡Œè¯¦ç»†æè¿°
ResNet:
  depth: 50                 # æ·±åº¦50ï¼Œå³ResNet50
  norm_type: bn             # æ­£åˆ™åŒ–ç±»BNï¼ŒåŸºæœ¬ä¸Šæ˜¯å”¯ä¸€é€‰æ‹©
  freeze_at: 0              # å†»ç»“éƒ¨åˆ†ï¼ŒResNetçš„å‰ä¸¤å±‚ï¼Œä¸è°ƒæ•´å‚æ•°
  return_idx: [0,1,2,3]     # æå–ç‰¹å¾çš„ä½ç½®ï¼Œå³ç”¨äºFPNçš„ç‰¹å¾ï¼Œå…¶å®indexä¸º0
  num_stages: 4             # æ€»å…±4ä¸ªé˜¶æ®µ

## å¯¹å®šä¹‰çš„FPNè¿›è¡Œè¯¦ç»†æè¿°
FPN:
  out_channel: 256          ## FPNé€šé“æ•°ï¼š256

### å¯¹å®šä¹‰çš„RPNHeadè¿›è¡Œæè¿°
RPNHead:
  anchor_generator:                             ## Anchorç”Ÿæˆå™¨
    aspect_ratios: [0.5,1.0,2.0]                # Anchorçš„æ¯”ä¾‹1:2,1:1,2:1
    anchor_sizes: [[32],[64],[128],[256],[512]] # Anchorçš„å°ºåº¦æ¯”ä¾‹
    strides: [4,8,16,32,64]                     # Anchorçš„æ­¥é•¿
  rpn_target_assign:                            ## RPNè®¾ç½®
    batch_size_per_im: 256                      # RPNé‡‡æ ·æ•°é‡ï¼š256
    fg_fraction: 0.5                            # æ­£åˆ™æ ·æœ¬æ•°é‡ï¼š256*0.5=128
    negative_overlap: 0.3                       # è´Ÿæ ·æœ¬IoU<0.3
    positive_overlap: 0.7                       # æ­£æ ·æœ¬IoU>0.7
    use_random: True
  train_proposal:                               ## è®­ç»ƒå»ºè®®æ¡†è®¾ç½®
    min_size: 0.0
    nms_thresh: 0.7                             # è®­ç»ƒé˜¶æ®µnmsé˜ˆå€¼
    pre_nms_top_n: 2000                         # ç¬¬ä¸€é˜¶æ®µnmsæ•°é‡
    post_nms_top_n: 1000                        # ç¬¬äºŒé˜¶æ®µnmsæ•°é‡
    topk_after_collect: True
  test_proposal:                                ## æµ‹è¯•å»ºè®®æ¡†è®¾ç½®
    min_size: 0.0
    nms_thresh: 0.7                             # æµ‹è¯•é˜¶æ®µnmsé˜ˆå€¼
    pre_nms_top_n: 1000                         # ç¬¬ä¸€é˜¶æ®µnmsæ•°é‡
    post_nms_top_n: 1000                        # ç¬¬äºŒé˜¶æ®µnmsæ•°é‡

## å¯¹å®šä¹‰çš„BBoxHeadè¿›è¡Œè¯¦ç»†æè¿°
BBoxHead:
  head: TwoFCHead                 ## ä¸¤ä¸ªFCå¤´
  roi_extractor:
    resolution: 7                 # RoIPoolingç‰¹å¾å±‚çš„å°ºåº¦7x7
    sampling_ratio: 0
    aligned: True                 # å¯ç”¨RoIAlign
  bbox_assigner: BBoxAssigner

## å¯¹BBoxHeadä¸­å®šä¹‰çš„BBoxAssignerå’ŒTwoFCHeadè¿›è¡Œè¯¦ç»†æè¿°
BBoxAssigner:
  batch_size_per_im: 512    # batchæ•°é‡ï¼š512
  bg_thresh: 0.5            # èƒŒæ™¯é˜ˆå€¼<0.5
  fg_thresh: 0.5            # å‰æ™¯é˜ˆå€¼>0.5
  fg_fraction: 0.25
  use_random: True

TwoFCHead:
  out_channel: 1024         # å…¨è¿æ¥å±‚ç‰¹å¾ç»´åº¦(åé¢ç´§è·Ÿåˆ†ç±»å’Œå›å½’å±‚):1024

## å¯¹å®šä¹‰çš„BBoxPostProcessè¿›è¡Œè¯¦ç»†æè¿°
BBoxPostProcess:
  decode: RCNNBox
  nms:
    name: MultiClassNMS
    keep_top_k: 100
    score_threshold: 0.05
    nms_threshold: 0.5

## å®šä¹‰å·¥ä½œå¹¶è¡Œåº¦
worker_num: 2


## æ•°æ®è¯»å–å’Œé¢„å¤„ç†(æ•°æ®å¢å¼ºç­‰)
TrainReader:
  sample_transforms:    # æ•°æ®é¢„å¤„ç†
  - Decode: {}
  - RandomResize: {target_size: [[640,1333],[672,1333],[704,1333],[736,1333],[768,1333],[800,1333]],interp: 2,keep_ratio: True} # å›¾ç‰‡éšæœºæ”¾å¤§
  - RandomFlip: {prob: 0.5}   # å›¾ç‰‡éšæœºç¿»è½¬
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406],std: [0.229,0.224,0.225]}  # å›¾ç‰‡å½’ä¸€åŒ–
  - Permute: {}
  batch_transforms:
  - PadBatch: {pad_to_stride: 32}
  batch_size: 1         # æ¯æ‰¹å¤§å°ºåº¦
  shuffle: true         # æ˜¯å¦æ‰“ä¹±é¡ºåº
  drop_last: true       # æœ€åä¸€ä¸ªbatchä¸æ˜¯batch_sizesæ—¶ï¼Œæ˜¯å¦å°†å¤šä½™æ•°æ®è¿›è¡Œä¸¢å¼ƒ

EvalReader:
  sample_transforms:
  - Decode: {}
  - Resize: {interp: 2,target_size:[800,1333],keep_ratio: True}
  - NormalizeImage: {is_scale: true,mean: [0.485,0.456,0.406],std:[0.229,0.224,0.225]}
  - Permute: {}
  batch_transforms:
  - PadBatch: {pad_to_stride: 32}
  batch_size: 1
  shuffle: false
  drop_last: false
  drop_empty: false

TestReader:
  sample_transforms:
  - Decode: {}
  - Resize: {interp: 2,target_size:[800,1333],keep_ratio: True}
  - NormalizeImage: {is_scale: true,mean:[0.485,0.456,0.406],std:[0.229,0.224,0.225]}
  - Permute: {}
  batch_transforms:
  - PadBatch: {pad_to_stride: 32}
  batch_size: 1
  shuffle: false
  drop_last: false


```

<br>
**è®­ç»ƒæ¨¡å‹**
`python -u .	ools	rain.py -c .\work\PCB_faster_rcnn_r50_fpn_3x_coco.yml --eval use_gpu=True`
```
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
[12/08 17:36:56] ppdet.utils.checkpoint INFO: Finish loading model weights: D:\ML\Project\PaddleDetection-release-2.3\output\PCB_faster_rcnn_r50_fpn_3x_coco .pdparams
[12/08 17:37:05] ppdet.engine INFO: Epoch: [0] [  0/593] learning_rate: 0.000250 loss_rpn_cls: 0.077478 loss_rpn_reg: 0.048770 loss_bbox_cls: 0.151260 loss_bbox_reg: 0.053664 loss: 0.331172 eta: 1 day, 10:05:31 batch_cost: 8.6236 data_cost: 0.0000 ips: 0.1160 images/s
[12/08 17:38:47] ppdet.engine INFO: Epoch: [0] [ 10/593] learning_rate: 0.000363 loss_rpn_cls: 0.087272 loss_rpn_reg: 0.061770 loss_bbox_cls: 0.217608 loss_bbox_reg: 0.207371 loss: 0.706757 eta: 1 day, 15:42:19 batch_cost: 10.1933 data_cost: 0.0002 ips: 0.0981 images/s
[12/08 17:40:51] ppdet.engine INFO: Epoch: [0] [ 20/593] learning_rate: 0.000475 loss_rpn_cls: 0.084982 loss_rpn_reg: 0.087303 loss_bbox_cls: 0.147528 loss_bbox_reg: 0.072444 loss: 0.408839 eta: 1 day, 20:04:12 batch_cost: 12.3873 data_cost: 0.0000 ips: 0.0807 images/s
[12/08 17:42:28] ppdet.engine INFO: Epoch: [0] [ 30/593] learning_rate: 0.000588 loss_rpn_cls: 0.097606 loss_rpn_reg: 0.065509 loss_bbox_cls: 0.215224 loss_bbox_reg: 0.134091 loss: 0.556537 eta: 1 day, 18:10:50 batch_cost: 9.7029 data_cost: 0.0002 ips: 0.1031 images/s
```
**å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°**
`python -u .	oolsval.py -c .\work\PCB_faster_rcnn_r50_fpn_3x_coco.yml -o weights=.\output\PCB_faster_rcnn_r50_fpn_3x_cocoest_model.pdparams use_gpu=True`
```
[12/08 17:58:43] ppdet.metrics.coco_utils INFO: Start evaluate...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.07s).
Accumulating evaluation results...
DONE (t=0.04s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.085
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.024
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.023
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.107
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.115
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.115
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
[12/08 17:58:44] ppdet.engine INFO: Total sample number: 10, averge FPS: 0.15968471430523315
```
**ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨æµ‹**
`python -u .	ools\infer.py -c .\work\PCB_faster_rcnn_r50_fpn_3x_coco.yml --infer_img=.\work\PCB_DATASET\images_missing_hole_10.jpg -o weights=.\work\output\PCB_faster_rcnn_r50_fpn_3x_cocoest_model.pdparams use_gpu=True`
æŸ¥çœ‹é¢„æµ‹åçš„å›¾ç‰‡
```
import matplotlib.pyplot as plt
import cv2

infer_img = cv2.imread("D:/ML/Project/PaddleDetection-release-2.3/output/04_missing_hole_10.jpg")
plt.figure(figsize=(15, 10))
plt.imshow(cv2.cvtColor(infer_img, cv2.COLOR_BGR2RGB))
plt.show()
```

<br>
## 2.6 è½¦ç‰Œè¯†åˆ«(PaddleOCR)
ä½¿ç”¨PaddlePaddleçš„[PaddleOCRå¼€å‘å¥—ä»¶](https://github.com/PaddlePaddle/PaddleOCR)æ¥å®Œæˆã€‚

**å®‰è£…PaddleOCRå¼€å‘å¥—ä»¶**
ä¸‹è½½PaddleOCRåŒ…ï¼Œä¸‹è½½requirementsä¸­çš„æ¨¡å— `pip install -r .equirements.txt`


**å¯¹æ•°æ®é›†è¿›è¡Œå¤„ç†**
```
import os
import cv2

ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',
       'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',
       '0', '1', '2', '3', '4', '5', '6', '7', '8,', '9', 'O']

provinces = ["çš–", "æ²ª", "æ´¥", "æ¸", "å†€", "æ™‹", "è’™", "è¾½", "å‰", "é»‘", "è‹",
             "æµ™", "äº¬", "é—½", "èµ£", "é²", "è±«", "é„‚", "æ¹˜", "ç²¤", "æ¡‚", "ç¼",
             "å·", "è´µ", "äº‘", "è—", "é™•", "ç”˜", "é’", "å®", "æ–°", "è­¦", "å­¦"]

if not os.path.exists('./img'):
    os.mkdir('./img')
## åˆ†ä¸ºè½¦ç‰Œæ£€æµ‹å’Œè½¦ç‰Œè¯†åˆ«
# è½¬æ¢æ£€æµ‹æ•°æ®
train_det = open('./train_det.txt', 'w', encoding='UTF-8')
dev_det = open('./dev_det.txt', 'w', encoding='UTF-8')

# è½¬æ¢è¯†åˆ«æ•°æ®
train_rec = open('./train_rec.txt', 'w', encoding='UTF-8')
dev_rec = open('./dev_rec.txt', 'w', encoding='UTF-8')

# æ€»æ ·æœ¬æ•°
total_num = len(os.listdir('D:\ML\Dataset\CCPD2019