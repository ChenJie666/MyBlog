---
title: 遇到的问题
categories:
- 大数据实时
---
### 问题一：
- 现象：使用Java的lambda表达式写算子的实现类
```
public class WordCount {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

//        env.setParallelism(8);
        DataStreamSource<String> source = env.readTextFile("C:\Users\CJ\Desktop\新建文本文档.txt");

        SingleOutputStreamOperator<Tuple2<String, Integer>> sum = source.flatMap((String o, Collector<Tuple2<String, Integer>> collector) -> {
            String[] arr = o.split(" ");
            for (String s : arr) {
                collector.collect(new Tuple2<>(s, 1));
            }
        }).keyBy(o -> o.f0)
                .sum(1);

        sum.print();

        env.execute();
    }
}
```
出现如下异常
```
Otherwise the type has to be specified explicitly using type information
```
- 原因：
- 解决：需要再添加一个返回值类型
```
public class WordCount {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

//        env.setParallelism(8);
        DataStreamSource<String> source = env.readTextFile("C:\Users\CJ\Desktop\新建文本文档.txt");

        SingleOutputStreamOperator<Tuple2<String, Integer>> sum = source.flatMap((String o, Collector<Tuple2<String, Integer>> collector) -> {
            String[] arr = o.split(" ");
            for (String s : arr) {
                collector.collect(new Tuple2<>(s, 1));
            }
        }).returns(Types.TUPLE(Types.STRING,Types.INT)).keyBy(o -> o.f0)
                .sum(1);

        sum.print();

        env.execute();
    }
}
```

### 问题二
- 现象：在一个Flink程序中包含了多个Sink源时，每个Sink源都会启动一个集群进行处理。
这样就会产生一个问题，就是每个程序都是相同的消费者组，即每个程序都是消费组中的一个消费者，按常理每个消费者消费一个分区，会导致每个程序都缺数据。
但是实际测试中发现，并不会因为是同一个消费者组中的消费者导致丢数据。如果非Flink Kafka Connector的同一消费者组下的消费者抢占一个或多个分区，Flink程序会有Warn告警信息，但是还是能完整读取到数据。
- 原理：推测Flink中的Kafka Connector做了优化，不同程序中的消费者都会完整读取到topic中的数据，不会因为归属于同一个消费者而丢数据。也不会被其他消费者抢占导致无法读取数据。


### 问题三
- 现象：使用Kafka Connector时，发现有一个分区的数据无法进行读取，导致Lag指标变大。
查询zookeeper发现该分区所在节点(/brokers/ids/1)的注册信息中，是hostname(该域名无法通过DNS查询)，而不是IP。
- 原理：因为该Kafka节点的配置文件server.properties中的配置使用了hostname
```
listeners=PLAINTEXT://bigdata2:9092
advertised.listeners=PLAINTEXT://bigdata2:9092
```
所以在zookeeper注册的访问地址也是bigdata2。
而远程访问数据时会到zookeeper中查询节点的访问地址，然后通过该访问地址来访问Kafka节点。访问地址错误导致无法找到该节点，也就丢失了主分区在该节点上的topic的数据。
- 解决：将bigdata2修改为IP地址，或使用真实域名。

### 问题四
- 现象：在配合Zookeeper实现Flink的高可用时，发现集群会经常重启，查询flink日志发现是Zookeeper集群的问题。
```
org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss
	at org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.KeeperException.create(KeeperException.java:102) ~[flink-shaded-zookeeper-3.4.14.jar:3.4.14-13.0]
2023-03-19 04:34:16,070 ERROR org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Fatal error occurred in ResourceManager.
org.apache.flink.runtime.resourcemanager.exceptions.ResourceManagerException: Received an error from the LeaderElectionService.
Caused by: org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss
	at org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.KeeperException.create(KeeperException.java:102) ~[flink-shaded-zookeeper-3.4.14.jar:3.4.14-13.0]
	at org.apache.flink.shaded.curator4.org.apache.curator.framework.imps.CuratorFrameworkImpl.checkBackgroundRetry(CuratorFrameworkImpl.java:862) ~[flink-shaded-zookeeper-3.4.14.jar:3.4.14-13.0]
	... 10 more
2023-03-19 04:34:16,073 ERROR org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Fatal error occurred in the cluster entrypoint.
org.apache.flink.runtime.resourcemanager.exceptions.ResourceManagerException: Received an error from the LeaderElectionService.
Caused by: org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss
	at org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.KeeperException.create(KeeperException.java:102) ~[flink-shaded-zookeeper-3.4.14.jar:3.4.14-13.0]
	at org.apache.flink.shaded.curator4.org.apache.curator.framework.imps.CuratorFrameworkImpl.checkBackgroundRetry(CuratorFrameworkImpl.java:862) ~[flink-shaded-zookeeper-3.4.14.jar:3.4.14-13.0]
	... 10 more
```
- 原理：集群网络不稳定，导致和zookeeper失联，暂时断开无法连接leadership。 如果 ZK 在一段时间内没有收到 Flink RM 的心跳 ，它会撤销领导权并通知。 查看TaskManager日志可能会获得这样的警告：
   ```
   WARN org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn - Client session timed out, have not heard from server in 40020ms for sessionid 0x404f9ca531a5d6f
   ```
   zk在切换leader或者网络抖动、机器繁忙、zk集群短暂无响应，都会导致curator将状态置为suspended.，会触发SUSPENDED状态，这个状态，会导致lost the leadership错误，而遇到这个错误，k8s直接就重启程序。

**查看zookeeper日志**
```
[2023-03-20 04:31:02,294] WARN fsync-ing the write ahead log in SyncThread:0 took 3377ms which will adversely effect operation latency. File size is 67108880 bytes. See the ZooKeeper troubleshooting guide (org.apache.zookeeper.server.persistence.FileTxnLog)
[2023-03-20 04:31:09,584] INFO Revalidating client: 0x3ef54ef710001 (org.apache.zookeeper.server.quorum.Learner)
[2023-03-20 04:31:10,279] INFO Revalidating client: 0x103ef54ef020000 (org.apache.zookeeper.server.quorum.Learner)
[2023-03-20 04:31:15,815] INFO Notification: 2 (message format version), 1 (n.leader), 0x2f00000087 (n.zxid), 0x2f (n.round), LOOKING (n.state), 1 (n.sid), 0x2f (n.peerEPoch), FOLLOWING (my state)0 (n.config version) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2023-03-20 07:28:07,259] WARN fsync-ing the write ahead log in SyncThread:0 took 8342ms which will adversely effect operation latency. File size is 67108880 bytes. See the ZooKeeper troubleshooting guide (org.apache.zookeeper.server.persistence.FileTxnLog)
[2023-03-20 08:24:14,833] WARN Exception when following the leader (org.apache.zookeeper.server.quorum.Learner)
java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.jute.BinaryInputArchive.readInt(BinaryInputArchive.java:84)
	at org.apache.zookeeper.server.quorum.QuorumPacket.deserialize(QuorumPacket.java:85)
	at org.apache.jute.BinaryInputArchive.readRecord(BinaryInputArchive.java:118)
	at org.apache.zookeeper.server.quorum.Learner.readPacket(Learner.java:158)
	at org.apache.zookeeper.server.quorum.Follower.followLeader(Follower.java:92)
	at org.apache.zookeeper.server.quorum.QuorumPeer.run(QuorumPeer.java:1253)
[2023-03-20 08:24:17,787] WARN Exception causing close of session 0x203f210cab90000: Socket closed (org.apache.zookeeper.server.NIOServerCnxn)
[2023-03-20 08:24:14,839] INFO Revalidating client: 0x103ef54ef020000 (org.apache.zookeeper.server.quorum.Learner)
[2023-03-20 08:24:14,839] WARN Unable to read additional data from client sessionid 0x103ef54ef020000, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2023-03-20 08:24:17,787] INFO shutdown called (org.apache.zookeeper.server.quorum.Learner)
java.lang.Exception: shutdown Follower
	at org.apache.zookeeper.server.quorum.Follower.shutdown(Follower.java:201)
	at org.apache.zookeeper.server.quorum.QuorumPeer.run(QuorumPeer.java:1257)
[2023-03-20 08:24:17,788] WARN Exception causing close of session 0x103ef54ef020000: Socket closed (org.apache.zookeeper.server.NIOServerCnxn)
[2023-03-20 08:24:46,928] WARN Exception causing close of session 0x0: ZooKeeperServer not running (org.apache.zookeeper.server.NIOServerCnxn)
[2023-03-20 08:24:46,935] INFO Shutting down (org.apache.zookeeper.server.SyncRequestProcessor)
[2023-03-20 08:24:47,264] WARN fsync-ing the write ahead log in SyncThread:0 took 48348ms which will adversely effect operation latency. File size is 67108880 bytes. See the ZooKeeper troubleshooting guide (org.apache.zookeeper.server.persistence.FileTxnLog)
[2023-03-20 08:24:47,265] WARN Closing connection to leader, exception during packet send (org.apache.zookeeper.server.quorum.SendAckRequestProcessor)
java.net.SocketException: Socket closed
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:118)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:155)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)
	at org.apache.zookeeper.server.quorum.Learner.writePacket(Learner.java:144)
	at org.apache.zookeeper.server.quorum.SendAckRequestProcessor.flush(SendAckRequestProcessor.java:62)
	at org.apache.zookeeper.server.SyncRequestProcessor.flush(SyncRequestProcessor.java:186)
	at org.apache.zookeeper.server.SyncRequestProcessor.run(SyncRequestProcessor.java:113)
[2023-03-20 08:24:47,265] INFO SyncRequestProcessor exited! (org.apache.zookeeper.server.SyncRequestProcessor)
[2023-03-20 08:24:47,265] WARN PeerState set to LOOKING (org.apache.zookeeper.server.quorum.QuorumPeer)
[2023-03-20 08:24:47,266] INFO LOOKING (org.apache.zookeeper.server.quorum.QuorumPeer)
[2023-03-20 08:24:47,266] INFO New election. My id =  0, proposed zxid=0x2f0000042b (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2023-03-20 08:24:47,266] INFO Notification: 2 (message format version), 0 (n.leader), 0x2f0000042b (n.zxid), 0x2f (n.round), LOOKING (n.state), 0 (n.sid), 0x2f (n.peerEPoch), LOOKING (my state)0 (n.config version) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2023-03-20 08:24:47,268] INFO Notification: 2 (message format version), 2 (n.leader), 0x2e000000dc (n.zxid), 0x2e (n.round), FOLLOWING (n.state), 1 (n.sid), 0x2f (n.peerEPoch), LOOKING (my state)0 (n.config version) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2023-03-20 08:24:47,268] INFO Notification: 2 (message format version), 2 (n.leader), 0x2e000000dc (n.zxid), 0x2e (n.round), LEADING (n.state), 2 (n.sid), 0x2f (n.peerEPoch), LOOKING (my state)0 (n.config version) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2023-03-20 08:24:47,268] INFO FOLLOWING (org.apache.zookeeper.server.quorum.QuorumPeer)
[2023-03-20 08:24:47,268] INFO minSessionTimeout set to 4000 (org.apache.zookeeper.server.ZooKeeperServer)
[2023-03-20 08:24:47,268] INFO maxSessionTimeout set to 40000 (org.apache.zookeeper.server.ZooKeeperServer)
[2023-03-20 08:24:47,268] INFO Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 datadir /opt/module/kafka_2.12-2.4.1/zookeeper/log/version-2 snapdir /opt/module/kafka_2.12-2.4.1/zookeeper/data/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2023-03-20 08:24:47,268] INFO FOLLOWING - LEADER ELECTION TOOK - 0 MS (org.apache.zookeeper.server.quorum.Learner)
[2023-03-20 08:24:47,270] WARN Unexpected exception, tries=0, remaining init limit=19999, connecting to /192.168.101.195:2888 (org.apache.zookeeper.server.quorum.Learner)
java.net.ConnectException: 拒绝连接 (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at org.apache.zookeeper.server.quorum.Learner.sockConnect(Learner.java:233)
	at org.apache.zookeeper.server.quorum.Learner.connectToLeader(Learner.java:262)
	at org.apache.zookeeper.server.quorum.Follower.followLeader(Follower.java:77)
	at org.apache.zookeeper.server.quorum.QuorumPeer.run(QuorumPeer.java:1253)
......
[2023-03-20 08:24:48,405] INFO Notification: 2 (message format version), 1 (n.leader), 0x2f0000042b (n.zxid), 0x2f (n.round), LOOKING (n.state), 1 (n.sid), 0x2f (n.peerEPoch), FOLLOWING (my state)0 (n.config version) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2023-03-20 08:24:48,405] INFO Notification: 2 (message format version), 2 (n.leader), 0x2f0000042b (n.zxid), 0x2f (n.round), LOOKING (n.state), 1 (n.sid), 0x2f (n.peerEPoch), FOLLOWING (my state)0 (n.config version) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2023-03-20 08:24:48,405] INFO Notification: 2 (message format version), 2 (n.leader), 0x2f0000042b (n.zxid), 0x2f (n.round), LOOKING (n.state), 2 (n.sid), 0x2f (n.peerEPoch), FOLLOWING (my state)0 (n.config version) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2023-03-20 08:24:49,279] INFO Getting a diff from the leader 0x2f0000042b (org.apache.zookeeper.server.quorum.Learner)
[2023-03-20 08:24:49,279] INFO Learner received NEWLEADER message (org.apache.zookeeper.server.quorum.Learner)
[2023-03-20 08:24:49,281] INFO Learner received UPTODATE message (org.apache.zookeeper.server.quorum.Learner)
```
估计异常原因：「FOLLOWER」在跟「LEADER」同步時，fsync操做時間過長，致使超時。

解决：增長「tickTime」或者「initLimit和syncLimit」的值，或者二者都增大。
```
# The number of milliseconds of each tick
tickTime=4000
# The number of ticks that the initial 
# synchronization phase can take
initLimit=20
# The number of ticks that can pass between 
# sending a request and getting an acknowledgement
syncLimit=10
```

### 问题五
- 现象：使用Lag开窗函数，存在水位线并且order by的字段存在相同值时，会导致丢失数据
- 原因：猜测是将数据存储在MapState中，orderby的字段作为key，相同的key导致先进入的数据被后面的数据覆盖。
Flink1.13.0存在的bug:：lag完全不能用，会得到错误的结果
Flink1.13.6存在的bug：lag排序字段有相同值，会导致lag到的数据有问题，不是正确的记录。
```
3> +I[IntegratedStove, 0LU98ys80fDU8TvsAAN3000000, 3167, {}, a1YTZpQDGwn, 1680235249145, 0LU98ys80fDU8TvsAAN3, {"ErrorCodeShow":{"value":15,"time":1680235249145},"ErrorCode":{"value":16384,"time":1680235249145}}, {"ErrorCodeShow":{"value":15,"time":1680235234288},"ErrorCode":{"value":16384,"time":1680235234288}}]
3> +I[IntegratedStove, 0LU98ys80fDU8TvsAAN3000000, 3177, {}, a1YTZpQDGwn, 1680235274230, 0LU98ys80fDU8TvsAAN3, {"ErrorCodeShow":{"value":0,"time":1680235274229},"ErrorCode":{"value":0,"time":1680235274229}}, {"ErrorCodeShow":{"value":0,"time":1680235274229},"ErrorCode":{"value":0,"time":1680235274229}}]
3> +I[IntegratedStove, 0LU98ys80fDU8TvsAAN3000000, 3175, {}, a1YTZpQDGwn, 1680235274230, 0LU98ys80fDU8TvsAAN3, {"ErrorCodeShow":{"value":15,"time":1680235274230},"ErrorCode":{"value":16384,"time":1680235274230}}, {"ErrorCodeShow":{"value":0,"time":1680235274229},"ErrorCode":{"value":0,"time":1680235274229}}]
```

### 问题六
- 现象：启动KafkaSink的EXCATLY_ONCE后，会报错
```
2023-04-03 14:53:04       WARN (org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase:onException) - Consumer subtask 6 failed async Kafka commit.
org.apache.kafka.clients.consumer.RetriableCommitFailedException: Offset commit failed with a retriable exception. You should retry committing the latest consumed offsets.
Caused by: org.apache.kafka.common.errors.DisconnectException
2023-04-03 14:55:56       WARN (org.apache.flink.runtime.checkpoint.CheckpointCoordinator:receiveAcknowledgeMessage) - Received late message for now expired checkpoint attempt 7 from task dde6074f653ffc36b304382e60c49716 of job 03ab02d2bfd43584307e0eb4015c7609 at 3ff7375c-9af8-4b56-8714-dde613722b49 @ 127.0.0.1 (dataPort=-1).
2023-04-03 14:56:57       WARN (org.apache.kafka.common.utils.AppInfoParser:registerAppInfo) - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id="producer-KeyedProcess -> (Sink: Unnamed, Sink: Unnamed)-62178c8ca330ae8cd73d75beef1312de-12"
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:426)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:298)
	at org.apache.flink.streaming.connectors.kafka.internals.FlinkKafkaInternalProducer.<init>(FlinkKafkaInternalProducer.java:79)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.lambda$abortTransactions$3(FlinkKafkaProducer.java:1282)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.HashMap$KeySpliterator.forEachRemaining(HashMap.java:1556)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.abortTransactions(FlinkKafkaProducer.java:1263)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.cleanUpUserContext(FlinkKafkaProducer.java:1249)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.finishRecoveringContext(FlinkKafkaProducer.java:1224)
	at org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction.initializeState(TwoPhaseCommitSinkFunction.java:380)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.initializeState(FlinkKafkaProducer.java:1195)
	at org.apache.flink.streaming.util.functions.StreamingFunctionUtils.tryRestoreFunction(StreamingFunctionUtils.java:189)
	at org.apache.flink.streaming.util.functions.StreamingFunctionUtils.restoreFunctionState(StreamingFunctionUtils.java:171)
	at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.initializeState(AbstractUdfStreamOperator.java:96)
	at org.apache.flink.streaming.api.operators.StreamOperatorStateHandler.initializeOperatorState(StreamOperatorStateHandler.java:118)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:290)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain.initializeStateAndOpenOperators(OperatorChain.java:441)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.restoreGates(StreamTask.java:585)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.call(StreamTaskActionExecutor.java:55)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.executeRestore(StreamTask.java:565)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:650)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.restore(StreamTask.java:540)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:759)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:566)
	at java.lang.Thread.run(Thread.java:748)
   ```
- 原因：
- 


### 问题七
- 现象：在修改了Flink的代码之后，从原来的checkpoint启动时报错如下
```
Caused by: java.util.concurrent.CompletionException: java.lang.IllegalStateException: Failed to rollback to checkpoint/savepoint hdfs://192.168.101.193:8020/flink/checkpoint/msas/msas_device_exceptions/bd512804dd5bce0053dc8a8e1d94f879/chk-2568. Cannot map checkpoint/savepoint state for operator ba40499bacce995f15693b1735928377 to the new program, because the operator is not available in the new program. If you want to allow to skip this, you can set the --allowNonRestoredState option on the CLI.
```
如果添加参数 --allowNonRestoredState 就可以成功启动，但是不知道状态是否成功恢复，修改的代码逻辑是否生效。
实际使用中发现，添加--allowNonRestoredState并没有造成已有的状态丢失的情况，而且修改的代码逻辑也生效了。
