---
title: 业务问题
categories:
- 大数据离线
---
## 2022-04-29
- 问题：查询数仓数据，发现在2022-04-27日的2:30和13:30的任务都没有取到更新时间为 "upobjdatetime":"2022-04-26 13:59:53" 的6条记录。
- 排查：首先查询ods层数据不存在，那么在导入数仓时就丢失了该数据。原因可能在Kafka。
查询Kafka，因为遍历Kafka效率低下，所以采用二分法通过offset来查询在2022-04-27日的2:30和13:30存储到Kafka的数据，如果数据中不存在这6条记录，那么就是没有导入Kafka或导入时出现问题。
在partiton 0的offset=3677600到offset=3677800的数据中，发现‘S2204250001350’和‘S2204250001413’是存在的，在partition 1的offset=3678000到offset=3678150中，发现'S2204250001491','S2204250001449','S2204250001349'是存在的，在partition 2的offset=3677600到offset=3677800中，发现'S2204250001490'是存在的。所以凌晨的任务没问题。
但是中午的数据却查询不到，因为中午的数据没有从edb接口查询到。
- 原因：数仓丢失6条数据，因为是2:30查询到该数据并存储到数仓中，但是13:30没有查询到数据，导致数仓中数据被覆盖掉(目前edb订单宽表是全量更新，会覆盖掉凌晨的数据)，所以丢失了该数据。正常来说13:30肯定能查询到该数据，所以需要考虑为什么没有查到数据。最后排查发现edb接口通过更新时间在凌晨时能查到数据，但是中午查询不到了；而通过订货时间在凌晨和中午都能查到数据。
- 解决：通过订货时间查询或者让edb的人改进bug。

## 2022-05-17
- 问题：注释掉两个LEFT JOIN语句，会有一条记录过滤出来，但是加上LEFT JOIN语句后，这条记录也被过滤掉了。
```
SELECT *
FROM (
         SELECT *, row_number() over (partition by id) as row_num
         FROM ods_u8.ods_rdrecord09
         WHERE ds = '2022-05-16'
     ) tmp_rdrecord09
         INNER JOIN
     (
         SELECT *, row_number() over (partition by autoid) as row_num
         FROM ods_u8.ods_rdrecords09
         WHERE ds = '2022-05-16'
     ) tmp_rdrecords09
     ON tmp_rdrecord09.id = tmp_rdrecords09.id
         LEFT JOIN  compass_dim.dim_u8_department
     ON tmp_rdrecord09.cdepcode = dim_u8_department.cdepcode
         LEFT JOIN  compass_dim.dim_u8_warehouse
     ON tmp_rdrecord09.cwhcode = dim_u8_warehouse.cwhcode
WHERE tmp_rdrecord09.row_num = 1
  and tmp_rdrecords09.row_num = 1
  and dim_u8_department.ds = '2022-05-16'
  and dim_u8_warehouse.ds = '2022-05-16'
  and autoid = '2001751324';
```
- 原因：想当然以为谓词下推会在解析时，自动将过滤条件放到子查询中，实际则是在LEFT JOIN后被该过滤条件过滤掉了，产生了INNER JOIN的效果。
使用LEFT JOIN时，要注意谨慎使用谓词下推，即将表的过滤条件放到最外面。而使用INNER JOIN时，可以使用谓词下推，将过滤条件放到最外面。

## 2022-09-16
- 问题：如下sql，[A表 left join B表] 在on后加A表的筛选条件，该筛选条件无法生效
```
SELECT *
FROM compass_dwd.dwd_trade_gl_accvouch_mi
         LEFT JOIN compass_dim.dim_pub_channel_u8_df
                   on ds = '2022-09-15'
                       and ccus_id = dim_pub_channel_u8_df.channel_level3_id
                       and account_set = 'UFDATA_001_2011'
                       and dwd_trade_gl_accvouch_mi.ccus_id in
                           ('13011', '01611', '01634', '01633', '24083', '28096', '91744', '10181', '91001');
```
- 原因：
- 解决：通过where过滤。
```
SELECT *
FROM compass_dwd.dwd_trade_gl_accvouch_mi
         LEFT JOIN compass_dim.dim_pub_channel_u8_df
                   on ds = '2022-09-15'
                       and ccus_id = dim_pub_channel_u8_df.channel_level3_id
                       and account_set = 'UFDATA_001_2011'
where dwd_trade_gl_accvouch_mi.ccus_id in
      ('13011', '01611', '01634', '01633', '24083', '28096', '91744', '10181', '91001');
```

## 2022-09-16
- 问题：建表如下。将lzo文件放到目录中，然后读取是正常的。但是Insert到该表的数据无法读取。
```
DROP TABLE IF EXISTS compass_ods.ods_umeng_uv_di;
CREATE EXTERNAL TABLE IF NOT EXISTS compass_ods.ods_umeng_uv_di
(
    line string comment '订单信息(json格式)'
) COMMENT '友盟数据表设备数据'
    PARTITIONED BY (`ds` string)
    ROW FORMAT DELIMITED FIELDS TERMINATED BY '	'
    STORED AS INPUTFORMAT
        'com.hadoop.mapred.DeprecatedLzoTextInputFormat'
        OUTPUTFORMAT
            'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
    LOCATION '/warehouse/compass/compass_ods.db/ods_umeng_uv_di';
```
- 原因：因为我们进行查询时，会根据INPUTFORMAT配置的Lzo压缩格式解析数据文件。而我们插入时，会根据OUTPUTFORMAT配置的text格式进行落盘。所以读取该表时，无法通过Lzo解析text格式文件，导致Insert的数据无法查询到。
- 解决：可以在Insert前配置文件的落盘格式为Lzo。
```
set hive.exec.compress.output=true;
set mapreduce.output.fileoutputformat.compress=true;
set mapreduce.output.fileoutputformat.compress.type=BLOCK;
set mapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec;
```
