<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Spark-Tezè°ƒä¼˜ | Hexo</title><meta name="author" content="CJ"><meta name="copyright" content="CJ"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="ä¸€ã€Spark1.1 åŸç†è¯´æ˜![åŸç†å›¾](Spark-Tezè°ƒä¼˜.assets2c85806a6494f5db82bcf806925b58a.png) è¯¦ç»†åŸç†è§ä¸Šå›¾ã€‚æˆ‘ä»¬ä½¿ç”¨spark-submitæäº¤ä¸€ä¸ªSparkä½œä¸šä¹‹åï¼Œè¿™ä¸ªä½œä¸šå°±ä¼šå¯åŠ¨ä¸€ä¸ªå¯¹åº”çš„Driverè¿›ç¨‹ã€‚æ ¹æ®ä½ ä½¿ç”¨çš„éƒ¨ç½²æ¨¡å¼ï¼ˆdeploy-modeï¼‰ä¸åŒï¼ŒDriverè¿›ç¨‹å¯èƒ½åœ¨æœ¬åœ°å¯åŠ¨ï¼Œä¹Ÿå¯èƒ½åœ¨é›†ç¾¤ä¸­æŸä¸ªå·¥ä½œèŠ‚ç‚¹ä¸Šå¯åŠ¨ã€‚Dri">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark-Tezè°ƒä¼˜">
<meta property="og:url" content="http://example.com/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1/Spark-Tez%E8%B0%83%E4%BC%98/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="ä¸€ã€Spark1.1 åŸç†è¯´æ˜![åŸç†å›¾](Spark-Tezè°ƒä¼˜.assets2c85806a6494f5db82bcf806925b58a.png) è¯¦ç»†åŸç†è§ä¸Šå›¾ã€‚æˆ‘ä»¬ä½¿ç”¨spark-submitæäº¤ä¸€ä¸ªSparkä½œä¸šä¹‹åï¼Œè¿™ä¸ªä½œä¸šå°±ä¼šå¯åŠ¨ä¸€ä¸ªå¯¹åº”çš„Driverè¿›ç¨‹ã€‚æ ¹æ®ä½ ä½¿ç”¨çš„éƒ¨ç½²æ¨¡å¼ï¼ˆdeploy-modeï¼‰ä¸åŒï¼ŒDriverè¿›ç¨‹å¯èƒ½åœ¨æœ¬åœ°å¯åŠ¨ï¼Œä¹Ÿå¯èƒ½åœ¨é›†ç¾¤ä¸­æŸä¸ªå·¥ä½œèŠ‚ç‚¹ä¸Šå¯åŠ¨ã€‚Dri">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2023-05-06T05:31:21.051Z">
<meta property="article:modified_time" content="2023-05-06T05:31:21.051Z">
<meta property="article:author" content="CJ">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1/Spark-Tez%E8%B0%83%E4%BC%98/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'å¤åˆ¶æˆåŠŸ',
    error: 'å¤åˆ¶é”™è¯¯',
    noSupport: 'æµè§ˆå™¨ä¸æ”¯æŒ'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'åˆšåˆš',
    min: 'åˆ†é’Ÿå‰',
    hour: 'å°æ—¶å‰',
    day: 'å¤©å‰',
    month: 'ä¸ªæœˆå‰'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Spark-Tezè°ƒä¼˜',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-05-06 13:31:21'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">419</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">38</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Hexo"><span class="site-name">Hexo</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Spark-Tezè°ƒä¼˜</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2023-05-06T05:31:21.051Z" title="å‘è¡¨äº 2023-05-06 13:31:21">2023-05-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2023-05-06T05:31:21.051Z" title="æ›´æ–°äº 2023-05-06 13:31:21">2023-05-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1/">å¤§æ•°æ®å»ºæ¨¡</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Spark-Tezè°ƒä¼˜"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»é‡:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="ä¸€ã€Spark"><a href="#ä¸€ã€Spark" class="headerlink" title="ä¸€ã€Spark"></a>ä¸€ã€Spark</h1><h2 id="1-1-åŸç†è¯´æ˜"><a href="#1-1-åŸç†è¯´æ˜" class="headerlink" title="1.1 åŸç†è¯´æ˜"></a>1.1 åŸç†è¯´æ˜</h2><p>![åŸç†å›¾](Spark-Tezè°ƒä¼˜.assets2c85806a6494f5db82bcf806925b58a.png)</p>
<p>è¯¦ç»†åŸç†è§ä¸Šå›¾ã€‚<br>æˆ‘ä»¬ä½¿ç”¨spark-submitæäº¤ä¸€ä¸ªSparkä½œä¸šä¹‹åï¼Œè¿™ä¸ªä½œä¸šå°±ä¼šå¯åŠ¨ä¸€ä¸ªå¯¹åº”çš„Driverè¿›ç¨‹ã€‚æ ¹æ®ä½ ä½¿ç”¨çš„éƒ¨ç½²æ¨¡å¼ï¼ˆdeploy-modeï¼‰ä¸åŒï¼ŒDriverè¿›ç¨‹å¯èƒ½åœ¨æœ¬åœ°å¯åŠ¨ï¼Œä¹Ÿå¯èƒ½åœ¨é›†ç¾¤ä¸­æŸä¸ªå·¥ä½œèŠ‚ç‚¹ä¸Šå¯åŠ¨ã€‚Driverè¿›ç¨‹æœ¬èº«ä¼šæ ¹æ®æˆ‘ä»¬è®¾ç½®çš„å‚æ•°ï¼Œå æœ‰ä¸€å®šæ•°é‡çš„å†…å­˜å’ŒCPU coreã€‚è€ŒDriverè¿›ç¨‹è¦åšçš„ç¬¬ä¸€ä»¶äº‹æƒ…ï¼Œå°±æ˜¯å‘é›†ç¾¤ç®¡ç†å™¨ï¼ˆå¯ä»¥æ˜¯Spark Standaloneé›†ç¾¤ï¼Œä¹Ÿå¯ä»¥æ˜¯å…¶ä»–çš„èµ„æºç®¡ç†é›†ç¾¤ï¼Œç¾å›¢â€¢å¤§ä¼—ç‚¹è¯„ä½¿ç”¨çš„æ˜¯YARNä½œä¸ºèµ„æºç®¡ç†é›†ç¾¤ï¼‰ç”³è¯·è¿è¡ŒSparkä½œä¸šéœ€è¦ä½¿ç”¨çš„èµ„æºï¼Œè¿™é‡Œçš„èµ„æºæŒ‡çš„å°±æ˜¯Executorè¿›ç¨‹ã€‚YARNé›†ç¾¤ç®¡ç†å™¨ä¼šæ ¹æ®æˆ‘ä»¬ä¸ºSparkä½œä¸šè®¾ç½®çš„èµ„æºå‚æ•°ï¼Œåœ¨å„ä¸ªå·¥ä½œèŠ‚ç‚¹ä¸Šï¼Œå¯åŠ¨ä¸€å®šæ•°é‡çš„Executorè¿›ç¨‹ï¼Œæ¯ä¸ªExecutorè¿›ç¨‹éƒ½å æœ‰ä¸€å®šæ•°é‡çš„å†…å­˜å’ŒCPU coreã€‚</p>
<p>Sparkæ˜¯æ ¹æ®shuffleç±»ç®—å­æ¥è¿›è¡Œstageçš„åˆ’åˆ†ã€‚å¦‚æœæˆ‘ä»¬çš„ä»£ç ä¸­æ‰§è¡Œäº†æŸä¸ªshuffleç±»ç®—å­ï¼ˆæ¯”å¦‚reduceByKeyã€joinç­‰ï¼‰ï¼Œé‚£ä¹ˆå°±ä¼šåœ¨è¯¥ç®—å­å¤„ï¼Œåˆ’åˆ†å‡ºä¸€ä¸ªstageç•Œé™æ¥ã€‚å¯ä»¥å¤§è‡´ç†è§£ä¸ºï¼Œshuffleç®—å­æ‰§è¡Œä¹‹å‰çš„ä»£ç ä¼šè¢«åˆ’åˆ†ä¸ºä¸€ä¸ªstageï¼Œshuffleç®—å­æ‰§è¡Œä»¥åŠä¹‹åçš„ä»£ç ä¼šè¢«åˆ’åˆ†ä¸ºä¸‹ä¸€ä¸ªstageã€‚å› æ­¤ä¸€ä¸ªstageåˆšå¼€å§‹æ‰§è¡Œçš„æ—¶å€™ï¼Œå®ƒçš„æ¯ä¸ªtaskå¯èƒ½éƒ½ä¼šä»ä¸Šä¸€ä¸ªstageçš„taskæ‰€åœ¨çš„èŠ‚ç‚¹ï¼Œå»é€šè¿‡ç½‘ç»œä¼ è¾“æ‹‰å–éœ€è¦è‡ªå·±å¤„ç†çš„æ‰€æœ‰keyï¼Œç„¶åå¯¹æ‹‰å–åˆ°çš„æ‰€æœ‰ç›¸åŒçš„keyä½¿ç”¨æˆ‘ä»¬è‡ªå·±ç¼–å†™çš„ç®—å­å‡½æ•°æ‰§è¡Œèšåˆæ“ä½œï¼ˆæ¯”å¦‚reduceByKey()ç®—å­æ¥æ”¶çš„å‡½æ•°ï¼‰ã€‚è¿™ä¸ªè¿‡ç¨‹å°±æ˜¯shuffleã€‚</p>
<p>taskçš„æ‰§è¡Œé€Ÿåº¦æ˜¯è·Ÿæ¯ä¸ªExecutorè¿›ç¨‹çš„CPU coreæ•°é‡æœ‰ç›´æ¥å…³ç³»çš„ã€‚ä¸€ä¸ªCPU coreåŒä¸€æ—¶é—´åªèƒ½æ‰§è¡Œä¸€ä¸ªçº¿ç¨‹ã€‚è€Œæ¯ä¸ªExecutorè¿›ç¨‹ä¸Šåˆ†é…åˆ°çš„å¤šä¸ªtaskï¼Œéƒ½æ˜¯ä»¥æ¯ä¸ªtaskä¸€æ¡çº¿ç¨‹çš„æ–¹å¼ï¼Œå¤šçº¿ç¨‹å¹¶å‘è¿è¡Œçš„ã€‚å¦‚æœCPU coreæ•°é‡æ¯”è¾ƒå……è¶³ï¼Œè€Œä¸”åˆ†é…åˆ°çš„taskæ•°é‡æ¯”è¾ƒåˆç†ï¼Œé‚£ä¹ˆé€šå¸¸æ¥è¯´ï¼Œå¯ä»¥æ¯”è¾ƒå¿«é€Ÿå’Œé«˜æ•ˆåœ°æ‰§è¡Œå®Œè¿™äº›taskçº¿ç¨‹ã€‚</p>
<p>ä»¥ä¸Šå°±æ˜¯Sparkä½œä¸šçš„åŸºæœ¬è¿è¡ŒåŸç†çš„è¯´æ˜ï¼Œå¤§å®¶å¯ä»¥ç»“åˆä¸Šå›¾æ¥ç†è§£ã€‚ç†è§£ä½œä¸šåŸºæœ¬åŸç†ï¼Œæ˜¯æˆ‘ä»¬è¿›è¡Œèµ„æºå‚æ•°è°ƒä¼˜çš„åŸºæœ¬å‰æã€‚</p>
<h2 id="1-2-è°ƒä¼˜å‚æ•°"><a href="#1-2-è°ƒä¼˜å‚æ•°" class="headerlink" title="1.2 è°ƒä¼˜å‚æ•°"></a>1.2 è°ƒä¼˜å‚æ•°</h2><p><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/configuration.html">å®˜ç½‘é…ç½®</a></p>
<table>
<thead>
<tr>
<th>å‚æ•°</th>
<th>è¯´æ˜</th>
<th>é»˜è®¤å€¼</th>
<th>æ¨èå€¼</th>
</tr>
</thead>
<tbody><tr>
<td>num-executors&#x2F;spark.executor.instances</td>
<td>è¯¥å‚æ•°ç”¨äºè®¾ç½®Sparkä½œä¸šæ€»å…±è¦ç”¨å¤šå°‘ä¸ªExecutorè¿›ç¨‹æ¥æ‰§è¡Œã€‚Driveråœ¨å‘YARNé›†ç¾¤ç®¡ç†å™¨ç”³è¯·èµ„æºæ—¶ï¼ŒYARNé›†ç¾¤ç®¡ç†å™¨ä¼šå°½å¯èƒ½æŒ‰ç…§ä½ çš„è®¾ç½®æ¥åœ¨é›†ç¾¤çš„å„ä¸ªå·¥ä½œèŠ‚ç‚¹ä¸Šï¼Œå¯åŠ¨ç›¸åº”æ•°é‡çš„Executorè¿›ç¨‹ã€‚è¿™ä¸ªå‚æ•°éå¸¸ä¹‹é‡è¦ï¼Œå¦‚æœä¸è®¾ç½®çš„è¯ï¼Œé»˜è®¤åªä¼šç»™ä½ å¯åŠ¨å°‘é‡çš„Executorè¿›ç¨‹ï¼Œæ­¤æ—¶ä½ çš„Sparkä½œä¸šçš„è¿è¡Œé€Ÿåº¦æ˜¯éå¸¸æ…¢çš„</td>
<td></td>
<td>æ¯ä¸ªSparkä½œä¸šçš„è¿è¡Œä¸€èˆ¬è®¾ç½®50~100ä¸ªå·¦å³çš„Executorè¿›ç¨‹æ¯”è¾ƒåˆé€‚ï¼Œè®¾ç½®å¤ªå°‘æˆ–å¤ªå¤šçš„Executorè¿›ç¨‹éƒ½ä¸å¥½ã€‚è®¾ç½®çš„å¤ªå°‘ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨é›†ç¾¤èµ„æºï¼›è®¾ç½®çš„å¤ªå¤šçš„è¯ï¼Œå¤§éƒ¨åˆ†é˜Ÿåˆ—å¯èƒ½æ— æ³•ç»™äºˆå……åˆ†çš„èµ„æºã€‚</td>
</tr>
<tr>
<td>executor-cores&#x2F;spark.executor.cores</td>
<td>è®¾ç½®æ¯ä¸ªExecutorè¿›ç¨‹çš„CPU coreæ•°é‡ã€‚è¿™ä¸ªå‚æ•°å†³å®šäº†æ¯ä¸ªExecutorè¿›ç¨‹å¹¶è¡Œæ‰§è¡Œtaskçº¿ç¨‹çš„èƒ½åŠ›ã€‚å› ä¸ºæ¯ä¸ªCPU coreåŒä¸€æ—¶é—´åªèƒ½æ‰§è¡Œä¸€ä¸ªtaskçº¿ç¨‹ï¼Œå› æ­¤æ¯ä¸ªExecutorè¿›ç¨‹çš„CPU coreæ•°é‡è¶Šå¤šï¼Œè¶Šèƒ½å¤Ÿå¿«é€Ÿåœ°æ‰§è¡Œå®Œåˆ†é…ç»™è‡ªå·±çš„æ‰€æœ‰taskçº¿ç¨‹ã€‚</td>
<td>Yarnæ¨¡å¼ä¸‹é»˜è®¤ä¸º1</td>
<td>2<del>4ä¸ª,num-executors * executor-coresä¸è¦è¶…è¿‡é˜Ÿåˆ—æ€»CPU coreçš„1&#x2F;3</del>1&#x2F;2</td>
</tr>
<tr>
<td>executor-memory&#x2F;spark.executor.memory</td>
<td>è¯¥å‚æ•°ç”¨äºè®¾ç½®æ¯ä¸ªExecutorè¿›ç¨‹çš„å†…å­˜ã€‚Executorå†…å­˜çš„å¤§å°ï¼Œå¾ˆå¤šæ—¶å€™ç›´æ¥å†³å®šäº†Sparkä½œä¸šçš„æ€§èƒ½ï¼Œè€Œä¸”è·Ÿå¸¸è§çš„JVM OOMå¼‚å¸¸ï¼Œä¹Ÿæœ‰ç›´æ¥çš„å…³è”ï¼›ä¸èƒ½å¤§äºcontainerçš„å†…å­˜å€¼yarn.scheduler.maximum-allocation-mb</td>
<td></td>
<td>4G<del>8G,num-executors * executor-memoryä¸è¦è¶…è¿‡é˜Ÿåˆ—æ€»å†…å­˜çš„1&#x2F;3</del>1&#x2F;2</td>
</tr>
<tr>
<td>spark.executor.memoryOverhead</td>
<td>executorå †å¤–å†…å­˜</td>
<td>é»˜è®¤å€¼æ˜¯max(384M, 0.07 Ã— spark.executor.memory)</td>
<td>1.5G</td>
</tr>
<tr>
<td>driver-memory&#x2F;spark.driver.memory</td>
<td>ç”¨äºé©±åŠ¨ç¨‹åºè¿›ç¨‹çš„å†…å­˜é‡ï¼Œå³åˆå§‹åŒ–SparkContextå†…å­˜ã€‚å¦‚æœéœ€è¦ä½¿ç”¨collectç®—å­å°†RDDçš„æ•°æ®å…¨éƒ¨æ‹‰å–åˆ°Driverä¸Šè¿›è¡Œå¤„ç†ï¼Œé‚£ä¹ˆå¿…é¡»ç¡®ä¿Driverçš„å†…å­˜è¶³å¤Ÿå¤§ï¼Œå¦åˆ™ä¼šå‡ºç°OOMå†…å­˜æº¢å‡ºçš„é—®é¢˜ã€‚</td>
<td>1G</td>
<td>2G</td>
</tr>
<tr>
<td>spark.driver.memoryOverhead</td>
<td>driverå †å¤–å†…å­˜</td>
<td>driverMemory * 0.10</td>
<td></td>
</tr>
<tr>
<td>spark.driver.cores</td>
<td>åœ¨é›†ç¾¤æ¨¡å¼ä¸‹ç®¡ç†èµ„æºæ—¶ï¼Œç”¨äºdriverç¨‹åºçš„CPUå†…æ ¸æ•°é‡ã€‚</td>
<td>1</td>
<td>ç”Ÿäº§ç¯å¢ƒä¸­è°ƒå¤§</td>
</tr>
<tr>
<td>spark.default.parallelism</td>
<td>è¯¥å‚æ•°ç”¨äºè®¾ç½®æ¯ä¸ªstageçš„é»˜è®¤taskæ•°é‡ã€‚è¿™ä¸ªå‚æ•°æä¸ºé‡è¦ï¼Œå¦‚æœä¸è®¾ç½®å¯èƒ½ä¼šç›´æ¥å½±å“ä½ çš„Sparkä½œä¸šæ€§èƒ½</td>
<td>HDFS blockå¯¹åº”ä¸€ä¸ªtaskï¼Œå³blockæ•°é‡</td>
<td>500<del>1000ï¼Œnum-executors * executor-coresçš„2</del>3å€</td>
</tr>
<tr>
<td>spark.storage.memoryFraction</td>
<td>è¯¥å‚æ•°ç”¨äºè®¾ç½®RDDæŒä¹…åŒ–æ•°æ®åœ¨Executorå†…å­˜ä¸­èƒ½å çš„æ¯”ä¾‹ï¼Œé»˜è®¤æ˜¯0.6ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œé»˜è®¤Executor 60%çš„å†…å­˜ï¼Œå¯ä»¥ç”¨æ¥ä¿å­˜æŒä¹…åŒ–çš„RDDæ•°æ®ã€‚æ ¹æ®ä½ é€‰æ‹©çš„ä¸åŒçš„æŒä¹…åŒ–ç­–ç•¥ï¼Œå¦‚æœå†…å­˜ä¸å¤Ÿæ—¶ï¼Œå¯èƒ½æ•°æ®å°±ä¸ä¼šæŒä¹…åŒ–ï¼Œæˆ–è€…æ•°æ®ä¼šå†™å…¥ç£ç›˜ã€‚</td>
<td>é»˜è®¤æ˜¯0.6</td>
<td>å¦‚æœSparkä½œä¸šä¸­ï¼Œæœ‰è¾ƒå¤šçš„RDDæŒä¹…åŒ–æ“ä½œï¼Œè¯¥å‚æ•°çš„å€¼å¯ä»¥é€‚å½“æé«˜ä¸€äº›ï¼Œä¿è¯æŒä¹…åŒ–çš„æ•°æ®èƒ½å¤Ÿå®¹çº³åœ¨å†…å­˜ä¸­ã€‚é¿å…å†…å­˜ä¸å¤Ÿç¼“å­˜æ‰€æœ‰çš„æ•°æ®ï¼Œå¯¼è‡´æ•°æ®åªèƒ½å†™å…¥ç£ç›˜ä¸­ï¼Œé™ä½äº†æ€§èƒ½ã€‚ä½†æ˜¯å¦‚æœSparkä½œä¸šä¸­çš„shuffleç±»æ“ä½œæ¯”è¾ƒå¤šï¼Œè€ŒæŒä¹…åŒ–æ“ä½œæ¯”è¾ƒå°‘ï¼Œé‚£ä¹ˆè¿™ä¸ªå‚æ•°çš„å€¼é€‚å½“é™ä½ä¸€äº›æ¯”è¾ƒåˆé€‚ã€‚æ­¤å¤–ï¼Œå¦‚æœå‘ç°ä½œä¸šç”±äºé¢‘ç¹çš„gcå¯¼è‡´è¿è¡Œç¼“æ…¢ï¼ˆé€šè¿‡spark web uiå¯ä»¥è§‚å¯Ÿåˆ°ä½œä¸šçš„gcè€—æ—¶ï¼‰ï¼Œæ„å‘³ç€taskæ‰§è¡Œç”¨æˆ·ä»£ç çš„å†…å­˜ä¸å¤Ÿç”¨ï¼Œé‚£ä¹ˆåŒæ ·å»ºè®®è°ƒä½è¿™ä¸ªå‚æ•°çš„å€¼ã€‚</td>
</tr>
<tr>
<td>spark.shuffle.memoryFraction</td>
<td>è¯¥å‚æ•°ç”¨äºè®¾ç½®shuffleè¿‡ç¨‹ä¸­ä¸€ä¸ªtaskæ‹‰å–åˆ°ä¸Šä¸ªstageçš„taskçš„è¾“å‡ºåï¼Œè¿›è¡Œèšåˆæ“ä½œæ—¶èƒ½å¤Ÿä½¿ç”¨çš„Executorå†…å­˜çš„æ¯”ä¾‹ï¼Œé»˜è®¤æ˜¯0.2ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼ŒExecutoré»˜è®¤åªæœ‰20%çš„å†…å­˜ç”¨æ¥è¿›è¡Œè¯¥æ“ä½œã€‚shuffleæ“ä½œåœ¨è¿›è¡Œèšåˆæ—¶ï¼Œå¦‚æœå‘ç°ä½¿ç”¨çš„å†…å­˜è¶…å‡ºäº†è¿™ä¸ª20%çš„é™åˆ¶ï¼Œé‚£ä¹ˆå¤šä½™çš„æ•°æ®å°±ä¼šæº¢å†™åˆ°ç£ç›˜æ–‡ä»¶ä¸­å»ï¼Œæ­¤æ—¶å°±ä¼šæå¤§åœ°é™ä½æ€§èƒ½ã€‚</td>
<td>é»˜è®¤æ˜¯0.2</td>
<td>å¦‚æœSparkä½œä¸šä¸­çš„RDDæŒä¹…åŒ–æ“ä½œè¾ƒå°‘ï¼Œshuffleæ“ä½œè¾ƒå¤šæ—¶ï¼Œå»ºè®®é™ä½æŒä¹…åŒ–æ“ä½œçš„å†…å­˜å æ¯”ï¼Œæé«˜shuffleæ“ä½œçš„å†…å­˜å æ¯”æ¯”ä¾‹ï¼Œé¿å…shuffleè¿‡ç¨‹ä¸­æ•°æ®è¿‡å¤šæ—¶å†…å­˜ä¸å¤Ÿç”¨ï¼Œå¿…é¡»æº¢å†™åˆ°ç£ç›˜ä¸Šï¼Œé™ä½äº†æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå¦‚æœå‘ç°ä½œä¸šç”±äºé¢‘ç¹çš„gcå¯¼è‡´è¿è¡Œç¼“æ…¢ï¼Œæ„å‘³ç€taskæ‰§è¡Œç”¨æˆ·ä»£ç çš„å†…å­˜ä¸å¤Ÿç”¨ï¼Œé‚£ä¹ˆåŒæ ·å»ºè®®è°ƒä½è¿™ä¸ªå‚æ•°çš„å€¼ã€‚</td>
</tr>
<tr>
<td>spark.sql.adaptive.enabled</td>
<td>å¼€å¯ spark çš„è‡ªé€‚åº”æ‰§è¡Œåï¼Œè¯¥å‚æ•°æ§åˆ¶shuffle é˜¶æ®µçš„å¹³å‡è¾“å…¥æ•°æ®å¤§å°ï¼Œé˜²æ­¢äº§ç”Ÿè¿‡å¤šçš„task</td>
<td>false</td>
<td>true</td>
</tr>
<tr>
<td>spark.sql.adaptive.shuffle.targetPostShuffleInputSize</td>
<td>åŠ¨æ€è°ƒæ•´ reduce ä¸ªæ•°çš„ partition å¤§å°ä¾æ®ã€‚å¦‚è®¾ç½® 64MBï¼Œåˆ™ reduce é˜¶æ®µæ¯ä¸ª task æœ€å°‘å¤„ç† 64MB çš„æ•°æ®ã€‚</td>
<td>64MB</td>
<td>128000000</td>
</tr>
<tr>
<td>spark.sql.shuffle.partitions</td>
<td>shuffleå¹¶å‘åº¦</td>
<td>200</td>
<td>800</td>
</tr>
<tr>
<td>spark.yarn.executor.memoryOverhead</td>
<td>executoræ‰§è¡Œçš„æ—¶å€™ï¼Œç”¨çš„å†…å­˜å¯èƒ½ä¼šè¶…è¿‡executor-memoyï¼Œæ‰€ä»¥ä¼šä¸ºexecutoré¢å¤–é¢„ç•™ä¸€éƒ¨åˆ†å†…å­˜</td>
<td>max(MEMORY_OVERHEAD_FACTOR*executorMemory, MEMORY_OVERHEAD_MIN),   é»˜è®¤MEMORY_OVERHEAD_FACTORä¸º0.1, MEMORY_OVERHEAD_MINä¸º384MB</td>
<td></td>
</tr>
<tr>
<td>spark.dynamicAllocation.enabled</td>
<td>å¼€å¯åŠ¨æ€èµ„æºé…ç½®</td>
<td>false</td>
<td>true</td>
</tr>
<tr>
<td>spark.dynamicAllocation.minExecutors</td>
<td>åŠ¨æ€åˆ†é…æœ€å°executorä¸ªæ•°ï¼Œåœ¨å¯åŠ¨æ—¶å°±ç”³è¯·å¥½çš„</td>
<td>0</td>
<td>è§†èµ„æºè€Œå®š</td>
</tr>
<tr>
<td>spark.dynamicAllocation.maxExecutors</td>
<td>å¼€å¯åŠ¨æ€èµ„æºé…ç½®</td>
<td>infinity</td>
<td>è§†èµ„æºè€Œå®š</td>
</tr>
<tr>
<td>spark.dynamicAllocation.initialExecutors</td>
<td>åŠ¨æ€åˆ†é…åˆå§‹executorä¸ªæ•°é»˜è®¤å€¼</td>
<td>spark.dynamicAllocation.minExecutors</td>
<td></td>
</tr>
<tr>
<td>spark.dynamicAllocation.executorIdleTimeout</td>
<td>å½“æŸä¸ªexecutorç©ºé—²è¶…è¿‡è¿™ä¸ªè®¾å®šå€¼ï¼Œå°±ä¼šè¢«kill</td>
<td>60s</td>
<td></td>
</tr>
<tr>
<td>spark.dynamicAllocation.cachedExecutorIdleTimeout</td>
<td>å½“æŸä¸ªç¼“å­˜æ•°æ®çš„executorç©ºé—²æ—¶é—´è¶…è¿‡è¿™ä¸ªè®¾å®šå€¼ï¼Œå°±ä¼šè¢«kill</td>
<td>infinity</td>
<td></td>
</tr>
<tr>
<td>spark.dynamicAllocation.schedulerBacklogTimeout</td>
<td>ä»»åŠ¡é˜Ÿåˆ—éç©ºï¼Œèµ„æºä¸å¤Ÿï¼Œç”³è¯·executorçš„æ—¶é—´é—´éš”</td>
<td>1s</td>
<td></td>
</tr>
<tr>
<td>spark.dynamicAllocation.sustainedSchedulerBacklogTimeout</td>
<td>åŒschedulerBacklogTimeoutï¼Œæ˜¯ç”³è¯·äº†æ–°executorä¹‹åç»§ç»­ç”³è¯·çš„é—´éš”</td>
<td>é»˜è®¤åŒschedulerBacklogTimeout</td>
<td></td>
</tr>
<tr>
<td>spark.executor.memory</td>
<td>executorå †å†…å­˜</td>
<td>1G</td>
<td>9G</td>
</tr>
<tr>
<td>spark.executor.cores</td>
<td>executoræ‹¥æœ‰çš„coreæ•°</td>
<td>1</td>
<td>3</td>
</tr>
<tr>
<td>spark.locality.wait.process</td>
<td>è¿›ç¨‹å†…ç­‰å¾…æ—¶é—´</td>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td>spark.locality.wait.node</td>
<td>èŠ‚ç‚¹å†…ç­‰å¾…æ—¶é—´</td>
<td>3</td>
<td>8</td>
</tr>
<tr>
<td>spark.locality.wait.rack</td>
<td>æœºæ¶å†…ç­‰å¾…æ—¶é—´</td>
<td>3</td>
<td>5</td>
</tr>
<tr>
<td>spark.hadoop.mapreduce.input.fileinputformat.split.minsize</td>
<td>æ§åˆ¶è¾“å…¥æ–‡ä»¶å—çš„å¤§å°ï¼Œå½±å“å¹¶è¡Œåº¦</td>
<td>3</td>
<td>5</td>
</tr>
<tr>
<td>spark.hadoop.mapreduce.input.fileinputformat.split.maxsize</td>
<td>æ§åˆ¶è¾“å…¥æ–‡ä»¶å—çš„å¤§å°ï¼Œå½±å“å¹¶è¡Œåº¦</td>
<td>3</td>
<td>5</td>
</tr>
<tr>
<td>spark.rpc.askTimeout</td>
<td>rpcè¶…æ—¶æ—¶é—´</td>
<td>10</td>
<td>1000</td>
</tr>
<tr>
<td>spark.sql.autoBroadcastJoinThreshold</td>
<td>å°è¡¨éœ€è¦broadcastçš„å¤§å°é˜ˆå€¼</td>
<td>10485760</td>
<td>33554432</td>
</tr>
<tr>
<td>spark.sql.hive.convertCTAS</td>
<td>åˆ›å»ºè¡¨æ˜¯å¦ä½¿ç”¨é»˜è®¤æ ¼å¼</td>
<td>false</td>
<td>true</td>
</tr>
<tr>
<td>spark.sql.sources.default</td>
<td>é»˜è®¤æ•°æ®æºæ ¼å¼</td>
<td>parquet</td>
<td>orc</td>
</tr>
<tr>
<td>spark.sql.files.openCostIlnBytes</td>
<td>å°æ–‡ä»¶åˆå¹¶é˜ˆå€¼</td>
<td>4194304</td>
<td>6291456</td>
</tr>
<tr>
<td>spark.sql.orc.filterPushdown</td>
<td>orcæ ¼å¼è¡¨æ˜¯å¦è°“è¯ä¸‹æ¨</td>
<td>false</td>
<td>true</td>
</tr>
<tr>
<td>spark.shuffle.sort.bypassMergeThreshold</td>
<td>shuffle read taské˜ˆå€¼ï¼Œå°äºè¯¥å€¼åˆ™shuffle writeè¿‡ç¨‹ä¸è¿›è¡Œæ’åº</td>
<td>200</td>
<td>600</td>
</tr>
<tr>
<td>spark.shuffle.io.retryWait</td>
<td>æ¯æ¬¡é‡è¯•æ‹‰å–æ•°æ®çš„ç­‰å¾…é—´éš”</td>
<td>5</td>
<td>30</td>
</tr>
<tr>
<td>spark.shuffle.io.maxRetries</td>
<td>æ‹‰å–æ•°æ®é‡è¯•æ¬¡æ•°</td>
<td>3</td>
<td>10</td>
</tr>
<tr>
<td>spark.shuffle.service.enabled</td>
<td>NodeManagerä¸­ä¸€ä¸ªé•¿æœŸè¿è¡Œçš„è¾…åŠ©æœåŠ¡ï¼Œç”¨äºæå‡Shuffleè®¡ç®—æ€§èƒ½</td>
<td>false</td>
<td>true</td>
</tr>
<tr>
<td>spark.speculation</td>
<td>å¼€å¯æ¨æµ‹æ‰§è¡Œ</td>
<td>false</td>
<td>true</td>
</tr>
<tr>
<td>spark.speculation.quantile</td>
<td>ä»»åŠ¡å»¶è¿Ÿçš„æ¯”ä¾‹ï¼Œæ¯”å¦‚å½“70%çš„taskéƒ½å®Œæˆï¼Œé‚£ä¹ˆå–ä»–ä»¬è¿è¡Œæ—¶é—´çš„ä¸­ä½æ•°è·Ÿè¿˜æœªæ‰§è¡Œå®Œçš„ä»»åŠ¡ä½œå¯¹æ¯”ã€‚å¦‚æœè¶…è¿‡1.2å€ï¼Œåˆ™å¼€å¯æ¨æµ‹æ‰§è¡Œã€‚</td>
<td></td>
<td>0.7</td>
</tr>
<tr>
<td>spark.speculation.multiplier</td>
<td>æ‹‰å–æ•°æ®é‡è¯•æ¬¡æ•°</td>
<td></td>
<td>1.2</td>
</tr>
<tr>
<td>spark.shuffle.io.maxRetries</td>
<td>æ‹‰å–æ•°æ®é‡è¯•æ¬¡æ•°</td>
<td>3</td>
<td>10</td>
</tr>
<tr>
<td>spark.shuffle.io.maxRetries</td>
<td>æ‹‰å–æ•°æ®é‡è¯•æ¬¡æ•°</td>
<td>3</td>
<td>10</td>
</tr>
<tr>
<td>spark.shuffle.io.maxRetries</td>
<td>æ‹‰å–æ•°æ®é‡è¯•æ¬¡æ•°</td>
<td>3</td>
<td>10</td>
</tr>
<tr>
<td>hive.merge.sparkfiles</td>
<td>è¾“å‡ºæ—¶æ˜¯å¦åˆå¹¶å°æ–‡ä»¶</td>
<td>false</td>
<td>true</td>
</tr>
<tr>
<td>spark.speculation</td>
<td>æ˜¯å¦å¼€å¯æ¨æµ‹æ‰§è¡Œ</td>
<td>false</td>
<td></td>
</tr>
<tr>
<td>spark.app.name</td>
<td>è®¾ç½®sparkä»»åŠ¡å</td>
<td>Hive on Spark</td>
<td></td>
</tr>
</tbody></table>
<blockquote>
<p>å¦‚æœéœ€è¦æŒ‡å®šsparkä½¿ç”¨çš„é˜Ÿåˆ—ï¼Œå¯ä»¥é€šè¿‡<code>set mapreduce.job.queuename=default</code>è¿›è¡Œè®¾ç½®ã€‚</p>
</blockquote>
<p><strong>Sparkå†…å­˜ä½¿ç”¨è¯´æ˜ï¼š</strong></p>
<ol>
<li>é€šè¿‡<code>spark.executor.memory</code>æŒ‡å®šçš„executorå€¼ä¸èƒ½å¤§äº<code>yarn.scheduler.maximum-allocation-mb</code>çš„å€¼ï¼Œå› ä¸ºexecutorè·‘åœ¨containerä¸­ï¼Œå¦‚æœè¶…è¿‡containerå†…å­˜ä¼šæŠ¥é”™å†…å­˜è¶Šç•Œã€‚å…·ä½“çš„è®¾ç½®è¿˜æ˜¯å¾—æ ¹æ®ä¸åŒéƒ¨é—¨çš„èµ„æºé˜Ÿåˆ—æ¥å®šï¼Œå¯ä»¥çœ‹çœ‹è‡ªå·±å›¢é˜Ÿçš„èµ„æºé˜Ÿåˆ—çš„æœ€å¤§å†…å­˜é™åˆ¶æ˜¯å¤šå°‘ï¼Œnum-executorsä¹˜ä»¥executor-memoryï¼Œæ˜¯ä¸èƒ½è¶…è¿‡é˜Ÿåˆ—çš„æœ€å¤§å†…å­˜é‡çš„1&#x2F;3ã€‚</li>
<li><code>spark.yarn.executor.memoryOverhead</code>ï¼šexecutoræ‰§è¡Œçš„æ—¶å€™ï¼Œç”¨çš„å†…å­˜å¯èƒ½ä¼šè¶…è¿‡executor-memoyï¼Œæ‰€ä»¥ä¼šä¸ºexecutoré¢å¤–é¢„ç•™ä¸€éƒ¨åˆ†å†…å­˜ï¼Œ<code>spark.yarn.executor.memoryOverhead</code>ä»£è¡¨äº†è¿™éƒ¨åˆ†å†…å­˜ï¼Œæ‰€ä»¥æŒ‡å®šçš„<code>spark.executor.memory+spark.yarn.executor.memoryOverhead</code>ä¸èƒ½å¤§äº<code>yarn.scheduler.maximum-allocation-mb</code>ã€‚</li>
<li>æ‰€ä»¥å½“æˆ‘ä»¬è®¾ç½®spark.executor.memoryä¸º6Gæ—¶ï¼Œç®—ä¸Šé¢„ç•™å†…å­˜ä¸€å…±ä½¿ç”¨å†…å­˜ä¸º6G*1.1ã€‚è€Œå®é™…ä½¿ç”¨äº†7168 MBï¼Œæ˜¯å› ä¸º<strong>è§„æ•´åŒ–å› å­</strong>ï¼Œå³æœ€ç»ˆä½¿ç”¨çš„å†…å­˜ä¸ºå®¹å™¨æœ€å°å†…å­˜<code>yarn.scheduler.minimum-allocation-mb</code>çš„æœ€å°æ•´æ•°å€ã€‚</li>
</ol>
<p><strong>è¾“å…¥è¾“å‡ºæ–‡ä»¶è¯´æ˜ï¼š</strong></p>
<ol>
<li>å¼€å¯org.apache.hadoop.hive.ql.io.CombineHiveInputFormatè€Œä¸é…ç½®åˆ†ç‰‡å¤§å°çš„å‚æ•°ï¼Œæ‰€æœ‰è¾“å…¥ä¼šåˆå¹¶ä¸ºä¸€ä¸ªæ–‡ä»¶ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä¸ç®¡ä½ æ•°æ®å¤šå¤§ï¼Œåªæœ‰ä¸€ä¸ªMapã€‚å¯ä»¥é€šè¿‡æœ€æ–°çš„å‚æ•°</li>
</ol>
<ul>
<li>set mapreduce.input.fileinputformat.split.maxsize&#x3D;256000000;</li>
<li>set mapreduce.input.fileinputformat.split.minsize&#x3D;100000000;<br>æ¥è®¾ç½®æœ€ç»ˆåˆå¹¶åæ–‡ä»¶çš„å¤§å°èŒƒå›´ã€‚</li>
</ul>
<p><strong>Sparkè¯»Hiveã€HDFSæ—¶çš„Taskæ•°é‡:</strong><br>sparkè¯»å–hdfsæ•°æ®æ—¶ï¼Œæœ€ç»ˆä¼šç”ŸæˆHadoopRDDï¼Œæ‰€ä»¥HadoopRDDçš„åˆ†åŒºæ•°é‡å°±æ˜¯taskæ•°é‡ã€‚<br>ä»¥sparkContext.textFileä¸ºä¾‹ï¼Œæ¥åˆ†æä¸‹HadoopRDDçš„åˆ†åŒºæ•°ã€‚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// æœ‰ä¸¤ä¸ªé‡è½½æ–¹æ³•ã€‚ä¸€ä¸ªè¦æ±‚æŒ‡å®šminPartitionsï¼Œå¦ä¸€ä¸ªä¸åšè¦æ±‚ã€‚</span><br><span class="line">def textFile(path: String): JavaRDD[String] = sc.textFile(path)</span><br><span class="line"></span><br><span class="line">// minPartitionsæ˜¯æŒ‡å¸Œæœ›è¿”å›çš„æœ€å°åˆ†åŒºæ•°ã€‚ä¹Ÿå°±è¯´è¿”å›çš„RDDåˆ†åŒºæ•°å¤§äºæˆ–è€…ç­‰äºminPartitionsã€‚</span><br><span class="line">def textFile(path: String, minPartitions: Int): JavaRDD[String] =</span><br><span class="line">    sc.textFile(path, minPartitions)</span><br></pre></td></tr></table></figure>
<p>ä¸€è·¯è·Ÿè¿›ï¼Œæœ€ç»ˆä¼šè°ƒç”¨åˆ°org.apache.hadoop.mapred.FileInputFormatçš„getSplitsæ–¹æ³•ï¼Œè¿”å›çš„splitæ•°å°±æ˜¯rddåˆ†åŒºæ•°ã€‚</p>
<p>ä»¥ä¸‹æ˜¯getSplitsæ–¹æ³•çš„å®ç°é€»è¾‘ã€‚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">    // numSplitsæ˜¯æœŸæœ›çš„åˆ†ç‰‡æ•°é‡</span><br><span class="line">    public InputSplit[] getSplits(JobConf job, int numSplits) throws IOException &#123;</span><br><span class="line">        Stopwatch sw = new Stopwatch().start();</span><br><span class="line">        // åˆ—å‡ºè¦è¯»å–çš„æ‰€æœ‰æ–‡ä»¶</span><br><span class="line">        FileStatus[] files = listStatus(job);</span><br><span class="line">        // è®¾ç½®è¾“å…¥æ–‡ä»¶çš„ä¸ªæ•°</span><br><span class="line">        job.setLong(NUM_INPUT_FILES, files.length);</span><br><span class="line">        // è®°å½•æ‰€æœ‰æ–‡ä»¶çš„æ€»å¤§å°ã€‚å­—èŠ‚</span><br><span class="line">        long totalSize = 0; // compute total size</span><br><span class="line"></span><br><span class="line">        // éå†æ‰€æœ‰æ–‡ä»¶</span><br><span class="line">        for (FileStatus file : files) &#123;// check we have valid files</span><br><span class="line">            if (file.isDirectory()) &#123;</span><br><span class="line">                throw new IOException(&quot;Not a file: &quot; + file.getPath());</span><br><span class="line">            &#125;</span><br><span class="line">            // è®¡ç®—æ‰€æœ‰æ–‡ä»¶æ€»å¤§å°</span><br><span class="line">            totalSize += file.getLen();</span><br><span class="line">        &#125;</span><br><span class="line">        // ç®—å‡ºä¸€ä¸ªåˆ†ç‰‡çš„æœŸæœ›å¤§å°ã€‚å¦‚æœæŒ‡å®šçš„åˆ†ç‰‡ä¸º0ï¼Œåˆ™ä½¿ç”¨æ€»å¤§å°é™¤ä»¥1ï¼›å¦åˆ™ç”¨æ€»å¤§å°é™¤ä»¥æœŸæœ›çš„åˆ†ç‰‡ä¸ªæ•°</span><br><span class="line">        long goalSize = totalSize / (numSplits == 0 ? 1 : numSplits);</span><br><span class="line">        // æœ€å°çš„ç‰‡å¤§å°ã€‚minSplitSize=1ï¼ŒSPLIT_MINSIZEé»˜è®¤ä¹Ÿä¸º1ï¼Œå–ä¸¤è€…ä¸­çš„æœ€å¤§å€¼ï¼›</span><br><span class="line">        long minSize = Math.max(job.getLong(org.apache.hadoop.mapreduce.lib.input.FileInputFormat.SPLIT_MINSIZE, 1), minSplitSize);</span><br><span class="line">        // åˆ›å»ºæœ€ç»ˆçš„åˆ†ç‰‡åˆ—è¡¨</span><br><span class="line">        ArrayList&lt;FileSplit&gt; splits = new ArrayList&lt;FileSplit&gt;(numSplits);</span><br><span class="line">        NetworkTopology clusterMap = new NetworkTopology();</span><br><span class="line">        // éå†æ‰€æœ‰æ–‡ä»¶ for (FileStatus file: files) &#123;</span><br><span class="line">        Path path = file.getPath();</span><br><span class="line">        // è·å–è¿™ä¸ªæ–‡ä»¶å¤§å°</span><br><span class="line">        long length = file.getLen();</span><br><span class="line">        if (length != 0) &#123;</span><br><span class="line">            FileSystem fs = path.getFileSystem(job);</span><br><span class="line">            // è·å–åˆ†ç‰‡ä½ç½®ä¿¡æ¯</span><br><span class="line">            BlockLocation[] blkLocations;</span><br><span class="line">            if (file instanceof LocatedFileStatus) &#123;</span><br><span class="line">                blkLocations = ((LocatedFileStatus) file).getBlockLocations();</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                blkLocations = fs.getFileBlockLocations(file, 0, length);</span><br><span class="line">            &#125;</span><br><span class="line">            // å¦‚æœæ–‡ä»¶æ˜¯å¯åˆ‡åˆ†æ ¼å¼çš„</span><br><span class="line">            if (isSplitable(fs, path)) &#123;</span><br><span class="line">                // è·å–æ–‡ä»¶å¤§å°</span><br><span class="line">                long blockSize = file.getBlockSize();</span><br><span class="line">                // è®¡ç®—å¾—å‡ºæœ€ç»ˆçš„åˆ†ç‰‡å¤§å°ã€‚</span><br><span class="line">                // åœ¨goalSizeå’ŒblockSizeä¸­å–è¾ƒå°çš„å€¼ä½œä¸ºç»“æœï¼Œç„¶åå»å’ŒminSizeæ¯”å¤§å°ï¼Œå–è¾ƒå¤§çš„å€¼</span><br><span class="line">                long splitSize = computeSplitSize(goalSize, minSize, blockSize);</span><br><span class="line">                // å‰©ä½™çš„å­—èŠ‚</span><br><span class="line">                long bytesRemaining = length;</span><br><span class="line">                // SPLIT_SLOP =1.1ã€‚å¦‚æœå‰©ä½™çš„å­—èŠ‚æ•°é™¤ä»¥åˆ†ç‰‡å¤§å°å¤§äº1.1ï¼Œåˆ™ç»§ç»­ç”Ÿæˆåˆ†ç‰‡</span><br><span class="line">                // å¾ªç¯ç”Ÿæˆåˆ†ç‰‡</span><br><span class="line">                while (((double) bytesRemaining) / splitSize &gt; SPLIT_SLOP) &#123;</span><br><span class="line">                    // è·å–åˆ†ç‰‡ä½ç½®</span><br><span class="line">                    String[][] splitHosts = getSplitHostsAndCachedHosts(blkLocations, length - bytesRemaining, splitSize, clusterMap);</span><br><span class="line">                    // ç”Ÿæˆæ–°çš„åˆ†ç‰‡</span><br><span class="line">                    splits.add(makeSplit(path, length - bytesRemaining, splitSize, splitHosts[0], splitHosts[1]));</span><br><span class="line">                    // æ›´æ–°å‰©ä½™å­—èŠ‚æ•°</span><br><span class="line">                    bytesRemaining -= splitSize;</span><br><span class="line">                &#125;</span><br><span class="line">                // å¦‚æœè¿˜æœ‰å‰©ä¸‹çš„å­—èŠ‚ï¼Œç”Ÿæˆç‹¬ç«‹çš„åˆ†ç‰‡</span><br><span class="line">                if (bytesRemaining != 0) &#123;</span><br><span class="line">                    String[][] splitHosts = getSplitHostsAndCachedHosts(blkLocations, length - bytesRemaining, bytesRemaining, clusterMap);</span><br><span class="line">                    splits.add(makeSplit(path, length - bytesRemaining, bytesRemaining, splitHosts[0], splitHosts[1]));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                // å¦‚æœæ–‡ä»¶ä¸å¯åˆ‡åˆ†ï¼Œåˆ™ç›´æ¥ç”Ÿæˆåˆ†ç‰‡ã€‚</span><br><span class="line">                String[][] splitHosts = getSplitHostsAndCachedHosts(blkLocations, 0, length, clusterMap);</span><br><span class="line">                splits.add(makeSplit(path, 0, length, splitHosts[0], splitHosts[1]));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            // å¦‚æœæ–‡ä»¶ä¸ºç©ºï¼Œç›´æ¥ç”Ÿæˆç©ºçš„split</span><br><span class="line">            // Create empty hosts array for zero length files</span><br><span class="line">            splits.add(makeSplit(path, 0, length, new String[0]));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    sw.stop();</span><br><span class="line">    if(LOG.isDebugEnabled()) &#123;</span><br><span class="line">        LOG.debug(&quot;Total # of splits generated by getSplits: &quot; + splits.size() + &quot;, TimeTaken: &quot; + sw.elapsedMillis());</span><br><span class="line">    &#125;</span><br><span class="line">    // è¿”å›ç”Ÿæˆçš„splitåˆ—è¡¨ </span><br><span class="line">     return splits.toArray(new FileSplit[splits.size()]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>ç»“è®ºï¼š</strong><br>å…³é”®ç‚¹ï¼šæ˜¯å¦æŒ‡å®šäº†minPartitionsã€è¯»å–çš„æ–‡ä»¶æ˜¯å¦å¯åˆ‡åˆ†</p>
<ul>
<li>æ˜¯å¦å¯åˆ‡åˆ†ï¼šå¦‚æœæ–‡ä»¶æ²¡æœ‰å‹ç¼©æˆ–è€…ä½¿ç”¨çš„æ˜¯BZip2å‹ç¼©ï¼Œåˆ™æ–‡ä»¶å¯åˆ‡åˆ†ï¼›å¦‚æœæ˜¯å…¶å®ƒå‹ç¼©æ–¹å¼ï¼Œå¦‚gzipï¼Œæ–‡ä»¶å°±ä¸å¯åˆ‡åˆ†ã€‚</li>
<li>å¦‚æœæŒ‡å®šäº†minPartitionsï¼Œä¸”è¯»å–çš„æ–‡ä»¶å¯åˆ‡åˆ†ï¼Œåˆ™è¿”å›çš„åˆ†åŒºæ•°ä¼šå¤§äºç­‰äºminPartitionsã€‚ä¼šæ ¹æ®æ–‡ä»¶çš„æ€»å¤§å°å’ŒminPartitionsè®¡ç®—å‡ºæ¥æ¯ä¸ªåˆ†åŒºçš„æœŸæœ›æ–‡ä»¶å¤§å°ï¼Œæ¥ç”Ÿæˆåˆ†åŒºã€‚</li>
<li>å¦‚æœæŒ‡å®šäº†minPartitionsï¼Œä¸”è¯»å–çš„æ–‡ä»¶ä¸å¯åˆ‡åˆ†ï¼Œè¿”å›çš„åˆ†åŒºæ•°å°±æ˜¯æ–‡ä»¶çš„ä¸ªæ•°</li>
<li>å¦‚æœæ²¡æœ‰æŒ‡å®šminPartitionsï¼Œè¿”å›çš„åˆ†åŒºæ•°å°±æ˜¯æ–‡ä»¶çš„ä¸ªæ•°ã€‚</li>
</ul>
<p>hiveä¹Ÿæ˜¯åŒç†ã€‚<br>å‚è€ƒ<a target="_blank" rel="noopener" href="https://blog.csdn.net/ifenggege/article/details/104581273">https://blog.csdn.net/ifenggege/article/details/104581273</a></p>
<br>
## 1.3 Hive-on-sparkè°ƒä¼˜æ¡ˆä¾‹
### 1.3.1 æ¡ˆä¾‹ä¸€
**æ•°æ®é‡ï¼š10g**
![image.png](Spark-Tezè°ƒä¼˜.assets\6c0bb69381e64a37bc7913e81328c0fa.png)

<p>å¯ä»¥çœ‹å‡ºï¼š</p>
<ul>
<li>éšç€æ¯ä¸ªexecutorå ç”¨çš„CPU coreæ•°å¢åŠ ï¼Œq04æŸ¥è¯¢çš„æ—¶é—´æ˜¾è‘—ä¸‹é™ï¼Œq03ä¹Ÿä¸‹é™ï¼Œä½†å¹…åº¦æ²¡é‚£ä¹ˆå¤§ã€‚</li>
</ul>
<p>æœ¬æ¬¡è°ƒä¼˜åªè®¾ç½®äº†spark.executor.memoryå’Œspark.executor.coresä¸¤ä¸ªå‚æ•°ï¼Œæ²¡æœ‰æ¶‰åŠåˆ°spark.executor.instanceså‚æ•°ï¼Œè€Œé»˜è®¤çš„spark.executor.instancesä¸º2ï¼Œä¹Ÿå°±æ˜¯æ¯ä¸ªä½œä¸šåªç”¨åˆ°2ä¸ªexecutorï¼Œå› æ­¤è¿˜æ²¡å°†æ€§èƒ½å‘æŒ¥åˆ°æœ€ä½³ã€‚</p>
<p>æ¥ä¸‹æ¥é‡‡ç”¨100gçš„æ•°æ®é‡ï¼Œå¹¶ä¸”å¢åŠ spark.executor.instanceså‚æ•°çš„è®¾ç½®ã€‚</p>
<p><strong>æ•°æ®é‡ï¼š100g</strong><br>![image.png](Spark-Tezè°ƒä¼˜.assetsabaa483f2a5453a84531128bd4cb86f.png)</p>
<p>å¯ä»¥çœ‹å‡ºï¼š</p>
<ul>
<li>è°ƒä¼˜å‰åæŸ¥è¯¢æ—¶é—´æœ‰äº†å¾ˆå¤§çš„é£è·ƒï¼›</li>
<li>å¢åŠ spark.executor.instancesè®¾ç½®é¡¹æŒ‡å®šæ¯ä¸ªä½œä¸šå ç”¨çš„executorä¸ªæ•°åæ€§èƒ½åˆæœ‰å¾ˆå¤§æå‡ï¼ˆé€šè¿‡ç›‘æ§æˆ‘ä»¬å‘ç°æ­¤æ—¶CPUåˆ©ç”¨ç‡å¹³å‡æœ‰å¥½å‡ åï¼Œç”šè‡³å¯ä»¥é«˜åˆ°ç™¾åˆ†ä¹‹ä¹åå‡ ï¼‰ï¼›</li>
</ul>
<p>è‡³æ­¤ï¼Œæˆ‘ä»¬ç»ˆäºå°†æ•´ä¸ªé›†ç¾¤æ€§èƒ½å……åˆ†å‘æŒ¥å‡ºæ¥ï¼Œè¾¾åˆ°ç›®çš„ã€‚</p>
<p>æœ€åä¸€åˆ—é…ç½®é¡¹æ˜¯æ ¹æ®ç¾å›¢æŠ€æœ¯å›¢é˜Ÿåšå®¢çš„å»ºè®®è®¾ç½®çš„ï¼Œå¯ä»¥çœ‹å‡ºæ€§èƒ½ç›¸æ¯”æˆ‘ä»¬ä¹‹å‰è‡ªå·±çš„è®¾ç½®è¿˜æ˜¯æœ‰ä¸€å®šæå‡çš„ï¼Œè‡³å°‘è¯¥åšå®¢é‡Œå»ºè®®çš„è®¾ç½®æ˜¯æ¯”è¾ƒé€šç”¨çš„ï¼Œå› æ­¤ä¹‹åæˆ‘ä»¬éƒ½é‡‡å–æœ€åä¸€åˆ—çš„è®¾ç½®æ¥è·‘TPCx-BBæµ‹è¯•ã€‚</p>
<p>æœ€åæ¥å¼ å¤§å›¾å±•ç¤ºè°ƒä¼˜å‰å’Œè°ƒä¼˜åè·‘100gæ•°æ®çš„å¯¹æ¯”ï¼š<br><img src="/Spark-Tez%E8%B0%83%E4%BC%98.assets%5C5ea9981d9c00467ca63bd55d0bdfe5e4.png" alt="image.png"></p>
<p>å¯ä»¥çœ‹å‡ºï¼š</p>
<p>ç»å¤§å¤šæ•°æŸ¥è¯¢è°ƒä¼˜å‰åæŸ¥è¯¢æ—¶é—´æœ‰äº†æå¤§çš„é£è·ƒï¼›</p>
<p>ä½†æ˜¯åƒq01&#x2F;q04&#x2F;q14â€¦è¿™å‡ ä¸ªæŸ¥è¯¢ï¼Œå¯èƒ½å› ä¸ºæŸ¥è¯¢æ¶‰åŠåˆ°çš„è¡¨æ¯”è¾ƒå°ï¼Œè°ƒä¼˜å‰æ—¶é—´å°±å¾ˆçŸ­ï¼Œå› æ­¤è°ƒä¼˜åä¹Ÿçœ‹ä¸å‡ºå¾ˆå¤šå·®åˆ«ï¼Œå¦‚æœæƒ³çœ‹åˆ°å¤§çš„å·®åˆ«ï¼Œå¯èƒ½éœ€è¦æé«˜æ•°æ®é‡ï¼Œæ¯”å¦‚1Tï¼Œ3Tï¼›</p>
<p>q10å’Œq18è°ƒä¼˜å‰åæ—¶é—´éƒ½è¾ƒé•¿ï¼Œè€Œä¸”è°ƒä¼˜åæ€§èƒ½æ²¡æœ‰æå‡ï¼Œéœ€è¦å†æ·±å…¥æ¢ç´¢ä¸‹æ˜¯ä»€ä¹ˆåŸå› ã€‚</p>
<p>æœ€åï¼Œç”¨è°ƒä¼˜åçš„é›†ç¾¤ï¼Œåˆ†åˆ«è·‘10gã€30gã€100gçš„æ•°æ®ï¼Œç»“æœå¦‚ä¸‹ï¼š<br><img src="/Spark-Tez%E8%B0%83%E4%BC%98.assets%5C4dfd60fa1b024adc87024c193ab12c98.png" alt="image.png"></p>
<p>å¯ä»¥çœ‹å‡ºï¼š</p>
<ul>
<li>éšç€æ•°æ®é‡å¢å¤§ï¼Œå¾ˆå¤šæŸ¥è¯¢æ—¶é—´å¹¶æ²¡æœ‰æ˜æ˜¾å¢åŠ ï¼Œå¯èƒ½æ˜¯å› ä¸ºé›†ç¾¤æ€§èƒ½å¤ªå¼ºï¼Œè€Œä¸”æ•°æ®é‡è¿˜ä¸å¤Ÿå¤§ï¼Œå¯ä»¥å¢å¤§æ•°æ®é‡ç»§ç»­è§‚å¯Ÿ</li>
<li>å¯¹äºq10ã€q18å’Œq30ï¼Œéšç€æ•°æ®é‡å¢å¤§ï¼Œæ—¶é—´æ˜æ˜¾å¢å¤§ï¼Œéœ€å†æ·±å…¥åˆ†æ</li>
</ul>
<h3 id="1-3-2-æ¡ˆä¾‹äºŒï¼šGroupByå¯¼è‡´çš„æ•°æ®å€¾æ–œä¼˜åŒ–"><a href="#1-3-2-æ¡ˆä¾‹äºŒï¼šGroupByå¯¼è‡´çš„æ•°æ®å€¾æ–œä¼˜åŒ–" class="headerlink" title="1.3.2 æ¡ˆä¾‹äºŒï¼šGroupByå¯¼è‡´çš„æ•°æ®å€¾æ–œä¼˜åŒ–"></a>1.3.2 æ¡ˆä¾‹äºŒï¼šGroupByå¯¼è‡´çš„æ•°æ®å€¾æ–œä¼˜åŒ–</h3><h4 id="æ•°æ®å€¾æ–œé—®é¢˜"><a href="#æ•°æ®å€¾æ–œé—®é¢˜" class="headerlink" title="æ•°æ®å€¾æ–œé—®é¢˜"></a>æ•°æ®å€¾æ–œé—®é¢˜</h4><p>é€šå¸¸æ˜¯æŒ‡å‚ä¸è®¡ç®—çš„æ•°æ®åˆ†å¸ƒä¸å‡ï¼Œå³æŸä¸ªkeyæˆ–è€…æŸäº›keyçš„æ•°æ®é‡è¿œè¶…å…¶ä»–keyï¼Œå¯¼è‡´åœ¨shuffleé˜¶æ®µï¼Œå¤§é‡ç›¸åŒkeyçš„æ•°æ®è¢«å‘å¾€ä¸€ä¸ªReduceï¼Œè¿›è€Œå¯¼è‡´è¯¥Reduceæ‰€éœ€çš„æ—¶é—´è¿œè¶…å…¶ä»–Reduceï¼Œæˆä¸ºæ•´ä¸ªä»»åŠ¡çš„ç“¶é¢ˆã€‚<br>Hiveä¸­çš„æ•°æ®å€¾æ–œå¸¸å‡ºç°åœ¨åˆ†ç»„èšåˆå’Œjoinæ“ä½œçš„åœºæ™¯ä¸­ï¼Œä¸‹é¢åˆ†åˆ«ä»‹ç»åœ¨ä¸Šè¿°ä¸¤ç§åœºæ™¯ä¸‹çš„ä¼˜åŒ–æ€è·¯ã€‚</p>
<p><strong>ç¤ºä¾‹SQLè¯­å¥å¦‚ä¸‹</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    province_id,</span><br><span class="line">    count(*)</span><br><span class="line">from dwd_trade_order_detail_inc</span><br><span class="line">where dt=&#x27;2020-06-16&#x27;</span><br><span class="line">group by province_id;</span><br></pre></td></tr></table></figure>
<p><strong>ä¼˜åŒ–å‰çš„æ‰§è¡Œè®¡åˆ’</strong><br><img src="/Spark-Tez%E8%B0%83%E4%BC%98.assets%5C32617fd55b04430c821ac738e4eaf758.png" alt="image.png"></p>
<br>
#### ä¼˜åŒ–æ€è·¯
ç”±åˆ†ç»„èšåˆå¯¼è‡´çš„æ•°æ®å€¾æ–œé—®é¢˜ä¸»è¦æœ‰ä»¥ä¸‹ä¸¤ç§ä¼˜åŒ–æ€è·¯ï¼š
**1ï¼‰å¯ç”¨map-sideèšåˆ**
- 1. å¯ç”¨map-sideèšåˆ `set hive.map.aggr=true;`
- 2. hash mapå ç”¨mapç«¯å†…å­˜çš„æœ€å¤§æ¯”ä¾‹ `set hive.map.aggr.hash.percentmemory=0.5;`

<p>å¯ç”¨map-sideèšåˆåçš„æ‰§è¡Œè®¡åˆ’å¦‚ä¸‹å›¾æ‰€ç¤º<br><img src="/Spark-Tez%E8%B0%83%E4%BC%98.assets%5C73261bed766b48538f2573d11c746ee7.png" alt="image.png"></p>
<p><strong>2ï¼‰å¯ç”¨skew groupbyä¼˜åŒ–</strong><br>å…¶åŸç†æ˜¯å¯åŠ¨ä¸¤ä¸ªMRä»»åŠ¡ï¼Œç¬¬ä¸€ä¸ªMRæŒ‰ç…§éšæœºæ•°åˆ†åŒºï¼Œå°†æ•°æ®åˆ†æ•£å‘é€åˆ°Reduceï¼Œå®Œæˆéƒ¨åˆ†èšåˆï¼Œç¬¬äºŒä¸ªMRæŒ‰ç…§åˆ†ç»„å­—æ®µåˆ†åŒºï¼Œå®Œæˆæœ€ç»ˆèšåˆã€‚<br>ç›¸å…³å‚æ•°å¦‚ä¸‹ï¼š</p>
<ul>
<li>å¯ç”¨åˆ†ç»„èšåˆæ•°æ®å€¾æ–œä¼˜åŒ–<br><code>set hive.groupby.skewindata=true;</code></li>
</ul>
<p>å¯ç”¨skew groupbyä¼˜åŒ–åçš„æ‰§è¡Œè®¡åˆ’å¦‚ä¸‹å›¾æ‰€ç¤º<br><img src="/Spark-Tez%E8%B0%83%E4%BC%98.assets%5C41e29e53a65f4cde9a80c813525ba68f.png" alt="image.png"></p>
<h3 id="1-3-3-æ¡ˆä¾‹ä¸‰ï¼šJOINå¯¼è‡´çš„æ•°æ®å€¾æ–œä¼˜åŒ–"><a href="#1-3-3-æ¡ˆä¾‹ä¸‰ï¼šJOINå¯¼è‡´çš„æ•°æ®å€¾æ–œä¼˜åŒ–" class="headerlink" title="1.3.3 æ¡ˆä¾‹ä¸‰ï¼šJOINå¯¼è‡´çš„æ•°æ®å€¾æ–œä¼˜åŒ–"></a>1.3.3 æ¡ˆä¾‹ä¸‰ï¼šJOINå¯¼è‡´çš„æ•°æ®å€¾æ–œä¼˜åŒ–</h3><p><strong>ç¤ºä¾‹SQLå¦‚ä¸‹</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from</span><br><span class="line">(</span><br><span class="line">    select</span><br><span class="line">        *</span><br><span class="line">    from dwd_trade_order_detail_inc</span><br><span class="line">    where dt=&#x27;2020-06-16&#x27;</span><br><span class="line">)fact</span><br><span class="line">join</span><br><span class="line">(</span><br><span class="line">    select</span><br><span class="line">        *</span><br><span class="line">    from dim_province_full</span><br><span class="line">    where dt=&#x27;2020-06-16&#x27;</span><br><span class="line">)dim</span><br><span class="line">on fact.province_id=dim.id;</span><br></pre></td></tr></table></figure>
<p><strong>ä¼˜åŒ–å‰çš„æ‰§è¡Œè®¡åˆ’</strong><br>![image.png](Spark-Tezè°ƒä¼˜.assets5727bfca68e4938a8406b93e960ae0b.png)</p>
<h4 id="ä¼˜åŒ–æ€è·¯"><a href="#ä¼˜åŒ–æ€è·¯" class="headerlink" title="ä¼˜åŒ–æ€è·¯"></a>ä¼˜åŒ–æ€è·¯</h4><p>ç”±joinå¯¼è‡´çš„æ•°æ®å€¾æ–œé—®é¢˜ä¸»è¦æœ‰ä»¥ä¸‹ä¸¤ç§ä¼˜åŒ–æ€è·¯ï¼š<br><strong>1ï¼‰ä½¿ç”¨map joinä¼˜åŒ–</strong><br>ç›¸å…³å‚æ•°å¦‚ä¸‹ï¼š</p>
<ul>
<li>å¯ç”¨map joinè‡ªåŠ¨è½¬æ¢<br><code>set hive.auto.convert.join=true;</code></li>
<li>common joinè½¬map joinå°è¡¨é˜ˆå€¼<br><code>set hive.auto.convert.join.noconditionaltask.size</code></li>
</ul>
<p>ä½¿ç”¨map joinä¼˜åŒ–åæ‰§è¡Œè®¡åˆ’å¦‚ä¸‹å›¾<br>![image.png](Spark-Tezè°ƒä¼˜.assetsc80b1dce354297ba115d056918a504.png)</p>
<p><strong>2ï¼‰å¯ç”¨skew joinä¼˜åŒ–</strong><br>å…¶åŸç†å¦‚ä¸‹å›¾<br>![image.png](Spark-Tezè°ƒä¼˜.assetsfaf784b2c3f4028ba2d5d2fa006edfe.png)</p>
<p>ç›¸å…³å‚æ•°å¦‚ä¸‹ï¼š</p>
<ul>
<li>å¯ç”¨skew joinä¼˜åŒ–<br><code>set hive.optimize.skewjoin=true;</code></li>
<li>è§¦å‘skew joinçš„é˜ˆå€¼ï¼Œè‹¥æŸä¸ªkeyçš„è¡Œæ•°è¶…è¿‡è¯¥å‚æ•°å€¼ï¼Œåˆ™è§¦å‘<br><code>set hive.skewjoin.key=100000;</code><br>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ<strong>skew joinåªæ”¯æŒInner Join</strong>ã€‚</li>
</ul>
<p>å¯åŠ¨skew joinä¼˜åŒ–åçš„æ‰§è¡Œè®¡åˆ’å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š<br>![image.png](Spark-Tezè°ƒä¼˜.assets441d3fcd24e4456ad16395e1d5847ba.png)</p>
<br>
## 1.4 å¸¸ç”¨é…ç½®
### 1.4.1 ä»»åŠ¡å¹¶è¡Œåº¦ä¼˜åŒ–
**ä¼˜åŒ–è¯´æ˜**
å¯¹äºä¸€ä¸ªåˆ†å¸ƒå¼çš„è®¡ç®—ä»»åŠ¡è€Œè¨€ï¼Œè®¾ç½®ä¸€ä¸ªåˆé€‚çš„å¹¶è¡Œåº¦ååˆ†é‡è¦ã€‚åœ¨Hiveä¸­ï¼Œæ— è®ºå…¶è®¡ç®—å¼•æ“æ˜¯ä»€ä¹ˆï¼Œæ‰€æœ‰çš„è®¡ç®—ä»»åŠ¡éƒ½å¯åˆ†ä¸ºMapé˜¶æ®µå’ŒReduceé˜¶æ®µã€‚æ‰€ä»¥å¹¶è¡Œåº¦çš„è°ƒæ•´ï¼Œä¹Ÿå¯ä»ä¸Šè¿°ä¸¤ä¸ªæ–¹é¢è¿›è¡Œè°ƒæ•´ã€‚

<h4 id="1-4-1-1-Mapé˜¶æ®µå¹¶è¡Œåº¦"><a href="#1-4-1-1-Mapé˜¶æ®µå¹¶è¡Œåº¦" class="headerlink" title="1.4.1.1 Mapé˜¶æ®µå¹¶è¡Œåº¦"></a>1.4.1.1 Mapé˜¶æ®µå¹¶è¡Œåº¦</h4><p>Mapç«¯çš„å¹¶è¡Œåº¦ï¼Œä¹Ÿå°±æ˜¯Mapçš„ä¸ªæ•°ã€‚æ˜¯ç”±è¾“å…¥æ–‡ä»¶çš„åˆ‡ç‰‡æ•°å†³å®šçš„ã€‚ä¸€èˆ¬æƒ…å†µä¸‹ï¼ŒMapç«¯çš„å¹¶è¡Œåº¦æ— éœ€æ‰‹åŠ¨è°ƒæ•´ã€‚Mapç«¯çš„å¹¶è¡Œåº¦ç›¸å…³å‚æ•°å¦‚ä¸‹ï¼š</p>
<ul>
<li><p>å¯å°†å¤šä¸ªå°æ–‡ä»¶åˆ‡ç‰‡ï¼Œåˆå¹¶ä¸ºä¸€ä¸ªåˆ‡ç‰‡ï¼Œè¿›è€Œç”±ä¸€ä¸ªmapä»»åŠ¡å¤„ç†<br><code>set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</code></p>
</li>
<li><p>ä¸€ä¸ªåˆ‡ç‰‡çš„æœ€å¤§å€¼<br><code>set mapreduce.input.fileinputformat.split.maxsize=256000000;</code></p>
</li>
</ul>
<h4 id="1-4-1-2-Reduceé˜¶æ®µå¹¶è¡Œåº¦"><a href="#1-4-1-2-Reduceé˜¶æ®µå¹¶è¡Œåº¦" class="headerlink" title="1.4.1.2 Reduceé˜¶æ®µå¹¶è¡Œåº¦"></a>1.4.1.2 Reduceé˜¶æ®µå¹¶è¡Œåº¦</h4><p>Reduceç«¯çš„å¹¶è¡Œåº¦ï¼Œç›¸å¯¹æ¥è¯´ï¼Œæ›´éœ€è¦å…³æ³¨ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒHiveä¼šæ ¹æ®Reduceç«¯è¾“å…¥æ•°æ®çš„å¤§å°ï¼Œä¼°ç®—ä¸€ä¸ªReduceå¹¶è¡Œåº¦ã€‚ä½†æ˜¯åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå…¶ä¼°è®¡å€¼ä¸ä¸€å®šæ˜¯æœ€åˆé€‚çš„ï¼Œæ•…éœ€è¦äººä¸ºè°ƒæ•´å…¶å¹¶è¡Œåº¦ã€‚</p>
<p>Reduceå¹¶è¡Œåº¦ç›¸å…³å‚æ•°å¦‚ä¸‹ï¼š</p>
<ul>
<li>æŒ‡å®šReduceç«¯å¹¶è¡Œåº¦ï¼Œé»˜è®¤å€¼ä¸º-1ï¼Œè¡¨ç¤ºç”¨æˆ·æœªæŒ‡å®š<br><code>set mapreduce.job.reduces;</code></li>
<li>Reduceç«¯å¹¶è¡Œåº¦æœ€å¤§å€¼<br><code>set hive.exec.reducers.max;</code></li>
<li>å•ä¸ªReduceÂ Taskè®¡ç®—çš„æ•°æ®é‡ï¼Œç”¨äºä¼°ç®—Reduceå¹¶è¡Œåº¦<br><code>set hive.exec.reducers.bytes.per.reducer;</code></li>
</ul>
<p>Reduceç«¯å¹¶è¡Œåº¦çš„ç¡®å®šé€»è¾‘ä¸ºï¼Œè‹¥æŒ‡å®šå‚æ•°mapreduce.job.reducesçš„å€¼ä¸ºä¸€ä¸ªéè´Ÿæ•´æ•°ï¼Œåˆ™Reduceå¹¶è¡Œåº¦ä¸ºæŒ‡å®šå€¼ã€‚å¦åˆ™ï¼ŒHiveä¼šè‡ªè¡Œä¼°ç®—Reduceå¹¶è¡Œåº¦ï¼Œä¼°ç®—é€»è¾‘å¦‚ä¸‹ï¼š<br>å‡è®¾Reduceç«¯è¾“å…¥çš„æ•°æ®é‡å¤§å°ä¸ºtotalInputBytes<br>å‚æ•°hive.exec.reducers.bytes.per.reducerçš„å€¼ä¸ºbytesPerReducer<br>å‚æ•°hive.exec.reducers.maxçš„å€¼ä¸ºmaxReducers<br>åˆ™Reduceç«¯çš„å¹¶è¡Œåº¦ä¸ºï¼š<br><img src="/Spark-Tez%E8%B0%83%E4%BC%98.assets%5Cd30fa7f09dca412994ba22aa62a3bb82.png" alt="image.png"></p>
<p>å…¶ä¸­ï¼ŒReduceç«¯è¾“å…¥çš„æ•°æ®é‡å¤§å°ï¼Œæ˜¯ä»Reduceä¸Šæ¸¸çš„Operatorçš„Statisticsï¼ˆç»Ÿè®¡ä¿¡æ¯ï¼‰ä¸­è·å–çš„ã€‚ä¸ºä¿è¯Hiveèƒ½è·å¾—å‡†ç¡®çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œéœ€é…ç½®å¦‚ä¸‹å‚æ•°ï¼š</p>
<ul>
<li>æ‰§è¡ŒDMLè¯­å¥æ—¶ï¼Œæ”¶é›†è¡¨çº§åˆ«çš„ç»Ÿè®¡ä¿¡æ¯<br><code>setÂ hive.stats.autogather=true;</code></li>
<li>æ‰§è¡ŒDMLè¯­å¥æ—¶ï¼Œæ”¶é›†å­—æ®µçº§åˆ«çš„ç»Ÿè®¡ä¿¡æ¯<br><code>set hive.stats.column.autogather=true;</code></li>
<li>è®¡ç®—Reduceå¹¶è¡Œåº¦æ—¶ï¼Œä»ä¸Šæ¸¸Operatorç»Ÿè®¡ä¿¡æ¯è·å¾—è¾“å…¥æ•°æ®é‡<br><code>set hive.spark.use.op.stats=true;</code></li>
<li>è®¡ç®—Reduceå¹¶è¡Œåº¦æ—¶ï¼Œä½¿ç”¨åˆ—çº§åˆ«çš„ç»Ÿè®¡ä¿¡æ¯ä¼°ç®—è¾“å…¥æ•°æ®é‡<br><code>set hive.stats.fetch.column.stats=true;</code></li>
</ul>
<h3 id="1-4-2-å°æ–‡ä»¶åˆå¹¶ä¼˜åŒ–"><a href="#1-4-2-å°æ–‡ä»¶åˆå¹¶ä¼˜åŒ–" class="headerlink" title="1.4.2 å°æ–‡ä»¶åˆå¹¶ä¼˜åŒ–"></a>1.4.2 å°æ–‡ä»¶åˆå¹¶ä¼˜åŒ–</h3><h4 id="1-4-2-1-ä¼˜åŒ–è¯´æ˜"><a href="#1-4-2-1-ä¼˜åŒ–è¯´æ˜" class="headerlink" title="1.4.2.1 ä¼˜åŒ–è¯´æ˜"></a>1.4.2.1 ä¼˜åŒ–è¯´æ˜</h4><p>å°æ–‡ä»¶åˆå¹¶ä¼˜åŒ–ï¼Œåˆ†ä¸ºä¸¤ä¸ªæ–¹é¢ï¼Œåˆ†åˆ«æ˜¯Mapç«¯è¾“å…¥çš„å°æ–‡ä»¶åˆå¹¶ï¼Œå’ŒReduceç«¯è¾“å‡ºçš„å°æ–‡ä»¶åˆå¹¶ã€‚</p>
<h4 id="1-4-2-2-Mapç«¯è¾“å…¥æ–‡ä»¶åˆå¹¶"><a href="#1-4-2-2-Mapç«¯è¾“å…¥æ–‡ä»¶åˆå¹¶" class="headerlink" title="1.4.2.2 Mapç«¯è¾“å…¥æ–‡ä»¶åˆå¹¶"></a>1.4.2.2 Mapç«¯è¾“å…¥æ–‡ä»¶åˆå¹¶</h4><p>åˆå¹¶Mapç«¯è¾“å…¥çš„å°æ–‡ä»¶ï¼Œæ˜¯æŒ‡å°†å¤šä¸ªå°æ–‡ä»¶åˆ’åˆ†åˆ°ä¸€ä¸ªåˆ‡ç‰‡ä¸­ï¼Œè¿›è€Œç”±ä¸€ä¸ªMap Taskå»å¤„ç†ã€‚ç›®çš„æ˜¯é˜²æ­¢ä¸ºå•ä¸ªå°æ–‡ä»¶å¯åŠ¨ä¸€ä¸ªMap Taskï¼Œæµªè´¹è®¡ç®—èµ„æºã€‚<br>ç›¸å…³å‚æ•°ä¸ºï¼š</p>
<ul>
<li>å¯å°†å¤šä¸ªå°æ–‡ä»¶åˆ‡ç‰‡ï¼Œåˆå¹¶ä¸ºä¸€ä¸ªåˆ‡ç‰‡ï¼Œè¿›è€Œç”±ä¸€ä¸ªmapä»»åŠ¡å¤„ç†<br><code>set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat; </code></li>
</ul>
<h4 id="1-4-2-3-Reduceè¾“å‡ºæ–‡ä»¶åˆå¹¶"><a href="#1-4-2-3-Reduceè¾“å‡ºæ–‡ä»¶åˆå¹¶" class="headerlink" title="1.4.2.3 Reduceè¾“å‡ºæ–‡ä»¶åˆå¹¶"></a>1.4.2.3 Reduceè¾“å‡ºæ–‡ä»¶åˆå¹¶</h4><p>åˆå¹¶Reduceç«¯è¾“å‡ºçš„å°æ–‡ä»¶ï¼Œæ˜¯æŒ‡å°†å¤šä¸ªå°æ–‡ä»¶åˆå¹¶æˆå¤§æ–‡ä»¶ã€‚ç›®çš„æ˜¯å‡å°‘HDFSå°æ–‡ä»¶æ•°é‡ã€‚<br>ç›¸å…³å‚æ•°ä¸ºï¼š</p>
<ul>
<li>å¼€å¯åˆå¹¶Hive on Sparkä»»åŠ¡è¾“å‡ºçš„å°æ–‡ä»¶<br><code>set hive.merge.sparkfiles=true;</code></li>
</ul>
<h4 id="1-4-2-4-ä»HDFSè¯»å–æ•°æ®çš„ä»»åŠ¡åˆ‡åˆ†"><a href="#1-4-2-4-ä»HDFSè¯»å–æ•°æ®çš„ä»»åŠ¡åˆ‡åˆ†" class="headerlink" title="1.4.2.4 ä»HDFSè¯»å–æ•°æ®çš„ä»»åŠ¡åˆ‡åˆ†"></a>1.4.2.4 ä»HDFSè¯»å–æ•°æ®çš„ä»»åŠ¡åˆ‡åˆ†</h4><p>Sparkä»HDFSä¸­è¯»å–æ•°æ®ï¼Œä¼šå…ˆåˆå¹¶å°æ–‡ä»¶ï¼Œç„¶åè¿›è¡Œå¯¼å…¥ï¼Œé»˜è®¤æŒ‰Blockå¤§å°åˆ‡åˆ†ä¸ºå¤šä¸ªHadoopRDDï¼Œæ¯ä¸ªRDDå¯¹åº”ä¸€ä¸ªtaskã€‚å¦‚æœå¸Œæœ›èƒ½åˆ‡åˆ†æ›´å¤štaskï¼Œå¯ä»¥é€šè¿‡å¦‚ä¸‹è®¾ç½®é…ç½®æ¯ä¸ªåˆ†å—å¤§å°ï¼Œå•ä½ä¸ºByteã€‚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapreduce.input.fileinputformat.split.maxsize=10000000;</span><br></pre></td></tr></table></figure>

<h2 id="1-4-3-Sparkæ‰§è¡Œèµ„æºé…ç½®"><a href="#1-4-3-Sparkæ‰§è¡Œèµ„æºé…ç½®" class="headerlink" title="1.4.3 Sparkæ‰§è¡Œèµ„æºé…ç½®"></a>1.4.3 Sparkæ‰§è¡Œèµ„æºé…ç½®</h2><p>hive on sparkå‚æ•°é…ç½®ï¼ˆé™æ€åˆ†é…instanceï¼‰</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> spark.app.name<span class="operator">=</span><span class="string">&#x27;$&#123;filename&#125;&#x27;</span>;</span><br><span class="line"><span class="keyword">set</span> mapreduce.job.queuename<span class="operator">=</span>job;</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span> hive.execution.engine<span class="operator">=</span>spark;</span><br><span class="line"><span class="keyword">set</span> spark.executor.instances<span class="operator">=</span><span class="number">4</span>;</span><br><span class="line"><span class="keyword">set</span> spark.executor.cores<span class="operator">=</span><span class="number">3</span>;</span><br><span class="line"><span class="keyword">set</span> spark.executor.memory<span class="operator">=</span><span class="number">6</span>G;</span><br><span class="line"><span class="keyword">set</span> spark.driver.memory<span class="operator">=</span><span class="number">819</span>m;</span><br><span class="line"><span class="keyword">set</span> spark.driver.memoryOverhead<span class="operator">=</span><span class="number">205</span>m;</span><br><span class="line"><span class="keyword">set</span> spark.default.parallelism<span class="operator">=</span><span class="number">30</span>;</span><br><span class="line"><span class="keyword">set</span> spark.sql.shuffle.partitions<span class="operator">=</span><span class="number">30</span>;</span><br><span class="line"><span class="keyword">set</span> mapreduce.input.fileinputformat.split.maxsize<span class="operator">=</span><span class="number">10000000</span>;</span><br><span class="line"><span class="keyword">set</span> spark.serializer<span class="operator">=</span>org.apache.spark.serializer.KryoSerializer;</span><br><span class="line"><span class="keyword">set</span> hive.merge.sparkfiles<span class="operator">=</span><span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

<p>hive on sparkå‚æ•°é…ç½®ï¼ˆåŠ¨æ€åˆ†é…instanceï¼‰</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- å¯åŠ¨åŠ¨æ€åˆ†é…</span></span><br><span class="line"><span class="keyword">set</span> spark.dynamicAllocation.enabled<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="comment">-- å¯ç”¨Spark shuffleæœåŠ¡</span></span><br><span class="line"><span class="keyword">set</span> spark.shuffle.service.enabled<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="comment">-- Executorä¸ªæ•°åˆå§‹å€¼</span></span><br><span class="line"><span class="keyword">set</span> spark.dynamicAllocation.initialExecutors<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line"><span class="comment">-- Executorä¸ªæ•°æœ€å°å€¼</span></span><br><span class="line"><span class="keyword">set</span> spark.dynamicAllocation.minExecutors<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line"><span class="comment">-- Executorä¸ªæ•°æœ€å¤§å€¼</span></span><br><span class="line"><span class="keyword">set</span> spark.dynamicAllocation.maxExecutors<span class="operator">=</span><span class="number">12</span>;</span><br><span class="line"><span class="comment">-- Executorç©ºé—²æ—¶é•¿ï¼Œè‹¥æŸExecutorç©ºé—²æ—¶é—´è¶…è¿‡æ­¤å€¼ï¼Œåˆ™ä¼šè¢«å…³é—­</span></span><br><span class="line"><span class="keyword">set</span> spark.dynamicAllocation.executorIdleTimeout<span class="operator">=</span><span class="number">60</span>s;</span><br><span class="line"><span class="comment">-- ç§¯å‹ä»»åŠ¡ç­‰å¾…æ—¶é•¿ï¼Œè‹¥æœ‰Taskç­‰å¾…æ—¶é—´è¶…è¿‡æ­¤å€¼ï¼Œåˆ™ç”³è¯·å¯åŠ¨æ–°çš„Executor</span></span><br><span class="line"><span class="keyword">set</span> spark.dynamicAllocation.schedulerBacklogTimeout<span class="operator">=</span><span class="number">1</span>s;</span><br><span class="line"><span class="keyword">set</span> spark.shuffle.useOldFetchProtocol<span class="operator">=</span><span class="literal">true</span>;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>è¯´æ˜ï¼šSpark shuffleæœåŠ¡çš„ä½œç”¨æ˜¯ç®¡ç†Executorä¸­çš„å„Taskçš„è¾“å‡ºæ–‡ä»¶ï¼Œä¸»è¦æ˜¯shuffleè¿‡ç¨‹mapç«¯çš„è¾“å‡ºæ–‡ä»¶ã€‚ç”±äºå¯ç”¨èµ„æºåŠ¨æ€åˆ†é…åï¼ŒSparkä¼šåœ¨ä¸€ä¸ªåº”ç”¨æœªç»“æŸå‰ï¼Œå°†å·²ç»å®Œæˆä»»åŠ¡ï¼Œå¤„äºç©ºé—²çŠ¶æ€çš„Executorå…³é—­ã€‚Executorå…³é—­åï¼Œå…¶è¾“å‡ºçš„æ–‡ä»¶ï¼Œä¹Ÿå°±æ— æ³•ä¾›å…¶ä»–Executorä½¿ç”¨äº†ã€‚éœ€è¦å¯ç”¨Spark shuffleæœåŠ¡ï¼Œæ¥ç®¡ç†å„Executorè¾“å‡ºçš„æ–‡ä»¶ï¼Œè¿™æ ·å°±èƒ½å…³é—­ç©ºé—²çš„Executorï¼Œè€Œä¸å½±å“åç»­çš„è®¡ç®—ä»»åŠ¡äº†ã€‚</p>
</blockquote>
<br>
### 1.4.4 hive on sparkçš„è¶…æ—¶æ—¶é—´é…ç½®
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- Spark driverè¿æ¥Hive clientçš„è¶…æ—¶æ—¶é—´,é»˜è®¤å•ä½æ¯«ç§’ --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.spark.client.connect.timeout&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;600000ms&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- Hive clientå’Œè¿œç¨‹Spark clientæ¡æ‰‹çš„è¶…æ—¶æ—¶é—´,é»˜è®¤å•ä½æ¯«ç§’ --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.spark.client.server.connect.timeout&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;600000ms&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- Hive clientè¯·æ±‚Spark driverçš„è¶…æ—¶æ—¶é—´,é»˜è®¤å•ä½ç§’ --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.spark.client.future.timeout&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;600s&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- Jobç›‘æ§è·å–Sparkä½œä¸šçŠ¶æ€çš„è¶…æ—¶æ—¶é—´,é»˜è®¤å•ä½ç§’ --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.spark.client.future.timeout&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;600s&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<h3 id="1-4-5-å…¶ä»–ä¼˜åŒ–"><a href="#1-4-5-å…¶ä»–ä¼˜åŒ–" class="headerlink" title="1.4.5 å…¶ä»–ä¼˜åŒ–"></a>1.4.5 å…¶ä»–ä¼˜åŒ–</h3><p>å‚è€ƒèµ„æ–™ï¼š<br>1.<a target="_blank" rel="noopener" href="https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/admin_hos_tuning.html#hos_tuning">https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/admin_hos_tuning.html#hos_tuning</a><br>2.<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started](https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started)">https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started](https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started)</a></p>
<br>
# äºŒã€Tezè°ƒä¼˜
è¯¦ç»†é…ç½®å¯æŸ¥çœ‹å®˜ç½‘çš„[Tezé…ç½®](https://tez.apache.org/releases/0.8.4/tez-api-javadocs/configs/TezConfiguration.html)å’Œ[TezRuntimeé…ç½®](https://tez.apache.org/releases/0.10.1/tez-api-javadocs/configs/TezConfiguration.html)

<ul>
<li><strong>tez.runtime.io.sort.mb</strong>æ˜¯å½“éœ€è¦å¯¹è¾“å‡ºè¿›è¡Œæ’åºçš„å†…å­˜ã€‚</li>
<li><strong>tez.runtime.unordered.output.buffer.size-mb</strong>æ˜¯è¾“å‡ºä¸éœ€è¦æ’åºçš„å†…å­˜ã€‚</li>
<li><strong>hive.auto.convert.join.noconditionaltask.size</strong>æ˜¯ä¸€ä¸ªéå¸¸é‡è¦çš„å‚æ•°ï¼Œç”¨äºè®¾ç½®æ‰§è¡ŒMap joinæ—¶çš„å†…å­˜å¤§å°ã€‚</li>
<li><strong>tez.am.resource.memory.mb</strong>è®¾ç½®ä¸ºä¸<strong>yarn.scheduler.minimum-allocate-mb</strong> YARNæœ€å°å®¹å™¨å¤§å°ç›¸åŒã€‚ </li>
<li><strong>hive.tez.container.size</strong>è®¾ç½®ä¸ºä¸<strong>yarn.scheduler.minimum-allocation-mb</strong>å¤§å°ç›¸åŒæˆ–å°å€æ•°(1æˆ–2å€)ï¼Œä½†ä¸èƒ½è¶…è¿‡<strong>yarn.scheduler.maximum-allocation-mb</strong>ã€‚</li>
<li><strong>tez.runtime.io.sort.mb</strong>ä¸º<strong>hive.tez.container.size</strong>çš„40%ï¼Œä¸åº”è¯¥è¶…è¿‡2gbã€‚</li>
<li><strong>hive.auto.convert.join.noconditionaltask.size</strong>ä¸º<strong>hive.tez.container.size</strong>çš„1&#x2F;3</li>
<li><strong>tez.runtime.unordered.output.buffer.size-mb</strong>ä¸º<strong>hive.tez.container.size</strong>çš„10%</li>
</ul>
<p><strong>1. AMã€Containerå¤§å°è®¾ç½®</strong></p>
<ul>
<li>tez.am.resource.memory.mbã€€ã€€#è®¾ç½® tez AMå®¹å™¨å†…å­˜<br>ã€€ã€€é»˜è®¤å€¼ï¼š1024ã€€ã€€<br>ã€€ã€€é…ç½®æ–‡ä»¶ï¼štez-site.xml<br>ã€€ã€€å»ºè®®ï¼šç­‰äºyarn.scheduler.minimum-allocation-mbå€¼ã€‚</li>
</ul>
<p>ã€€ã€€</p>
<blockquote>
<p><strong>Noteï¼š</strong>é‡åˆ°è¿‡tezæ‰§è¡Œæ•°æ®é‡ç‰¹åˆ«å¤§çš„ä»»åŠ¡æ—¶ï¼Œä¸€ç›´å¡åœ¨Scheduledé˜¶æ®µçš„æƒ…å†µã€‚éœ€è¦è°ƒæ•´amçš„å¤§å°<br>set tez.am.resource.memory.mb&#x3D;5120;<br>set tez.am.launch.cmd-opts&#x3D;-Xms5120m -Xmx5120m;</p>
</blockquote>
<ul>
<li>hive.tez.container.sizeã€€ã€€#è®¾ç½® tez containerå†…å­˜<br>ã€€ã€€é»˜è®¤å€¼ï¼š-1<br>ã€€ã€€é»˜è®¤æƒ…å†µä¸‹ï¼ŒTezå°†ç”Ÿæˆä¸€ä¸ªmapperå¤§å°çš„å®¹å™¨ã€‚è¿™å¯ä»¥ç”¨æ¥è¦†ç›–é»˜è®¤å€¼ã€‚<br>ã€€ã€€é…ç½®æ–‡ä»¶ï¼šhive-site.xml<br>ã€€ã€€å»ºè®®ï¼šç­‰äºæˆ–å‡ å€äºyarn.scheduler.minimum-allocation-mbå€¼ï¼Œä½†æ˜¯ä¸èƒ½å¤§äºyarn.scheduler.maximum-allocation-mbã€‚</li>
</ul>
<br>
**2. AMã€Container JVMå‚æ•°è®¾ç½®**
- tez.am.launch.cmd-optsã€€ã€€#è®¾ç½® AM jvmï¼Œå¯åŠ¨TEZä»»åŠ¡è¿›ç¨‹æœŸé—´æä¾›çš„å‘½ä»¤è¡Œé€‰é¡¹ã€‚
ã€€ã€€é»˜è®¤å€¼ï¼š-XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+UseNUMA -XX:+UseParallelGC(ç”¨äºGC)ï¼Œé»˜è®¤çš„å¤§å°ï¼š80%*tez.am.resource.memory.mb
ã€€ã€€é…ç½®æ–‡ä»¶ï¼štez-site.xml
ã€€ã€€å»ºè®®ï¼šä¸è¦åœ¨è¿™äº›å¯åŠ¨é€‰é¡¹ä¸­è®¾ç½®ä»»ä½•xmxæˆ–xmsï¼Œä»¥ä¾¿tezå¯ä»¥è‡ªåŠ¨ç¡®å®šå®ƒä»¬ã€‚
ã€€ã€€
- tez.task.launch.cmd-opts
   é»˜è®¤å€¼ï¼šå¯åŠ¨çš„JVMå‚æ•° ï¼Œé»˜è®¤-XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+UseNUMA -XX:+UseParallelGC

<ul>
<li><p>tez.container.max.java.heap.fraction<br> è¯´æ˜ï¼šåŸºäºyarnæä¾›çš„å†…å­˜ï¼Œåˆ†é…ç»™javaè¿›ç¨‹çš„ç™¾åˆ†æ¯”ï¼Œé»˜è®¤æ˜¯0.8ï¼Œå…·ä½“å¤§å°å–å†³äºmapreduce.reduce.memory.mbå’Œmapreduce.map.memory.mbã€‚ä¸€èˆ¬ä¸ç”¨å˜å³å¯</p>
</li>
<li><p>hive.tez.java.opsã€€ã€€#è®¾ç½® container jvm<br>ã€€ã€€é»˜è®¤å€¼ï¼šHortonworkså»ºè®®â€œâ€“server â€“Djava.net.preferIPv4Stack&#x3D;trueâ€“XX:NewRatio&#x3D;8 â€“XX:+UseNUMA â€“XX:UseG1Gâ€ï¼Œé»˜è®¤å¤§å°ï¼š80%*hive.tez.container.size<br>ã€€ã€€é…ç½®æ–‡ä»¶ï¼šhive-site.xml<br>ã€€ã€€å»ºè®®ï¼šHortonworkså»ºè®®â€œâ€“server â€“Djava.net.preferIPv4Stack&#x3D;trueâ€“XX:NewRatio&#x3D;8 â€“XX:+UseNUMA â€“XX:UseG1Gâ€</p>
</li>
<li><p>tez.container.max.java.heap.fractionã€€ã€€#è®¾ç½®task&#x2F;AMå ç”¨jvmå†…å­˜å¤§å°çš„æ¯”ä¾‹ã€‚<br>ã€€ã€€é»˜è®¤å€¼ï¼š0.8<br>ã€€ã€€é…ç½®æ–‡ä»¶ï¼štez-site.xml<br>ã€€ã€€è¯´æ˜ï¼štask\AMå ç”¨JVM Xmxçš„æ¯”ä¾‹ï¼Œè¿™ä¸ªå€¼æŒ‰å…·ä½“éœ€è¦è°ƒæ•´ï¼Œå½“å†…å­˜ä¸è¶³æ—¶ï¼Œä¸€èˆ¬éƒ½è¦è°ƒå°ã€‚</p>
</li>
</ul>
<br>
**3. Hiveå†…å­˜Map Joinå‚æ•°è®¾ç½®**
- tez.runtime.io.sort.mbã€€ã€€#è®¾ç½®è¾“å‡ºæ’åºå†…å­˜å¤§å°
ã€€ã€€é»˜è®¤å€¼ï¼š100
ã€€ã€€é…ç½®æ–‡ä»¶ï¼štez-site.xml
ã€€ã€€å»ºè®®ï¼š40%*hive.tez.container.sizeï¼Œä¸€èˆ¬ä¸è¶…è¿‡2G


<ul>
<li><p>hive.auto.convert.join  #æ˜¯å¦è‡ªåŠ¨è½¬æ¢ä¸ºmapjoin<br>ã€€ã€€é»˜è®¤å€¼ï¼štrue<br>ã€€ã€€å»ºè®®ä½¿ç”¨é»˜è®¤å€¼ã€‚<br>ã€€ã€€é…ç½®æ–‡ä»¶ï¼šhive-site.xml</p>
</li>
<li><p>hive.auto.convert.join.noconditionaltaskã€€ã€€#æ˜¯å¦å°†å¤šä¸ªmapjoinåˆå¹¶ä¸ºä¸€ä¸ª<br>ã€€ã€€é»˜è®¤å€¼ï¼štrue<br>ã€€ã€€å»ºè®®ä½¿ç”¨é»˜è®¤å€¼ã€‚<br>ã€€ã€€é…ç½®æ–‡ä»¶ï¼šhive-site.xml</p>
</li>
<li><p>hive.auto.convert.join.noconditionaltask.size<br>ã€€ã€€é»˜è®¤å€¼ï¼š10000000ã€€ã€€(10M)<br>ã€€ã€€è¯´æ˜ï¼šè¿™ä¸ªå‚æ•°ä½¿ç”¨çš„å‰ææ˜¯hive.auto.convert.join.noconditionaltaskå€¼ä¸ºtrueï¼Œå¤šä¸ªmapjoinè½¬æ¢ä¸º1ä¸ªæ—¶ï¼Œæ‰€æœ‰å°è¡¨çš„æ–‡ä»¶å¤§å°æ€»å’Œå°äºè¿™ä¸ªå€¼ï¼Œè¿™ä¸ªå€¼åªæ˜¯é™åˆ¶è¾“å…¥çš„è¡¨æ–‡ä»¶çš„å¤§å°ï¼Œå¹¶ä¸ä»£è¡¨å®é™…mapjoinæ—¶hashtableçš„å¤§å°ã€‚ å»ºè®®å€¼ï¼š1&#x2F;3* hive.tez.container.size<br>ã€€ã€€é…ç½®æ–‡ä»¶ï¼šhive-site.xml</p>
</li>
<li><p>tez.runtime.unordered.output.buffer.size-mbã€€ã€€#å¦‚æœä¸ç›´æ¥å†™å…¥ç£ç›˜ï¼Œä½¿ç”¨çš„ç¼“å†²åŒºå¤§å°. Size of the buffer to use if not writing directly to disk.<br>ã€€ã€€é»˜è®¤å€¼ï¼š100M<br> ã€€å»ºè®®ï¼š10%* hive.tez.container.size<br>ã€€ã€€é…ç½®æ–‡ä»¶ï¼štez-site.xml</p>
</li>
<li><p>tez.am.container.reuse.enabledã€€ã€€#å®¹å™¨é‡ç”¨<br>ã€€ã€€é»˜è®¤å€¼ï¼štrue<br>ã€€ã€€é…ç½®æ–‡ä»¶ï¼štez-ste.xml</p>
</li>
</ul>
<br>
**4. Hiveä½¿ç”¨CPUè®¾ç½®**
- hive.tez.cpu.vcores
ã€€ã€€é»˜è®¤å€¼ï¼š-1
 ã€€  è¯´æ˜ï¼šæ¯ä¸ªå®¹å™¨åˆ†é…çš„CPUä¸ªæ•°
ã€€ã€€é…ç½®æ–‡ä»¶ï¼šhive-site.xml

<ul>
<li>tez.am.resource.cpu.vcores<br> è¯´æ˜ï¼šamåˆ†é…çš„cpuä¸ªæ•°ï¼Œé»˜è®¤1</li>
</ul>
<br>
**5.Mapper/Reducerè®¾ç½®**

<p>â‘ Mapperæ•°è®¾ç½®<br>åœ¨Tezåˆ†é…ä»»åŠ¡æ—¶ï¼Œä¸ä¼šåƒmré‚£æ ·ä¸ºæ¯ä¸ªsplitç”Ÿæˆä¸€ä¸ªmapä»»åŠ¡ï¼Œè€Œæ˜¯ä¼šå°†å¤šä¸ªsplitè¿›è¡Œgroupingï¼Œè®©mapä»»åŠ¡æ›´é«˜æ•ˆåœ°çš„å®Œæˆã€‚é¦–å…ˆTezä¼šæ ¹æ®è®¡ç®—å¾—åˆ°çš„ estimated number of tasks &#x3D; 5ï¼Œå°†splitsèšåˆä¸º5ä¸ªSplit Groupï¼Œç”Ÿæˆ5ä¸ªmapperæ‰§è¡Œä»»åŠ¡ã€‚<br>Tezä¼šæ£€æŸ¥lengthPerGroupæ˜¯å¦åœ¨ tez.grouping.min-size ï¼ˆé»˜è®¤ä¸º50MBï¼‰ä»¥åŠ tez.grouping.max-sizeï¼ˆé»˜è®¤ä¸º1GBï¼‰ å®šä¹‰èŒƒå›´å†…ã€‚å¦‚æœè¶…è¿‡äº†max-sizeï¼Œåˆ™æŒ‡å®šlengthPerGroupä¸ºmax-sizeï¼Œå¦‚æœå°äºmin-sizeï¼Œåˆ™æŒ‡å®šlengthPerGroupä¸ºmin-sizeã€‚</p>
<ul>
<li><p>tez.grouping.min-size<br> é»˜è®¤å€¼ï¼š5010241024 (50M)<br> å‚æ•°è¯´æ˜ï¼šLower bound on the size (in bytes) of a grouped split, to avoid generating too many small splits.</p>
</li>
<li><p>tez.grouping.max-size<br> é»˜è®¤å€¼ï¼š102410241024<br> å‚æ•°è¯´æ˜ï¼šUpper bound on thesize (in bytes) of a grouped split, to avoid generating excessively largesplits.</p>
</li>
<li><p>tez.grouping.split-count<br> é»˜è®¤å€¼ï¼šæ— <br> å‚æ•°è¯´æ˜ï¼šgroupçš„åˆ†å‰²ç»„æ•°ï¼Œå¹¶ä¸æ˜¯ç²¾ç¡®æŒ‡å®šåˆ‡åˆ†æ•°é‡ã€‚å½“è®¾ç½®çš„å€¼å¤§äºåŸå§‹çš„895æ—¶ï¼Œtezä¼šç›´æ¥ä½¿ç”¨895ã€‚</p>
</li>
</ul>
<p>â‘¡Reduceræ•°è®¾ç½®</p>
<ul>
<li><p>hive.tez.auto.reducer.parallelism<br>é»˜è®¤å€¼ï¼šfalse<br>å‚æ•°è¯´æ˜ï¼šTezä¼šä¼°è®¡æ•°æ®é‡å¤§å°ï¼Œè®¾ç½®å¹¶è¡Œåº¦ã€‚åœ¨è¿è¡Œæ—¶ä¼šæ ¹æ®éœ€è¦è°ƒæ•´ä¼°è®¡å€¼ã€‚Turn on Tezâ€™ autoreducer parallelism feature. When enabled, Hive will still estimate data sizesand set parallelism estimates. Tez will sample source verticesâ€™ output sizesand adjust the estimates at runtime as necessary.<br>å»ºè®®è®¾ç½®ä¸ºtrue.</p>
</li>
<li><p>hive.tex.min.partition.factor<br>é»˜è®¤å€¼ï¼š0.25<br>å‚æ•°è¯´æ˜ï¼šWhen auto reducerparallelism is enabled this factor will be used to put a lower limit to thenumber of reducers that Tez specifies.</p>
</li>
<li><p>hive.tez.max.partition.factor<br>é»˜è®¤å€¼ï¼š2.0<br>å‚æ•°è¯´æ˜ï¼šWhen auto reducerparallelism is enabled this factor will be used to over-partition data inshuffle edges.</p>
</li>
<li><p>hive.exec.reducers.bytes.per.reducer<br>é»˜è®¤å€¼ï¼š256,000,000 (256M)<br>å‚æ•°è¯´æ˜ï¼šæ¯ä¸ªreduceçš„æ•°æ®å¤„ç†é‡ã€‚Sizeper reducer. The default in Hive 0.14.0 and earlier is 1 GB, that is, if theinput size is 10 GB then 10 reducers will be used. In Hive 0.14.0 and later thedefault is 256 MB, that is, if the input size is 1 GB then 4 reducers willbe used.</p>
</li>
<li><p>mapred.reduce.tasks<br>é»˜è®¤å€¼ï¼š-1<br>å‚æ•°è¯´æ˜ï¼šåŒmapreduceå¼•æ“é…ç½®ï¼ŒæŒ‡å®šreduceçš„ä¸ªæ•°ã€‚</p>
</li>
<li><p>hive.exec.reducers.max<br>é»˜è®¤å€¼ï¼š1009<br>å‚æ•°è¯´æ˜ï¼šæœ€å¤§reduceä¸ªæ•°</p>
<p> ä»¥ä¸‹å…¬å¼ç¡®è®¤Reducerä¸ªæ•°ï¼š<br> <code>Max(1, Min(hive.exec.reducers.max [1009], ReducerStage estimate/hive.exec.reducers.bytes.per.reducer)) x hive.tez.max.partition.factor</code></p>
</li>
</ul>
<p>â‘¢Shuffleå‚æ•°è®¾ç½®</p>
<ul>
<li><p>tez.shuffle-vertex-manager.min-src-fraction<br>é»˜è®¤å€¼ï¼š0.25<br>å‚æ•°è¯´æ˜ï¼šthefraction of source tasks which should complete before tasks for the currentvertex are scheduled.</p>
</li>
<li><p>tez.shuffle-vertex-manager.max-src-fraction<br>é»˜è®¤å€¼ï¼š0.75<br>å‚æ•°è¯´æ˜ï¼šoncethis fraction of source tasks have completed, all tasks on the current vertexcan be scheduled. Number of tasks ready for scheduling on the current vertexscales linearly between min-fraction and max-fraction.</p>
</li>
</ul>
<blockquote>
<p><strong>ä¾‹å­ï¼š</strong><br>hive.exec.reducers.bytes.per.reducer&#x3D;1073741824; &#x2F;&#x2F; 1GB<br>tez.shuffle-vertex-manager.min-src-fraction&#x3D;0.25ï¼›<br>tez.shuffle-vertex-manager.max-src-fraction&#x3D;0.75ï¼›</p>
<p><strong>è¯´æ˜ï¼š</strong>This indicates thatthe decision will be made between 25% of mappers finishing and 75% of mappersfinishing, provided thereâ€™s at least 1Gb of data being output (i.e if 25% ofmappers donâ€™t send 1Gb of data, we will wait till at least 1Gb is sent out).</p>
</blockquote>
<br>
**5. å…¶ä»–è®¾ç½®**
- tez.job.name
   è¯´æ˜ï¼šè®¾ç½®tezä»»åŠ¡å

<ul>
<li><p>tez.am.speculation.enabled<br> è¯´æ˜ï¼šæ˜¯å¦å¼€å¯æ¨æµ‹æ‰§è¡Œï¼Œé»˜è®¤æ˜¯falseï¼Œåœ¨å‡ºç°æœ€åä¸€ä¸ªä»»åŠ¡å¾ˆæ…¢çš„æƒ…å†µä¸‹ï¼Œå»ºè®®æŠŠè¿™ä¸ªå‚æ•°è®¾ç½®ä¸ºtrue</p>
</li>
<li><p>tez.task.log.level<br> è¯´æ˜ï¼šæ—¥å¿—çº§åˆ«ï¼Œé»˜è®¤info</p>
</li>
<li><p>tez.queue.name<br> è¯´æ˜ï¼šåœ¨yarnä¸­çš„é»˜è®¤æ‰§è¡Œé˜Ÿåˆ—</p>
</li>
<li><p>tez.am.task.max.failed.attempts<br> è¯´æ˜ï¼šä»»åŠ¡ä¸­attemptså¤±è´¥çš„æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤è·Ÿyarnä¸€æ ·æ˜¯4æ¬¡ ï¼Œåœ¨ä¸ç¨³å®šé›†ç¾¤å¯ä»¥è®¾ç½®å¤§ä¸€ç‚¹</p>
</li>
<li><p>tez.am.max.app.attempts<br> è¯´æ˜ï¼šamè‡ªå·±å¤±è´¥çš„æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤æ˜¯2æ¬¡ã€‚è¿™é‡Œå¹¶ä¸æ˜¯è¯´amè‡ªå·±æŒ‚äº†ï¼Œåªæ˜¯å› ä¸ºä¸€äº›ç³»ç»ŸåŸå› å¯¼è‡´å¤±è”äº†</p>
</li>
<li><p>set mapreduce.input.fileinputformat.input.dir.recursive&#x3D;true<br> è¯´æ˜ï¼šå› ä¸ºTezä½¿ç”¨Insert â€¦ UNION ALL è¯­å¥ï¼Œä¼šå°†æ¯ä¸ªUNION ALLç»“æœå•ç‹¬å­˜æ–‡ä»¶å¤¹ã€‚éœ€è¦è®¾ç½®mrå¼•æ“é€’å½’æŸ¥è¯¢ï¼Œå¯¹sparkå¼•æ“åŒæ ·ç”Ÿæ•ˆã€‚</p>
</li>
</ul>
<br>
**6. å®ä¾‹**
åœ¨Hive ä¸­æ‰§è¡Œä¸€ä¸ªqueryæ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°Hive çš„æ‰§è¡Œå¼•æ“åœ¨ä½¿ç”¨ Tez ä¸ MRæ—¶ï¼Œä¸¤è€…ç”Ÿæˆmapperæ•°é‡å·®å¼‚è¾ƒå¤§ã€‚ä¸»è¦åŸå› åœ¨äº Tez ä¸­å¯¹ inputSplit åšäº† grouping æ“ä½œï¼Œå°†å¤šä¸ª inputSplit ç»„åˆæˆæ›´å°‘çš„ groupsï¼Œç„¶åä¸ºæ¯ä¸ª group ç”Ÿæˆä¸€ä¸ª mapper ä»»åŠ¡ï¼Œè€Œä¸æ˜¯ä¸ºæ¯ä¸ªinputSplit ç”Ÿæˆä¸€ä¸ªmapper ä»»åŠ¡ã€‚ä¸‹é¢æˆ‘ä»¬é€šè¿‡æ—¥å¿—åˆ†æä¸€ä¸‹è¿™ä¸­é—´çš„æ•´ä¸ªè¿‡ç¨‹ã€‚

<p>è°ƒæ•´inputFormtä¸ºCombineInputFormatåˆå¹¶å°æ–‡ä»¶å¯ä»¥æœ‰æ•ˆå‡å°‘ä½œä¸šä¸­Mapperçš„æ•°é‡ã€‚</p>
<p>1ï¼‰MapReduceæ¨¡å¼<br>åœ¨ mr æ¨¡å¼ä¸‹ï¼Œç”Ÿæˆçš„containeræ•°ä¸º116ä¸ªï¼š</p>
<p>å¯¹åº”æ—¥å¿—æ¡ç›®ä¸ºï¼š<br>Input size for job job_1566964005095_0003 &#x3D; 31733311148. Number of splits &#x3D; 116</p>
<p>åœ¨MRä¸­ï¼Œä½¿ç”¨çš„æ˜¯Hadoopä¸­çš„FileInputFormatï¼Œæ‰€ä»¥è‹¥æ˜¯ä¸€ä¸ªæ–‡ä»¶å¤§äºä¸€ä¸ªblockçš„å¤§å°ï¼Œåˆ™ä¼šåˆ‡åˆ†ä¸ºå¤šä¸ªInputSplitï¼›è‹¥æ˜¯ä¸€ä¸ªæ–‡ä»¶å°äºä¸€ä¸ªblockå¤§å°ï¼Œåˆ™ä¸ºä¸€ä¸ªInputSplitã€‚</p>
<p>åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæ€»æ–‡ä»¶ä¸ªæ•°ä¸º14ä¸ªï¼Œæ¯ä¸ªå‡ä¸º2.1GBï¼Œä¸€å…±29.4GBå¤§å°ã€‚ç”Ÿæˆçš„InputSplitæ•°ä¸º116ä¸ªï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯ä¸ªblockï¼ˆè¿™ä¸ªåœºæ™¯ä¸‹InputSplit å¤§å°ä¸ºä¸€ä¸ªblockå¤§å°ï¼‰çš„å¤§å°å¤§çº¦ä¸º256MBã€‚</p>
<p>2ï¼‰Tezæ¨¡å¼</p>
<p>è€Œåœ¨Tezæ¨¡å¼ä¸‹ï¼Œç”Ÿæˆçš„mapä»»åŠ¡ä¸º32ä¸ªï¼š</p>
<p>ç”Ÿæˆsplit groupsçš„ç›¸å…³æ—¥å¿—å¦‚ä¸‹ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mapred.FileInputFormat|: Total input files to process : 14</span><br><span class="line">io.HiveInputFormat|: number of splits 476</span><br><span class="line">tez.HiveSplitGenerator|: Number of input splits: 476. 3 available slots, 1.7 waves. Input format is: org.apache.hadoop.hive.ql.io.HiveInputFormat</span><br><span class="line"></span><br><span class="line">tez.SplitGrouper|: # Src groups for split generation: 2</span><br><span class="line">tez.SplitGrouper|: Estimated number of tasks: 5 for bucket 1</span><br><span class="line">grouper.TezSplitGrouper|: Grouping splits in Tez</span><br><span class="line">|grouper.TezSplitGrouper|: Desired splits: 5 too small. Desired splitLength: 6346662229 Max splitLength: 1073741824 New desired splits: 30 Total length: 31733311148 Original splits: 476</span><br><span class="line">|grouper.TezSplitGrouper|: Desired numSplits: 30 lengthPerGroup: 1057777038 numLocations: 1 numSplitsPerLocation: 476 numSplitsInGroup: 15 totalLength: 31733311148 numOriginalSplits: 476 . Grouping by length: true count: false nodeLocalOnly: false</span><br><span class="line">|grouper.TezSplitGrouper|: Doing rack local after iteration: 32 splitsProcessed: 466 numFullGroupsInRound: 0 totalGroups: 31 lengthPerGroup: 793332736 numSplitsInGroup: 11</span><br><span class="line">|grouper.TezSplitGrouper|: Number of splits desired: 30 created: 32 splitsProcessed: 476</span><br><span class="line">|tez.SplitGrouper|: Original split count is 476 grouped split count is 32, for bucket: 1</span><br><span class="line">|tez.HiveSplitGenerator|: Number of split groups: 32</span><br></pre></td></tr></table></figure>

<br>
**Avaiable Slots**

<p>é¦–å…ˆå¯ä»¥çœ‹åˆ°ï¼Œéœ€è¦å¤„ç†çš„æ–‡ä»¶æ•°ä¸º14ï¼Œåˆå§‹splitsæ•°ç›®ä¸º476ï¼ˆå³æ„å‘³ç€åœ¨è¿™ä¸ªåœºæ™¯ä¸‹ï¼Œä¸€ä¸ªblockçš„å¤§å°çº¦ä¸º64MBï¼‰ã€‚å¯¹åº”æ—¥å¿—æ¡ç›®å¦‚ä¸‹ï¼š</p>
<p>|mapred.FileInputFormat|: Total input files to process : 14</p>
<p>|io.HiveInputFormat|: number of splits 476</p>
<p>è·å–åˆ°splitsçš„ä¸ªæ•°ä¸º476ä¸ªåï¼ŒDriverå¼€å§‹è®¡ç®—å¯ç”¨çš„slotsï¼ˆcontainerï¼‰æ•°ï¼Œè¿™é‡Œè®¡ç®—å¾—åˆ°3ä¸ªslotsï¼Œå¹¶æ‰“å°äº†é»˜è®¤çš„waveså€¼ä¸º1.7ã€‚<br>åœ¨æ­¤åœºæ™¯ä¸­ï¼Œé›†ç¾¤ä¸€å…±èµ„æºä¸º 8 vcoreï¼Œ12G å†…å­˜ï¼Œcapacity-schedulerä¸­æŒ‡å®šçš„user limit factor ä¸º0.5ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼šå½“å‰ç”¨æˆ·èƒ½ä½¿ç”¨çš„èµ„æºæœ€å¤šä¸º 6G å†…å­˜ã€‚åœ¨Tez Driverä¸­ï¼Œç”³è¯·çš„container èµ„æºçš„å•ä½ä¸ºï¼š Default Resources&#x3D;&lt;memory:1536, vCores:1&gt;</p>
<p>æ‰€ä»¥ç†è®ºä¸Šå¯ä»¥ç”³è¯·åˆ°çš„container æ•°ç›®ä¸º4ï¼ˆ6G&#x2F;1536MB &#x3D; 4ï¼‰ä¸ªï¼Œè€Œç”±äº Application Master å ç”¨äº†ä¸€ä¸ªcontainerï¼Œæ‰€ä»¥æœ€ç»ˆavailable slotsä¸º3ä¸ªã€‚</p>
<p>åœ¨è®¡ç®—å‡ºäº†å¯ç”¨çš„slotsä¸º3ä¸ªåï¼ŒTez ä½¿ç”¨split-waves ä¹˜æ•°ï¼ˆç”±tez.grouping.split-wavesæŒ‡å®šï¼Œé»˜è®¤ä¸º1.7ï¼‰æŒ‡å®šâ€œé¢„ä¼°â€çš„Map ä»»åŠ¡æ•°ç›®ä¸ºï¼š3 Ã— 1.7 &#x3D; 5 ä¸ªtasksã€‚å¯¹åº”æ—¥å¿—æ¡ç›®å¦‚ä¸‹ï¼š</p>
<p>|tez.HiveSplitGenerator|: Number of input splits: 476. 3 available slots, 1.7 waves. Input format is: org.apache.hadoop.hive.ql.io.HiveInputFormat</p>
<p>|tez.SplitGrouper|: Estimated number of tasks: 5 for bucket 1</p>
<br>
**Grouping Input Splits**

<p>åœ¨Tezåˆ†é…ä»»åŠ¡æ—¶ï¼Œä¸ä¼šåƒmré‚£æ ·ä¸ºæ¯ä¸ªsplitç”Ÿæˆä¸€ä¸ªmapä»»åŠ¡ï¼Œè€Œæ˜¯ä¼šå°†å¤šä¸ªsplitè¿›è¡Œgroupingï¼Œè®©mapä»»åŠ¡æ›´é«˜æ•ˆåœ°çš„å®Œæˆã€‚é¦–å…ˆTezä¼šæ ¹æ®è®¡ç®—å¾—åˆ°çš„ estimated number of tasks &#x3D; 5ï¼Œå°†splitsèšåˆä¸º5ä¸ªSplit Groupï¼Œç”Ÿæˆ5ä¸ªmapperæ‰§è¡Œä»»åŠ¡ã€‚</p>
<p><strong>ä½†æ˜¯è¿™é‡Œè¿˜éœ€è¦è€ƒè™‘å¦ä¸€ä¸ªå€¼</strong>ï¼šlengthPerGroupã€‚Tezä¼šæ£€æŸ¥lengthPerGroupæ˜¯å¦åœ¨ tez.grouping.min-size ï¼ˆé»˜è®¤ä¸º50MBï¼‰ä»¥åŠ tez.grouping.max-sizeï¼ˆé»˜è®¤ä¸º1GBï¼‰ å®šä¹‰èŒƒå›´å†…ã€‚å¦‚æœè¶…è¿‡äº†max-sizeï¼Œåˆ™æŒ‡å®šlengthPerGroupä¸ºmax-sizeï¼Œå¦‚æœå°äºmin-sizeï¼Œåˆ™æŒ‡å®šlengthPerGroupä¸ºmin-sizeã€‚</p>
<p>åœ¨è¿™ä¸ªåœºæ™¯ä¸‹ï¼Œæ•°æ®æ€»å¤§å°ä¸º 31733311148 bytesï¼ˆ29.5GBå·¦å³ï¼Œä¹Ÿæ˜¯åŸæ•°æ®å¤§å°ï¼‰ï¼Œé¢„ä¼°ä¸º5ä¸ªGroupï¼Œ åˆ™æ¯ä¸ªGroupçš„ splitLengthä¸º6346662229 bytesï¼ˆ5.9GB å·¦å³ï¼‰ï¼Œè¶…è¿‡äº† Max splitLength &#x3D; 1073741824 bytesï¼ˆ 1GBï¼‰ï¼Œæ‰€ä»¥é‡æ–°æŒ‰ splitLength &#x3D; 1GB æ¥ç®—ï¼Œè®¡ç®—å‡ºæ‰€éœ€çš„numSplits æ•°ä¸º 30 ä¸ªï¼Œæ¯ä¸ªSplit Groupçš„å¤§å°ä¸º1GBã€‚</p>
<p>åœ¨è®¡ç®—å‡ºäº†æ¯ä¸ªSplit Groupçš„å¤§å°ä¸º1GBåï¼Œç”±äºåŸSplitæ€»æ•°ç›®ä¸º476ï¼Œæ‰€ä»¥éœ€è¦å°†è¿™476ä¸ªinputSplitè¿›è¡Œgroupingï¼Œä½¿å¾—æ¯ä¸ªGroupçš„å¤§å°å¤§çº¦ä¸º1GBå·¦å³ã€‚æŒ‰æ­¤æ–¹æ³•è®¡ç®—ï¼Œé¢„æœŸçš„splitsæ•°ç›®åº”ä¸º30ä¸ªï¼ˆä½†æ˜¯ä»…æ˜¯é€šè¿‡æ€»æ•°æ®å¤§å°&#x2F;lengthPerGroupå¾—å‡ºï¼Œå°šæœªè€ƒè™‘inputSplitså¦‚ä½•åˆå¹¶çš„é—®é¢˜ï¼Œä¸ä¸€å®šä¸ºæœ€ç»ˆç”Ÿæˆçš„map tasksæ•°ç›®ï¼‰ã€‚ä¸”æœ€ç»ˆå¯è®¡ç®—å¾—å‡ºæ¯ä¸ªgroupä¸­å¯ä»¥åŒ…å«15ä¸ªåŸsplitï¼Œä¹Ÿå°±æ˜¯numSplitsInGroup &#x3D; 15ã€‚ç›¸å…³æ—¥å¿—æ¡ç›®å¦‚ä¸‹ï¼š</p>
<p>|grouper.TezSplitGrouper|: Grouping splits in Tez</p>
<p>|grouper.TezSplitGrouper|: Desired splits: 5 too small. Desired splitLength: 6346662229 Max splitLength: 1073741824 New desired splits: 30 Total length: 31733311148 Original splits: 476</p>
<p>|grouper.TezSplitGrouper|: Desired numSplits: 30 lengthPerGroup: 1057777038 numLocations: 1 numSplitsPerLocation: 476 numSplitsInGroup: 15 totalLength: 31733311148 numOriginalSplits: 476 . Grouping by length: true count: false nodeLocalOnly: false</p>
<p>åŸsplitsæ€»æ•°ç›®ä¸º 476ï¼Œåœ¨å¯¹splitsè¿›è¡Œgroupingæ—¶ï¼Œæ¯ä¸ªgroupä¸­å°†ä¼šåŒ…å«15ä¸ªinputSplitsï¼Œæ‰€ä»¥æœ€ç»ˆå¯ä»¥è®¡ç®—å‡ºçš„groupæ•°ç›®ä¸º 476&#x2F;15 &#x3D; 32 ä¸ªï¼Œä¹Ÿå°±æ˜¯æœ€ç»ˆç”Ÿæˆçš„mapperæ•°é‡ã€‚</p>
<p>|tez.SplitGrouper|: Original split count is 476 grouped split count is 32, for bucket: 1</p>
<p>|tez.HiveSplitGenerator|: Number of split groups: 32</p>
<p>æ‰€ä»¥åœ¨Tezä¸­ï¼ŒinputSplit æ•°ç›®è™½ç„¶æ˜¯476ä¸ªï¼Œä½†æ˜¯æœ€ç»ˆä»…ç”Ÿæˆäº†32ä¸ªmapä»»åŠ¡ç”¨äºå¤„ç†æ‰€æœ‰çš„ 475ä¸ªinputSplitsï¼Œå‡å°‘äº†è¿‡å¤šmapperä»»åŠ¡ä¼šå¸¦æ¥çš„é¢å¤–å¼€é”€ã€‚</p>
<br>
**Split Waves**
è¿™é‡Œä¸ºä»€ä¹ˆè¦å®šä¹‰ä¸€ä¸ªsplit waveså€¼å‘¢ï¼Ÿä½¿ç”¨æ­¤å€¼ä¹‹åä¼šè®©Driverç”³è¯·æ›´å¤šçš„containerï¼Œæ¯”å¦‚æ­¤åœºæ™¯ä¸­æœ¬æ¥ä»…æœ‰3ä¸ªslotså¯ç”¨ï¼Œä½†æ˜¯ä¼šæ ¹æ®è¿™ä¸ªä¹˜æ•°å†å¤šç”³è¯·2ä¸ªcontainerèµ„æºã€‚ä½†æ˜¯è¿™æ ·åšçš„åŸå› æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ
1. é¦–å…ˆå®ƒå¯ä»¥è®©åˆ†é…èµ„æºæ›´çµæ´»ï¼šæ¯”å¦‚é›†ç¾¤ä¹‹åæ·»åŠ äº†è®¡ç®—èŠ‚ç‚¹ã€å…¶ä»–ä»»åŠ¡å®Œæˆåé‡Šæ”¾äº†èµ„æºç­‰ã€‚æ‰€ä»¥å³ä½¿åˆšå¼€å§‹ä¼šæœ‰éƒ¨åˆ†mapä»»åŠ¡åœ¨ç­‰å¾…èµ„æºï¼Œå®ƒä»¬åœ¨åç»­ä¹Ÿä¼šå¾ˆå¿«è¢«åˆ†é…åˆ°èµ„æºæ‰§è¡Œä»»åŠ¡
2. å°†æ•°æ®åˆ†é…ç»™æ›´å¤šçš„mapä»»åŠ¡å¯ä»¥æé«˜å¹¶è¡Œåº¦ï¼Œå‡å°‘æ¯ä¸ªmapä»»åŠ¡ä¸­å¤„ç†çš„æ•°æ®é‡ï¼Œå¹¶ç¼“è§£ç”±äºå°‘éƒ¨åˆ†mapä»»åŠ¡æ‰§è¡Œè¾ƒæ…¢ï¼Œè€Œå¯¼è‡´çš„æ•´ä½“ä»»åŠ¡å˜æ…¢çš„æƒ…å†µ
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">æ–‡ç« ä½œè€…: </span><span class="post-copyright-info"><a href="http://example.com">CJ</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">æ–‡ç« é“¾æ¥: </span><span class="post-copyright-info"><a href="http://example.com/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1/Spark-Tez%E8%B0%83%E4%BC%98/">http://example.com/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1/Spark-Tez%E8%B0%83%E4%BC%98/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">ç‰ˆæƒå£°æ˜: </span><span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥è‡ª <a href="http://example.com" target="_blank">Hexo</a>ï¼</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%97%B6/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E6%A1%86%E6%9E%B6-1-13-0/" title="å®æ—¶æ•°ä»“æ¡†æ¶-1-13-0"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">ä¸Šä¸€ç¯‡</div><div class="prev_info">å®æ—¶æ•°ä»“æ¡†æ¶-1-13-0</div></div></a></div><div class="next-post pull-right"><a href="/2023/05/06/%E5%90%8E%E7%AB%AF%E6%A1%86%E6%9E%B6/Netty%E6%A1%86%E6%9E%B6/" title="Nettyæ¡†æ¶"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">ä¸‹ä¸€ç¯‡</div><div class="next_info">Nettyæ¡†æ¶</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">CJ</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">419</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">38</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>å…¬å‘Š</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>ç›®å½•</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81Spark"><span class="toc-number">1.</span> <span class="toc-text">ä¸€ã€Spark</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-%E5%8E%9F%E7%90%86%E8%AF%B4%E6%98%8E"><span class="toc-number">1.1.</span> <span class="toc-text">1.1 åŸç†è¯´æ˜</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0"><span class="toc-number">1.2.</span> <span class="toc-text">1.2 è°ƒä¼˜å‚æ•°</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-2-%E6%A1%88%E4%BE%8B%E4%BA%8C%EF%BC%9AGroupBy%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E4%BC%98%E5%8C%96"><span class="toc-number">1.2.1.</span> <span class="toc-text">1.3.2 æ¡ˆä¾‹äºŒï¼šGroupByå¯¼è‡´çš„æ•°æ®å€¾æ–œä¼˜åŒ–</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E9%97%AE%E9%A2%98"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">æ•°æ®å€¾æ–œé—®é¢˜</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-3-%E6%A1%88%E4%BE%8B%E4%B8%89%EF%BC%9AJOIN%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E4%BC%98%E5%8C%96"><span class="toc-number">1.2.2.</span> <span class="toc-text">1.3.3 æ¡ˆä¾‹ä¸‰ï¼šJOINå¯¼è‡´çš„æ•°æ®å€¾æ–œä¼˜åŒ–</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E6%80%9D%E8%B7%AF"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">ä¼˜åŒ–æ€è·¯</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-1-1-Map%E9%98%B6%E6%AE%B5%E5%B9%B6%E8%A1%8C%E5%BA%A6"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">1.4.1.1 Mapé˜¶æ®µå¹¶è¡Œåº¦</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-1-2-Reduce%E9%98%B6%E6%AE%B5%E5%B9%B6%E8%A1%8C%E5%BA%A6"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">1.4.1.2 Reduceé˜¶æ®µå¹¶è¡Œåº¦</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-2-%E5%B0%8F%E6%96%87%E4%BB%B6%E5%90%88%E5%B9%B6%E4%BC%98%E5%8C%96"><span class="toc-number">1.2.3.</span> <span class="toc-text">1.4.2 å°æ–‡ä»¶åˆå¹¶ä¼˜åŒ–</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-2-1-%E4%BC%98%E5%8C%96%E8%AF%B4%E6%98%8E"><span class="toc-number">1.2.3.1.</span> <span class="toc-text">1.4.2.1 ä¼˜åŒ–è¯´æ˜</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-2-2-Map%E7%AB%AF%E8%BE%93%E5%85%A5%E6%96%87%E4%BB%B6%E5%90%88%E5%B9%B6"><span class="toc-number">1.2.3.2.</span> <span class="toc-text">1.4.2.2 Mapç«¯è¾“å…¥æ–‡ä»¶åˆå¹¶</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-2-3-Reduce%E8%BE%93%E5%87%BA%E6%96%87%E4%BB%B6%E5%90%88%E5%B9%B6"><span class="toc-number">1.2.3.3.</span> <span class="toc-text">1.4.2.3 Reduceè¾“å‡ºæ–‡ä»¶åˆå¹¶</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-2-4-%E4%BB%8EHDFS%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E7%9A%84%E4%BB%BB%E5%8A%A1%E5%88%87%E5%88%86"><span class="toc-number">1.2.3.4.</span> <span class="toc-text">1.4.2.4 ä»HDFSè¯»å–æ•°æ®çš„ä»»åŠ¡åˆ‡åˆ†</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-3-Spark%E6%89%A7%E8%A1%8C%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE"><span class="toc-number">1.3.</span> <span class="toc-text">1.4.3 Sparkæ‰§è¡Œèµ„æºé…ç½®</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-5-%E5%85%B6%E4%BB%96%E4%BC%98%E5%8C%96"><span class="toc-number">1.3.1.</span> <span class="toc-text">1.4.5 å…¶ä»–ä¼˜åŒ–</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>æœ€æ–°æ–‡ç« </span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/MySQL/%E6%B3%A8%E8%A7%A3@Select%E5%92%8C@Insert/" title="æ³¨è§£@Selectå’Œ@Insert">æ³¨è§£@Selectå’Œ@Insert</a><time datetime="2023-05-06T05:48:28.906Z" title="å‘è¡¨äº 2023-05-06 13:48:28">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E5%90%8E%E7%AB%AF%E6%A1%86%E6%9E%B6/%E6%B3%A8%E8%A7%A3@EnableAutoConfiguration/" title="æ³¨è§£@EnableAutoConfiguration">æ³¨è§£@EnableAutoConfiguration</a><time datetime="2023-05-06T05:48:06.027Z" title="å‘è¡¨äº 2023-05-06 13:48:06">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A6%BB%E7%BA%BF/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7%E6%A1%86%E6%9E%B6/" title="å¤§æ•°æ®é›†ç¾¤ç›‘æ§æ¡†æ¶">å¤§æ•°æ®é›†ç¾¤ç›‘æ§æ¡†æ¶</a><time datetime="2023-05-06T05:42:56.298Z" title="å‘è¡¨äº 2023-05-06 13:42:56">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E9%AB%98%E5%B9%B6%E5%8F%91/HashMap%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98%E5%8F%8AConcurrentHashMap%E5%8E%9F%E7%90%86/" title="HashMapå¹¶å‘é—®é¢˜åŠConcurrentHashMapåŸç†">HashMapå¹¶å‘é—®é¢˜åŠConcurrentHashMapåŸç†</a><time datetime="2023-05-06T05:31:21.103Z" title="å‘è¡¨äº 2023-05-06 13:31:21">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E9%AB%98%E5%B9%B6%E5%8F%91/Stream%E5%8E%9F%E7%90%86/" title="StreamåŸç†">StreamåŸç†</a><time datetime="2023-05-06T05:31:21.103Z" title="å‘è¡¨äº 2023-05-06 13:31:21">2023-05-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By CJ</div><div class="framework-info"><span>æ¡†æ¶ </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>ä¸»é¢˜ </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="é˜…è¯»æ¨¡å¼"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="ç›®å½•"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>