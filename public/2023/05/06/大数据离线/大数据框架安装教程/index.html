<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>大数据框架安装教程 | Hexo</title><meta name="author" content="CJ"><meta name="copyright" content="CJ"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="一、架构![](大数据框架安装教程.assetsa6cb508aebd46f090309dfab8ebc2f3.png) 二、框架部署2.1 准备准备三台虚拟机，操作系统为CentOS 7.x，每台内存至少8G以上。 步骤：  关闭防火墙 创建hxr用户，设置密码，创建文件夹更改用户为hxr 配置ssh免密登录 安装jdk，设置环境变量 选择上海时间，并通过ntp同步互联网时间，通过cronta">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据框架安装教程">
<meta property="og:url" content="http://example.com/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A6%BB%E7%BA%BF/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="一、架构![](大数据框架安装教程.assetsa6cb508aebd46f090309dfab8ebc2f3.png) 二、框架部署2.1 准备准备三台虚拟机，操作系统为CentOS 7.x，每台内存至少8G以上。 步骤：  关闭防火墙 创建hxr用户，设置密码，创建文件夹更改用户为hxr 配置ssh免密登录 安装jdk，设置环境变量 选择上海时间，并通过ntp同步互联网时间，通过cronta">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2023-05-06T05:31:21.063Z">
<meta property="article:modified_time" content="2023-05-06T05:31:21.063Z">
<meta property="article:author" content="CJ">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A6%BB%E7%BA%BF/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '大数据框架安装教程',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-05-06 13:31:21'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">419</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">38</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Hexo"><span class="site-name">Hexo</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">大数据框架安装教程</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-05-06T05:31:21.063Z" title="发表于 2023-05-06 13:31:21">2023-05-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-05-06T05:31:21.063Z" title="更新于 2023-05-06 13:31:21">2023-05-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A6%BB%E7%BA%BF/">大数据离线</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="大数据框架安装教程"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="一、架构"><a href="#一、架构" class="headerlink" title="一、架构"></a>一、架构</h1><p>![](大数据框架安装教程.assetsa6cb508aebd46f090309dfab8ebc2f3.png)</p>
<h1 id="二、框架部署"><a href="#二、框架部署" class="headerlink" title="二、框架部署"></a>二、框架部署</h1><h2 id="2-1-准备"><a href="#2-1-准备" class="headerlink" title="2.1 准备"></a>2.1 准备</h2><p>准备三台虚拟机，操作系统为CentOS 7.x，每台内存至少8G以上。</p>
<p>步骤：</p>
<ol>
<li>关闭防火墙</li>
<li>创建hxr用户，设置密码，创建文件夹更改用户为hxr</li>
<li>配置ssh免密登录</li>
<li>安装jdk，设置环境变量</li>
<li>选择上海时间，并通过ntp同步互联网时间，通过crontab指令同步集群服务器时间</li>
</ol>
<h3 id="2-1-1-关闭防火墙"><a href="#2-1-1-关闭防火墙" class="headerlink" title="2.1.1 关闭防火墙"></a>2.1.1 关闭防火墙</h3><p><strong>关闭防火墙并停止开机自启(CentOS7)</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --state  # 查看防火墙状态</span><br><span class="line"></span><br><span class="line">systemctl start firewalld  # 开启防火墙</span><br><span class="line"></span><br><span class="line">systemctl stop firewalld  # 关闭防火墙</span><br><span class="line"></span><br><span class="line">systemctl disable firewalld  # 禁止防火墙开机启动</span><br><span class="line"></span><br><span class="line">systemctl enable firewalld  # 设置防火墙开机启动</span><br></pre></td></tr></table></figure>



<h3 id="2-1-2-创建hxr用户"><a href="#2-1-2-创建hxr用户" class="headerlink" title="2.1.2 创建hxr用户"></a>2.1.2 创建hxr用户</h3><p><strong>创建新用户hxr</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">useradd hxr</span><br></pre></td></tr></table></figure>

<p><strong>设置密码</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">passwd hxr</span><br></pre></td></tr></table></figure>

<p><strong>设置用户权限</strong></p>
<p>在&#x2F;etc&#x2F;sudoers文件中添加    <code>hxr ALL=(ALL) NOPASSWD:ALL</code><br>表示该用户或组执行来自任何计算机的所有用户和所有组的命令都不需要密码。<br>执行<code>visudo -c</code>检查文件是否正常</p>
<p><strong>创建文件夹用于框架安装</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/module /opt/software   # 在/opt 目录下创建两个文件夹module和software</span><br><span class="line">chown hxr:hxr /opt/module /opt/software   #并将所有权给hxr</span><br></pre></td></tr></table></figure>





<h3 id="2-1-3-配置ssh免密登录"><a href="#2-1-3-配置ssh免密登录" class="headerlink" title="2.1.3 配置ssh免密登录"></a>2.1.3 配置ssh免密登录</h3><p><strong>登录到hxr用户，配置免密登陆。</strong></p>
<ol>
<li>生成密钥对</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p>发送公钥到本机<br>将公钥发送到user@host上，即可免密登陆该host节点。该命令会将公钥写到指定节点host的.ssh&#x2F;authorized_keys文件中，拥有该文件中的公钥对应私钥的节点都允许远程登录。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id bigdata1</span><br></pre></td></tr></table></figure>
</li>
<li><p>分别ssh登陆一下所有虚拟机</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh bigdata2</span><br><span class="line">ssh bigdata3</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>把&#x2F;home&#x2F;hxr&#x2F;.ssh 文件夹发送到集群所有服务器</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsyncmy /home/hxr/.ssh</span><br></pre></td></tr></table></figure>

<blockquote>
<p>需要创建自定义xsyncmy脚本：见  [第四章  4.5 shell脚本]，在&#x2F;usr&#x2F;bin目录下创建脚本。</p>
</blockquote>
<h3 id="2-1-4-安装jdk，设置环境变量"><a href="#2-1-4-安装jdk，设置环境变量" class="headerlink" title="2.1.4 安装jdk，设置环境变量"></a>2.1.4 安装jdk，设置环境变量</h3><p>将JDK的安装包放入到&#x2F;opt&#x2F;software文件夹下，通过如下命令将安装包解压到&#x2F;opt&#x2F;module文件夹下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar –zxvf [安装包] -C [目标路径]</span><br></pre></td></tr></table></figure>

<p>在&#x2F;etc&#x2F;profile.d文件夹中添加脚本env.sh （好处就是shell登录和ssh登录都会加载该环境变量）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># JAVA_HOME</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br></pre></td></tr></table></figure>





<h3 id="2-1-5-节点间时间同步"><a href="#2-1-5-节点间时间同步" class="headerlink" title="2.1.5 节点间时间同步"></a>2.1.5 节点间时间同步</h3><p><strong>选择上海时间，并通过ntp同步互联网时间，通过crontab指令同步集群服务器时间。</strong></p>
<h4 id="时间服务器配置"><a href="#时间服务器配置" class="headerlink" title="时间服务器配置"></a>时间服务器配置</h4><ol>
<li>安装ntp</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum –y install ntp</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p>修改ntp配置文件  vim &#x2F;etc&#x2F;ntp.conf</p>
<ul>
<li><p>修改1（授权192.168.1.0-192.168.32.255网段上的所有机器可以从这台机器上查询和同步时间）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#restrict 127.0.0.1  # 注销语句</span><br><span class="line">restrict 192.168.32.0 mask 255.255.255.0 nomodify notrap   # 添加语句</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改2（集群在局域网中，不使用其他互联网上的时间）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#server 0.centos.pool.ntp.org iburst  # 注销语句</span><br><span class="line">#server 1.centos.pool.ntp.org iburst  # 注销语句</span><br><span class="line">#server 2.centos.pool.ntp.org iburst  # 注销语句</span><br><span class="line">#server 3.centos.pool.ntp.org iburst  # 注销语句</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#将本机作为时钟源</span><br><span class="line">server  127.127.1.0   # 添加语句</span><br><span class="line">fudge  127.127.1.0  stratum  10# 添加语句</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>修改ntpd配置文件   vim  &#x2F;etc&#x2F;sysconfig&#x2F;ntpd</p>
<p>增加内容如下（让硬件时间与系统时间一起同步）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 让硬件时间与系统时间一起同步</span><br><span class="line">SYNC_HWCLOCK=yes</span><br></pre></td></tr></table></figure>


</li>
<li><p>启动ntpd服务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable ntpd</span><br><span class="line">systemctl restart ntpd</span><br></pre></td></tr></table></figure>


</li>
<li><p>选择Shanghai时区作为节点时区</p>
</li>
</ol>
<p>   如果在&#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;这个目录下不存在时区配置文件Asia&#x2F;Shanghai，就要用 tzselect 生成。</p>
   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tzselect</span><br></pre></td></tr></table></figure>

<p>   拷贝该时区文件，覆盖系统本地时区配置</p>
   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm /etc/localtime</span><br><span class="line">ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br></pre></td></tr></table></figure>



<h4 id="其他节点配置"><a href="#其他节点配置" class="headerlink" title="其他节点配置"></a>其他节点配置</h4><p>安装组件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y ntpdate</span><br></pre></td></tr></table></figure>

<p>在其他机器配置10分钟与时间服务器同步一次</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crontab -e</span><br></pre></td></tr></table></figure>

<p>输入如下文本后保存(设置每10秒同步一次)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/10 * * * * /usr/sbin/ntpdate bigdata1</span><br></pre></td></tr></table></figure>



<p>为了验证时间同步是否生效，可以设置 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">date -s &quot;2008-8-8 8:8:8&quot;</span><br></pre></td></tr></table></figure>

<p> 修改时间，date观察时间是否同步。</p>
<h2 id="2-2-核心框架"><a href="#2-2-核心框架" class="headerlink" title="2.2 核心框架"></a>2.2 核心框架</h2><table>
<thead>
<tr>
<th></th>
<th>Bigdata1</th>
<th>Bigdata2</th>
<th>Bigdata3</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>NameNode<br />DataNode</td>
<td>DataNode</td>
<td>DataNode<br />SecondaryNameNode</td>
</tr>
<tr>
<td>Yarn</td>
<td>NodeManager</td>
<td>Resourcemanager<br />NodeManager</td>
<td>NodeManager</td>
</tr>
<tr>
<td>Zookeeper</td>
<td>QuorumPeerMain</td>
<td>QuorumPeerMain</td>
<td>QuorumPeerMain</td>
</tr>
<tr>
<td>Flume</td>
<td>Application</td>
<td>Application</td>
<td></td>
</tr>
<tr>
<td>Kafka</td>
<td>Kafka</td>
<td>Kafka</td>
<td>Kafka</td>
</tr>
<tr>
<td>Hive</td>
<td>RunJar<br />RunJar</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Sqoop</td>
<td>Sqoop</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Azkaban</td>
<td>AzkabanExecutorServer<br />AzkabanWebServer</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Hbase</td>
<td>HMaster<br />HRegionServer</td>
<td>HRegionServer</td>
<td>HRegionServer</td>
</tr>
<tr>
<td>Flink</td>
<td>YarnSessionClusterEntrypoint<br />YarnTaskExecutorRunner</td>
<td>FlinkYarnSessionCli<br />YarnTaskExecutorRunner</td>
<td>YarnTaskExecutorRunner</td>
</tr>
<tr>
<td>Clickhouse</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Atlas</td>
<td>Atlas</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Ganglia</td>
<td></td>
<td>ganglia</td>
<td></td>
</tr>
<tr>
<td>Zabbix</td>
<td>zabbix-server<br />zabbix-agent</td>
<td>zabbix-agent</td>
<td>zabbix-agent</td>
</tr>
<tr>
<td>Solr</td>
<td>jar</td>
<td>jar</td>
<td>jar</td>
</tr>
<tr>
<td>MySQL</td>
<td></td>
<td></td>
<td>MySQL</td>
</tr>
<tr>
<td>Spark-session</td>
<td>YarnCoarseGrainedExecutorBackend</td>
<td>YarnCoarseGrainedExecutorBackend</td>
<td>YarnCoarseGrainedExecutorBackend</td>
</tr>
</tbody></table>
<h3 id="2-2-1-Hadoop-2-7-2"><a href="#2-2-1-Hadoop-2-7-2" class="headerlink" title="2.2.1 Hadoop 2.7.2"></a>2.2.1 Hadoop 2.7.2</h3><h4 id="安装应用"><a href="#安装应用" class="headerlink" title="安装应用"></a>安装应用</h4><p>将hadoop-2.7.2.tar.gz安装包放入bigdata1节点的&#x2F;opt&#x2F;software文件夹下，通过如下命令将安装包解压到&#x2F;opt&#x2F;module文件夹下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar –zxvf hadoop-2.7.2.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>重命名解压后的文件为hadoop-2.7.2</p>
<h4 id="定义环境变量"><a href="#定义环境变量" class="headerlink" title="定义环境变量"></a>定义环境变量</h4><p>修改&#x2F;etc&#x2F;profile.d&#x2F;env.sh文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># JAVA_HOME</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop-2.7.2</span><br><span class="line"><span class="built_in">export</span>  PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br><span class="line"><span class="comment">#设置pid的存储路径，避免tmp清理时将pid删除，导致集群关闭脚本失效。</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_PID_DIR=<span class="variable">$&#123;HADOOP_HOME&#125;</span>/pids</span><br></pre></td></tr></table></figure>



<h4 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h4><p><strong>在bigdata1节点上的 &#x2F;opt&#x2F;module&#x2F;hadoop-2.7.2&#x2F;etc&#x2F;hadoop 路径下修改如下配置文件</strong></p>
<ul>
<li><p>core-site.xml   添加如下配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://bigdata1:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>hdfs-site.xml   添加如下配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 数据的副本数量 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata3:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  </span><br><span class="line"><span class="comment">&lt;!-- 如果有多个挂载点，需要对其进行配置--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">&lt;property&gt;</span></span><br><span class="line"><span class="comment">	&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span></span><br><span class="line"><span class="comment">       &lt;value&gt;file:///$&#123;hadoop.tmp.dir&#125;/dfs/data1,file:///dev/dfs/data2&lt;/value&gt;</span></span><br><span class="line"><span class="comment">&lt;/property&gt;</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>yarn-site.xml   添加如下配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 日志聚集功能使能 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 日志保留时间设置7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>mapred-site.xml   添加如下配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 资源调度器使用yarn --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata3:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata3:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>hadoop-env.sh   修改如下配置</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=<span class="variable">$&#123;JAVA_HOME&#125;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>yarn-env.sh   修改如下配置</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=<span class="variable">$&#123;JAVA_HOME&#125;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>mapred-env.sh   修改如下配置</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=<span class="variable">$&#123;JAVA_HOME&#125;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>slaves   添加如下配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bigdata1</span><br><span class="line">bigdata2</span><br><span class="line">bigdata3</span><br></pre></td></tr></table></figure>

<p>注：需要注意不能出现空行，否则集群启动会有问题</p>
</li>
</ul>
<h4 id="分发Hadoop到其他节点"><a href="#分发Hadoop到其他节点" class="headerlink" title="分发Hadoop到其他节点"></a>分发Hadoop到其他节点</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsyncmy /opt/module/hadoop-2.7.2</span><br></pre></td></tr></table></figure>



<h4 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h4><p>在bigdata1节点上格式化NameNode</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs namenode –format </span><br></pre></td></tr></table></figure>

<p>在bigdata1节点上启动hdfs</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>

<p>在bigdata2节点上启动yarn</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>

<p>在bigdata3节点上启动历史服务器</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>
<p>或</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mapred --daemon start historyserver</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>对hadoop集群的操作：</strong><br>start-dfs.sh  stop-dfs.sh   打开和关闭dfs<br>start-yarn.sh  stop-yarn.sh   打开和关闭yarn<br>hadoop-deamon.sh  start或stop  namenode或datanode   在本机上操作后台进程<br>yarn-deamon.sh  start或stop  resourcemanager或nodemanager  在本机上操作进程<br>hadoop-deamons.sh  start或stop  namenode或datanode   在集群上操作后台进程<br>yarn-deamons.sh  start或stop  resourcemanager或nodemanager  在集群上操作进程</p>
</blockquote>
<p><strong>正常情况下各节点进程如下</strong></p>
<ul>
<li><strong>bigdata1:</strong><br>NameNode<br>NodeManager<br>DataNode</li>
<li><strong>bigdata2:</strong><br>ResourceManager<br>NodeManager<br>DataNode</li>
<li><strong>bigdata3:</strong><br>Secondary NameNode<br>NodeManager<br>DataNode<br>JobHistoryServer</li>
</ul>
<p>如果出现问题，先停止所有hadoop进程</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sbin/stop-dfs.sh</span><br><span class="line">sbin/stop-yarn.sh</span><br></pre></td></tr></table></figure>

<p>对集群进行格式化</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> –rf /opt/module/hadoop-2.7.2/data /opt/module/hadoop-2.7.2/logs   <span class="comment"># 删除数据和日志文件</span></span><br><span class="line">bin/hdfs namenode -format   <span class="comment"># 格式化集群</span></span><br></pre></td></tr></table></figure>

<p>检查配置文件等有无错误，找到并修复问题后重启集群。</p>
<p><strong>验证集群是否正常工作</strong></p>
<p>在&#x2F;opt&#x2F;module&#x2F;hadoop-2.7.2目录下执行如下命令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs –put README.txt /   <span class="comment"># 将需要进行处理的文件上传到集群中</span></span><br><span class="line"></span><br><span class="line">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /README.txt /output   <span class="comment"># 调用hadoop自带的wordcount程序对文件中的单词进行wordcount</span></span><br><span class="line"></span><br><span class="line">hadoop fs –get /output /opt/module/hadoop-2.7.2   <span class="comment"># 从集群中下载输出的文件</span></span><br></pre></td></tr></table></figure>

<p>查看下载下来的输出文件是否正常，正常则集群可以正常工作。</p>
<h4 id="Web界面"><a href="#Web界面" class="headerlink" title="Web界面"></a>Web界面</h4><p>bigdata1:50070 hdfs页面</p>
<p>bigdata2:8088 yarn页面</p>
<p>bigdata3:19888 历史服务器页面</p>
<h4 id="hadoop的最终配置文件"><a href="#hadoop的最终配置文件" class="headerlink" title="hadoop的最终配置文件"></a>hadoop的最终配置文件</h4><p>core-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;hdfs://bigdata1:9000&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;io.compression.codecs&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;</span><br><span class="line">		org.apache.hadoop.io.compress.GzipCodec,</span><br><span class="line">		org.apache.hadoop.io.compress.DefaultCodec,</span><br><span class="line">		org.apache.hadoop.io.compress.BZip2Codec,</span><br><span class="line">		org.apache.hadoop.io.compress.SnappyCodec,</span><br><span class="line">		com.hadoop.compression.lzo.LzoCodec,</span><br><span class="line">		com.hadoop.compression.lzo.LzopCodec</span><br><span class="line">		&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;io.compression.codecs.lzo.class&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;hadoop.proxyuser.hxr.groups&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;*&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">    	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;hadoop.proxyuser.hxr.hosts&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;*&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>hdfs-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;3&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;bigdata3:50090&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>mapred-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;bigdata3:10020&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;bigdata3:19888&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">	&lt;!-- add chengwei 20210616 for add memory --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">	　　&lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt;</span><br><span class="line">	　　&lt;value&gt;1536&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">	　　&lt;name&gt;mapreduce.map.java.opts&lt;/name&gt;</span><br><span class="line">	　　&lt;value&gt;-Xmx1024M&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">	　　&lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt;</span><br><span class="line">	　　&lt;value&gt;3072&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">	　　&lt;name&gt;mapreduce.reduce.java.opts&lt;/name&gt;</span><br><span class="line">	　　&lt;value&gt;-Xmx2560M&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>yarn-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;bigdata2&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;true&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;604800&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;false&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;false&lt;/value&gt;</span><br><span class="line">		&lt;description&gt;是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true &lt;/description&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;true&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">       &lt;property&gt;  </span><br><span class="line">        &lt;name&gt;yarn.log.server.url&lt;/name&gt;  </span><br><span class="line">        &lt;value&gt;http://bigdata3:19888/jobhistory/logs&lt;/value&gt;  </span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>


<h3 id="2-2-2-Zookeeper-3-4-10"><a href="#2-2-2-Zookeeper-3-4-10" class="headerlink" title="2.2.2 Zookeeper 3.4.10"></a>2.2.2 Zookeeper 3.4.10</h3><h4 id="安装应用-1"><a href="#安装应用-1" class="headerlink" title="安装应用"></a>安装应用</h4><p>将zookeeper-3.4.10.tar.gz安装包放入bigdata1节点的&#x2F;opt&#x2F;software文件夹下，通过如下命令将安装包解压到&#x2F;opt&#x2F;module文件夹下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar –zxvf zookeeper-3.4.10.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>重命名解压后的文件为zookeeper-3.4.10</p>
<h4 id="配置文件-1"><a href="#配置文件-1" class="headerlink" title="配置文件"></a>配置文件</h4><ol>
<li><p>重命名&#x2F;conf这个目录下的zoo_sample.cfg为zoo.cfg</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv /opt/module/zookeeper-3.4.10/conf/zoo_sample.cfg  /opt/module/zookeeper-3.4.10/conf/zoo.cfg</span><br></pre></td></tr></table></figure>

<ul>
<li><p>修改文件中的dataDir路径</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">dataDir</span>=<span class="string">/opt/module/zookeeper-3.4.10/zkData</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>新增如下</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server.1</span>=<span class="string">bigdata1:2888:3888</span></span><br><span class="line"><span class="attr">server.2</span>=<span class="string">bigdata2:2888:3888</span></span><br><span class="line"><span class="attr">server.3</span>=<span class="string">bigdata3:2888:3888</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>server.2是id号，只要不重复就可以。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>在 &#x2F;opt&#x2F;module&#x2F;zookeeper-3.4.10&#x2F; 目录下创建zkData，在&#x2F;opt&#x2F;module&#x2F;zookeeper-3.4.10&#x2F;zkData目录下创建myid的文件，将本机的server号写入</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1</span><br></pre></td></tr></table></figure>
</li>
<li><p>日志输出位置<br>在bin&#x2F;zkEnv.sh中的开头添加一行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZOO_LOG_DIR=/opt/module/zookeeper-3.4.10/logs</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="分发Zookeeper到其他节点"><a href="#分发Zookeeper到其他节点" class="headerlink" title="分发Zookeeper到其他节点"></a>分发Zookeeper到其他节点</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsyncmy /opt/module/zookeeper-3.4.10</span><br></pre></td></tr></table></figure>

<p>注意：需要修改其他节点的&#x2F;opt&#x2F;module&#x2F;zookeeper-3.4.10&#x2F;zkData&#x2F;myid文件，为每个节点分配不同的server号(对应server.1&#x2F;server.2&#x2F;server.3)。</p>
<h4 id="启动集群-1"><a href="#启动集群-1" class="headerlink" title="启动集群"></a>启动集群</h4><p>在每个节点上启动zookeeper进程</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zkServer.sh start</span><br></pre></td></tr></table></figure>

<p>检查每个节点的状态</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zkServer.sh status</span><br></pre></td></tr></table></figure>

<p>关闭节点的zookeeper进程</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zkServer.sh stop</span><br></pre></td></tr></table></figure>



<h3 id="2-2-3-Flume-1-7-0"><a href="#2-2-3-Flume-1-7-0" class="headerlink" title="2.2.3 Flume 1.7.0"></a>2.2.3 Flume 1.7.0</h3><h4 id="安装应用-2"><a href="#安装应用-2" class="headerlink" title="安装应用"></a>安装应用</h4><p>将apache-flume-1.7.0-bin.tar.gz安装包放入bigdata1节点的&#x2F;opt&#x2F;software文件夹下，通过如下命令将安装包解压到&#x2F;opt&#x2F;module文件夹下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar –zxvf apache-flume-1.7.0-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>重命名解压后的文件为flume-1.7.0</p>
<h4 id="配置文件-2"><a href="#配置文件-2" class="headerlink" title="配置文件"></a>配置文件</h4><ol>
<li><p>修改flume-1.7.0&#x2F;conf中的flume-env.sh文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=<span class="variable">$&#123;JAVA_HOME&#125;</span></span><br><span class="line"><span class="built_in">export</span> JAVA_OPTS=<span class="string">&quot;-Xms100m -Xmx2000m -Dcom.sun.management.jmxremote&quot;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>-Xms和-Xmx推荐设置为一样大小，避免内存抖动。</p>
</blockquote>
</li>
<li><p>conf中的log4j.properties配置文件。</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">flume.log.dir</span>=<span class="string">/opt/module/flume-1.7.0/logs  # 指定输出日志位置</span></span><br></pre></td></tr></table></figure>

<p>log4j.root.logger指定了输出模式，将flume.root.logger改了也就改了输出模式。默认输出到log4j文件中，可以在配置文件中改为输出到console中（INFO，console）。也可以在命令中加上-D参数，将输出目的地改为控制台（-Dflume.root.logger&#x3D;INFO，console）。</p>
</li>
</ol>
<h4 id="任务文件"><a href="#任务文件" class="headerlink" title="任务文件"></a>任务文件</h4><p>针对不同的业务逻辑需要配置不同的文件。在启动时作为需要作为配置参数传入内存。</p>
<p>例：创建&#x2F;opt&#x2F;module&#x2F;flume-1.7.0&#x2F;job&#x2F;file-kafka-hdfs.conf文件</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># agent</span></span><br><span class="line"><span class="attr">a1.sources</span> = <span class="string">r1</span></span><br><span class="line"><span class="attr">a1.channels</span> = <span class="string">c1 c2</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = <span class="string">TAILDIR</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = <span class="string">c1 c2</span></span><br><span class="line"><span class="attr">a1.sources.r1.positionFile</span> = <span class="string">/opt/module/flume-1.7.0/taildir_position.json</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups</span> = <span class="string">f1</span></span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.f1</span> = <span class="string">/tmp/logs/q6/.*log</span></span><br><span class="line"><span class="attr">a1.sources.r1.fileHeader</span> = <span class="string">false</span></span><br><span class="line"><span class="attr">a1.sources.r1.maxBatchCount</span> = <span class="string">1000</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#设置拦截器</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors</span> = <span class="string">i1 i2</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i1.type</span> = <span class="string">com.hxr.flume.LogETLInterceptor$Builder</span></span><br><span class="line"><span class="attr">a1.sources.r1.interceptors.i2.type</span> = <span class="string">com.hxr.flume.LogTypeInterceptor$Builder</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#设置选择器</span></span><br><span class="line"><span class="attr">a1.sources.r1.selector.type</span> = <span class="string">multiplexing</span></span><br><span class="line"><span class="attr">a1.sources.r1.selector.header</span> = <span class="string">topic</span></span><br><span class="line"><span class="attr">a1.sources.r1.selector.mapping.Log_Q6</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sources.r1.selector.mapping.Log_E5</span> = <span class="string">c2</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#channel</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = <span class="string">org.apache.flume.channel.kafka.KafkaChannel</span></span><br><span class="line"><span class="attr">a1.channels.c1.kafka.bootstrap.servers</span> = <span class="string">BigData1:9092,BigData2:9092,BigData3:9092</span></span><br><span class="line"><span class="attr">a1.channels.c1.kafka.topic</span> = <span class="string">Log_Q6</span></span><br><span class="line"><span class="attr">a1.channels.c1.parseAsFlumeEvent</span> = <span class="string">false</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c2.type</span> = <span class="string">org.apache.flume.channel.kafka.KafkaChannel</span></span><br><span class="line"><span class="attr">a1.channels.c2.kafka.bootstrap.servers</span> = <span class="string">BigData1:9092,BigData2:9092,BigData3:9092</span></span><br><span class="line"><span class="attr">a1.channels.c2.kafka.topic</span> = <span class="string">Log_E5</span></span><br><span class="line"><span class="attr">a1.channels.c2.parseAsFlumeEvent</span> = <span class="string">false</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#sink</span></span><br><span class="line"><span class="attr">a1.sinks</span> = <span class="string">k1 k2</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = <span class="string">hdfs</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.path</span> = <span class="string">/origin_data/device_model_log/logs/q6/%Y-%m-%d</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.filePrefix</span> = <span class="string">q6-</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollInterval</span> = <span class="string">3600</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollSize</span> = <span class="string">134217728</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollCount</span> = <span class="string">0</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.useLocalTimeStamp</span> = <span class="string">true</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k2.type</span> = <span class="string">hdfs</span></span><br><span class="line"><span class="attr">a1.sinks.k2.channel</span> = <span class="string">c2</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.path</span> = <span class="string">/origin_data/device_model_log/logs/e5/%Y-%m-%d</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.filePrefix</span> = <span class="string">e5-</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.rollInterval</span> = <span class="string">3600</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.rollSize</span> = <span class="string">134217728</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.rollCount</span> = <span class="string">0</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.useLocalTimeStamp</span> = <span class="string">true</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#压缩格式</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.codeC</span> = <span class="string">lzop</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileType</span> = <span class="string">CompressedStream</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.codeC</span> = <span class="string">lzop</span></span><br><span class="line"><span class="attr">a1.sinks.k2.hdfs.fileType</span> = <span class="string">CompressedStream</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#拼装</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = <span class="string">c1</span></span><br><span class="line"><span class="attr">a1.sinks.k2.channel</span> = <span class="string">c2</span></span><br></pre></td></tr></table></figure>

<h4 id="单点启动"><a href="#单点启动" class="headerlink" title="单点启动"></a>单点启动</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/module/flume-1.7.0/bin/flume-ng agent -n a1 -c /opt/module/flume-1.7.0/conf -f /opt/module/flume-1.7.0/job/file-kafka-hdfs.conf</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>参数解释</strong></p>
<p>-n：任务名称<br>-c：指定配置文件<br>-f：指定任务文件</p>
</blockquote>
<h3 id="2-2-4-Kafka-2-11"><a href="#2-2-4-Kafka-2-11" class="headerlink" title="2.2.4 Kafka 2.11"></a>2.2.4 Kafka 2.11</h3><h4 id="安装应用-3"><a href="#安装应用-3" class="headerlink" title="安装应用"></a>安装应用</h4><p>将kafka_2.11-0.11.0.2.tgz安装包放入bigdata1节点的&#x2F;opt&#x2F;software文件夹下，通过如下命令将安装包解压到&#x2F;opt&#x2F;module文件夹下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar –zxvf kafka_2.11-0.11.0.2.tgz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>重命名解压后的文件为kafka-2.11</p>
<h4 id="配置文件-3"><a href="#配置文件-3" class="headerlink" title="配置文件"></a>配置文件</h4><p>修改kafka-2.11&#x2F;config&#x2F;server.properties文件</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#broker的全局唯一编号，不能重复</span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="string">0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#删除topic功能使能</span></span><br><span class="line"><span class="attr">delete.topic.enable</span>=<span class="string">true #是否真正删除topic</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#kafka运行日志存放的路径</span></span><br><span class="line"><span class="attr">log.dirs</span>=<span class="string">/opt/module/kafka-2.11/logs</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#配置连接Zookeeper集群地址</span></span><br><span class="line"><span class="attr">zookeeper.connect</span>=<span class="string">bigdata1:2181,bigdata2:2181,bigdata3:2181 #所有的kafka相关节点  都会存储在zookeeper的根目录下，可以在后面加上节点名称，将所有节点存储在该节点下。</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>真正删除topic</strong><br>找到要删除的topic，执行命令：rmr &#x2F;brokers&#x2F;topics&#x2F;【topic name】即可，此时topic被彻底删除。被标记为marked for deletion的topic可以在zookeeper客户端中通过命令获得：ls &#x2F;admin&#x2F;delete_topics&#x2F;【topic name】，如果你删除了此处的topic，那么marked for deletion 标记消失。<br><strong>配置listener和advertised.listener</strong><br>listeners学名叫监听器，就是tcp的侦听ip。可以在某个固定的ip上侦听，也可以是全网段进行侦听（0.0.0.0）。如果是在某个固定ip上侦听，例如“127.0.0.1”，那么只有与该ip正确连接的客户端能成功连接到kafka；而如果是全网段侦听，那么可以与kafka所在机器的任意ip进行连接并访问kafka。<br>与kafka连接成功后，并不代表可以顺利读取和写入数据。由于向topic的分区进行生产消费，最终都要和分区的leader进行交互。因此，获取到元数据信息后，客户端（生产者或消费者）会和topic分区的leader所在的broker建立新的tcp连接以进行后续的生产消费。<br>advertised.listeners配置的是kafka的broker ip，kafka成功注册zookeeper后，会将broker ip写入到kafka中。这样kafka集群中的每个节点都能知道其他所有节点的broker ip。在没有配置advertised.listeners的情况下，默认取值为kafka所在机器的主机名，端口与listeners中配置的端口一致。也就是kafka的broker ip是kafka所在机器的主机名。很多情况下，与kafka连接成功但无法正确生产消费的原因就是kafka的主机名无法被正确解析，最常见的就是kafka的主机名为localhost。</p>
</blockquote>
<h4 id="分发Kafka到其他节点"><a href="#分发Kafka到其他节点" class="headerlink" title="分发Kafka到其他节点"></a>分发Kafka到其他节点</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsyncmy /opt/module/kafka-2.11</span><br></pre></td></tr></table></figure>

<p>注意：需要修改其他节点的&#x2F;opt&#x2F;module&#x2F;kafka-2.11&#x2F;config&#x2F;server.properties文件中的broker.id名，不能重复。</p>
<h4 id="压测"><a href="#压测" class="headerlink" title="压测"></a>压测</h4><p><strong>写入消息</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./kafka-producer-perf-test.sh --topic test --num-records 1000000 --record-size 1000 --throughput 20000  --producer-props  bootstrap.servers=bigdata1:9092</span><br></pre></td></tr></table></figure>

<blockquote>
<p>–num-records 总共需要发送的消息数，本例为1000000<br>–record-size 每个记录的字节数，本例为1000<br>–throughput 每秒钟发送的记录数，本例为20000</p>
</blockquote>
<p><strong>消费消息</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-perf-test.sh --zookeeper bigdata1:2181 --topic test --fetch-size 1048576 --messages 1000000 --threads 1</span><br></pre></td></tr></table></figure>

<blockquote>
<p>–fetch-size 指定每次fetch的数据的大小，本例为1048576，也就是1M<br>–messages 总共要消费的消息个数，本例为1000000，100w</p>
</blockquote>
<h4 id="启动集群-2"><a href="#启动集群-2" class="headerlink" title="启动集群"></a>启动集群</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-start.sh -daemon config/server.properties</span><br><span class="line"></span><br><span class="line">bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure>



<h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><p><strong>对topic的增删改查</strong></p>
<ul>
<li><p>查看所有的topic</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh  --zookeeper bigdata1:2181  --list   </span><br></pre></td></tr></table></figure>
</li>
<li><p>创建一个名为first，分区数为3，副本数为2的topic</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh  --zookeeper bigdata1:2181  --create --topic first  --partitions 3  --replication-factor 2 </span><br></pre></td></tr></table></figure>
</li>
<li><p>查看名为first的topic的具体参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh  --zookeeper bigdata1:2181  --describe  --topic first </span><br></pre></td></tr></table></figure>
<p>分别表示topic名、分区号、该分区leader所在的brokerid、副本号、副本所在brokerid、可以同步的副本所在的brokerid<br>![image.png](大数据框架安装教程.assetsa0a2ceb65b94e4481bae1486d5146d7.png)</p>
</li>
<li><p>修改分区数或副本数（分区数只能增不能减，副本数可增可减）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh  --zookeeper bigdata1:2181  --alter  --topic first  --partitions 5</span><br></pre></td></tr></table></figure>
<p>在bigdata1的logs文件夹中可以查看该节点存储的副本文件first-n（n表示分区号）。分区0存储在broker0、1上，分区2存储在broker2、0上，分区3存储在broker0、2上、分区4存储在broker1、0上。综上，bigdata1存储了分区0、2、3、4的副本，与logs中的first副本文件对应。</p>
<p><img src="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B.assets%5C61486d698a51469e9f104d348f197430.png" alt="image.png"></p>
<p><img src="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B.assets%5C5d5fc293cbfc417da82b54086891bf1a.png" alt="image.png"></p>
</li>
<li><p>删除topic</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh  --zookeeper bigdata1:2181  --delete  --topic first</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果在server.properties中将 delete.topic.enable&#x3D;true，那么删除时就会将原数据删除。否则只会删除zk上的节点，原数据不会删除。</p>
</blockquote>
</li>
<li><p>生产数据到topic中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list bigdata2:9092,bigdata3:9092  --topic first</span><br></pre></td></tr></table></figure>
</li>
<li><p>从topic中读取数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server bigdata1:9092 --topic first [from-beginning]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>可以指定消费组的offset，默认是latest</p>
</blockquote>
</li>
<li><p>展示当前正在消费的消费者组的信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh  --bootstrap-server  bigdata1:9092   --list</span><br></pre></td></tr></table></figure>

<p><img src="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B.assets%5C648c08ea32104599948489c2671c92ee.png" alt="image.png"></p>
</li>
<li><p>监控某一消费者消费了哪些topic（一个消费者组可以消费多个topic）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh  --bootstrap-server hadoop102:9092  --describe  --group id</span><br></pre></td></tr></table></figure>
<p><img src="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B.assets%5C13f64b376a164395a253a096c88a8496.png" alt="image.png"></p>
<blockquote>
<p>这两个脚本直接从服务器上获取元数据，得到leader的信息；底层也是调用生产者和消费者的api。</p>
</blockquote>
</li>
</ul>
<br>
**不常用命令**
- 如新增了节点，需要重新分配分区，将数据均衡。资源消耗很大。
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reassign-partitions.sh  </span><br></pre></td></tr></table></figure>

<ul>
<li><p>每一个partition的leader的重新选举。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">preferred-replica-election.sh</span><br></pre></td></tr></table></figure>
<blockquote>
<p>将leader分布在不同节点上，缓解压力。一台leader挂了，其他副本会成为leader，可能会在同一个broker有多个leader，原leader上线后变成follower，需要重新选举，将leader的分别变为均匀状态（这两个指令需要json格式的文件指定分配计划）。</p>
</blockquote>
</li>
<li><p>查看Kafka集群中节点是否正常</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 进入zookeeper客户端</span><br><span class="line">bin/zkCli.sh</span><br><span class="line"># 查询Kafka注册的节点</span><br><span class="line">ls /brokers/ids</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-2-5-Hive-2-3-6"><a href="#2-2-5-Hive-2-3-6" class="headerlink" title="2.2.5 Hive 2.3.6"></a>2.2.5 Hive 2.3.6</h3><h4 id="安装应用-4"><a href="#安装应用-4" class="headerlink" title="安装应用"></a>安装应用</h4><ol>
<li><p>先在bigdata3上安装MySQL</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --restart always --name mysql -p 3306:3306 -v /root/docker/mysql/conf:/etc/mysql -v /root/docker/mysql/log:/var/log/mysql -v /root/docker/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=hxr mysql:5.6</span><br></pre></td></tr></table></figure>


</li>
<li><p>将apache-hive-2.3.6-bin.tar.gz安装包放入bigdata1节点的&#x2F;opt&#x2F;software文件夹下，通过如下命令将安装包解压到&#x2F;opt&#x2F;module文件夹下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar –zxvf apache-hive-2.3.6-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>重命名解压后的文件为hive-2.3.6。</p>
</li>
</ol>
<h4 id="配置文件-4"><a href="#配置文件-4" class="headerlink" title="配置文件"></a>配置文件</h4><p>默认配置文件为hive-default.xml，用户自定义配置文件为hive-site.xml</p>
<ol>
<li><p>配置&#x2F;opt&#x2F;module&#x2F;hive-2.3.6&#x2F;conf&#x2F;hive-env.sh文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 配置HADOOP_HOME路径</span><br><span class="line">export HADOOP_HOME=$&#123;HADOOP_HOME&#125;</span><br><span class="line"></span><br><span class="line"># 配置HIVE_CONF_DIR路径</span><br><span class="line">export HIVE_CONF_DIR=/opt/module/hive-2.3.6/conf</span><br></pre></td></tr></table></figure>
</li>
<li><p>新建hive-site.xml<br>配置hive-site.xml文件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">     <span class="comment">&lt;!-- metastore连接数据库配置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://bigdata3:3306/metastore?createDatabaseIfNotExist=true<span class="symbol">&amp;amp;</span>useSSL=false<span class="symbol">&amp;amp;</span>useUnicode=true<span class="symbol">&amp;amp;</span>characterEncoding=UTF-8<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">description</span>&gt;</span>JDBC connect string for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Driver class name for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">description</span>&gt;</span>username to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hxr<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	    <span class="tag">&lt;<span class="name">description</span>&gt;</span>password to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 内部表元数据存储路径 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">description</span>&gt;</span>location of default database for the warehouse（默认default数据库所在hdfs位置）<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">description</span>&gt;</span>显示查询的头信息<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">description</span>&gt;</span>显示当前数据库<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- Hive元数据存储版本的验证 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.schema.verification<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>datanucleus.schema.autoCreateAll<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- metastore所在节点配置 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://bigdata1:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<p><strong>Hive 运行日志信息配置</strong><br>修改&#x2F;opt&#x2F;module&#x2F;hive&#x2F;conf&#x2F;hive-log4j.properties.template文件名称为hive-log4j.properties，修改 log 存放位置hive.log.dir&#x3D;&#x2F;opt&#x2F;module&#x2F;hive&#x2F;logs</p>
<ol start="3">
<li>beeline远程登陆配置<br>在hadoop的core-site.xml文件中配置代理用户<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.proxyuser.hxr.groups&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.proxyuser.hxr.hosts&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
在hive的hive-site.xml文件中配置远程链接地址端口和账号密码<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;bigdata1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 指定hiveserver2连接的端口号 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.server2.thrift.port&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;10000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;!--    &lt;property&gt; </span><br><span class="line">        &lt;name&gt;hive.server2.thrift.client.user&lt;/name&gt; </span><br><span class="line">        &lt;value&gt;hxr&lt;/value&gt; </span><br><span class="line">        &lt;description&gt;Username to use against thrift client&lt;/description&gt; </span><br><span class="line">    &lt;/property&gt; </span><br><span class="line">    &lt;property&gt; </span><br><span class="line">        &lt;name&gt;hive.server2.thrift.client.password&lt;/name&gt; </span><br><span class="line">        &lt;value&gt;hxr&lt;/value&gt; </span><br><span class="line">        &lt;description&gt;Password to use against thrift client&lt;/description&gt; </span><br><span class="line">    &lt;/property&gt; --&gt;</span><br></pre></td></tr></table></figure></li>
</ol>
<p>设置hiveserver2的启动内存大小</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">if [ &quot;$SERVICE&quot; = &quot;hiveserver2&quot; ]; then</span><br><span class="line">    echo $HADOOP_OPTS</span><br><span class="line">    export HADOOP_OPTS=&quot;$HADOOP_OPTS -XX:PermSize=2048M -XX:MaxPermSize=2048M&quot;</span><br><span class="line">    echo $HADOOP_OPTS</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">export HADOOP_HEAPSIZE=4096</span><br></pre></td></tr></table></figure>
<blockquote>
<p>虽然通过<code>ps -ef | grep 16481</code>查看启动命令会显示启动jvm的内存参数为-XX:PermSize&#x3D;2048M -XX:MaxPermSize&#x3D;2048M。但是查看该hiveserver2进程的status文件，会发现实际分配的物理内存是VmHWM:	 4315028 kB(4G)。</p>
</blockquote>
<h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><p>启动metastore和hiveserver2</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nohup ./hive --service metastore &amp;</span><br><span class="line">nohup ./hive --service hiveserver2 &amp;</span><br></pre></td></tr></table></figure>
<p>①本地连接<br>进入hive客户端</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hive</span><br></pre></td></tr></table></figure>
<p>如果成功进入，则hive运行正常。<br>②beeline远程连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">beeline -u jdbc:hive2://bigdata1:10000 -n hxr</span><br></pre></td></tr></table></figure>
<p>③可以通过DataGrip等数据库管理工具远程连接<br>连接URL为 <code>jdbc:hive2://192.168.32.242:10000</code></p>
<h3 id="2-2-6-Sqoop-1-4-6"><a href="#2-2-6-Sqoop-1-4-6" class="headerlink" title="2.2.6 Sqoop 1.4.6"></a>2.2.6 Sqoop 1.4.6</h3><h4 id="安装应用-5"><a href="#安装应用-5" class="headerlink" title="安装应用"></a>安装应用</h4><p>将sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz安装包放入bigdata1节点的&#x2F;opt&#x2F;software文件夹下，通过如下命令将安装包解压到&#x2F;opt&#x2F;module文件夹下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar –zxvf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>重命名解压后的文件为sqoop-1.4.6</p>
<h4 id="配置文件-5"><a href="#配置文件-5" class="headerlink" title="配置文件"></a>配置文件</h4><ol>
<li><p>重命名sqoop-env-template.sh文件为sqoop-env.sh</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv /opt/module/sqoop-1.4.6/conf/sqoop-env-template.sh /opt/module/sqoop-1.4.6/conf/sqoop-env-template.shsqoop-env.sh</span><br></pre></td></tr></table></figure>

<p>修改文件sqoop-env.sh</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下配置可以不写</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/opt/module/hive-2.3.6</span><br><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/opt/module/zookeeper-3.4.10</span><br><span class="line"><span class="built_in">export</span> ZOOCFGDIR=/opt/module/zookeeper-3.4.10/conf</span><br><span class="line"><span class="built_in">export</span> HBASE_HOME=/opt/module/hbase</span><br></pre></td></tr></table></figure>
</li>
<li><p>拷贝JDBC驱动</p>
<p>将MySQL版本对应的驱动程序解压到&#x2F;opt&#x2F;module&#x2F;sqoop-1.4.6&#x2F;lib&#x2F; 目录下。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf mysql-connector-java-5.1.27.tar.gz   <span class="comment"># 解压驱动包</span></span><br><span class="line"><span class="built_in">cp</span> mysql-connector-java-5.1.27/mysql-connector-java-5.1.27-bin.jar /opt/module/sqoop-1.4.6/lib/   <span class="comment"># 复制驱动包</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h4><ol>
<li><p>通过某一个command来验证sqoop配置是否正确</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop help</span><br></pre></td></tr></table></figure>

<p>出现一些Warning警告，并伴随着帮助命令的输出。</p>
</li>
<li><p>测试Sqoop是否能够成功连接数据库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop list-databases --connect jdbc:mysql://bigdata3:3306/ --username root --password hxr</span><br></pre></td></tr></table></figure>

<p>如果打印出mysql中的所有数据库，则运行正常。</p>
<blockquote>
<p>需要预先在bigdata3节点上安装完mysql</p>
</blockquote>
</li>
</ol>
<h3 id="2-2-7-配置LZO格式压缩"><a href="#2-2-7-配置LZO格式压缩" class="headerlink" title="2.2.7 配置LZO格式压缩"></a>2.2.7 配置LZO格式压缩</h3><p>hadoop本身并不支持lzo压缩，故需要使用twitter提供的hadoop-lzo开源组件。</p>
<h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><ol>
<li><p>将编译好后的hadoop-lzo-0.4.20.jar 放入hadoop-2.7.2&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;</p>
</li>
<li><p>core-site.xml增加配置支持LZO压缩</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>io.compression.codecs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">       org.apache.hadoop.io.compress.GzipCodec,</span><br><span class="line">       org.apache.hadoop.io.compress.DefaultCodec,</span><br><span class="line">       org.apache.hadoop.io.compress.BZip2Codec,</span><br><span class="line">       org.apache.hadoop.io.compress.SnappyCodec,</span><br><span class="line">       com.hadoop.compression.lzo.LzoCodec,</span><br><span class="line">       com.hadoop.compression.lzo.LzopCodec</span><br><span class="line">	<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">   </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   	<span class="tag">&lt;<span class="name">name</span>&gt;</span>io.compression.codec.lzo.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   	<span class="tag">&lt;<span class="name">value</span>&gt;</span>com.hadoop.compression.lzo.LzoCodec<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>同步hadoop-lzo-0.4.20.jar 文件和core-site.xml文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsyncmy /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-lzo-0.4.20.jar /opt/module/hadoop-2.7.2/etc/hadoop/core-site.xml</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="重启集群"><a href="#重启集群" class="headerlink" title="重启集群"></a>重启集群</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-dfs.sh</span><br><span class="line">sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>



<h4 id="测试-2"><a href="#测试-2" class="headerlink" title="测试"></a>测试</h4><p>查看本地库支持的</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop checknative -a  </span><br></pre></td></tr></table></figure>



<p>创建索引：LZO压缩文件的可切片特性依赖于其索引，故我们需要手动为LZO压缩文件创建索引。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/hadoop-lzo-0.4.20.jar com.hadoop.compression.lzo.DistributedLzoIndexer big_file.lzo</span><br></pre></td></tr></table></figure>
<p>测试输出使用lzop进行压缩</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount -Dmapreduce.output.fileoutputformat.compress=true -Dmapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec /README.txt /outputlzo</span><br></pre></td></tr></table></figure>




<h3 id="2-2-8-TEZ-0-9-1"><a href="#2-2-8-TEZ-0-9-1" class="headerlink" title="2.2.8 TEZ 0.9.1"></a>2.2.8 TEZ 0.9.1</h3><h4 id="安装应用-6"><a href="#安装应用-6" class="headerlink" title="安装应用"></a>安装应用</h4><p>将apache-tez-0.9.1-bin.tar.gz安装包放入bigdata1节点的&#x2F;opt&#x2F;software文件夹下，通过如下命令将安装包解压到&#x2F;opt&#x2F;module文件夹下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar –zxvf apache-tez-0.9.1-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>重命名解压后的文件为tez-0.9.1</p>
<h4 id="配置文件-6"><a href="#配置文件-6" class="headerlink" title="配置文件"></a>配置文件</h4><ol>
<li><p>需要在hive的hive-env.sh中引入tez的所有jar包。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set HADOOP_HOME to point to a specific hadoop install directoryHADOOP_HOME=$&#123;HADOOP_HOME&#125;</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="comment"># Hive Configuration Directory can be controlled by:</span></span><br><span class="line"><span class="built_in">export</span> HIVE_CONF_DIR=<span class="variable">$HIVE_HOME</span>/conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Folder containing extra libraries required for hive compilation/execution can be controlled by:</span></span><br><span class="line"><span class="comment"># export HIVE_AUX_JARS_PATH=</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> TEZ_HOME=/opt/module/tez-0.9.1</span><br><span class="line"><span class="built_in">export</span> TEZ_JARS=<span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">for</span> jar <span class="keyword">in</span> `<span class="built_in">ls</span> <span class="variable">$TEZ_HOME</span> | grep jar`;<span class="keyword">do</span></span><br><span class="line">        <span class="built_in">export</span> TEZ_JARS=<span class="variable">$TEZ_JARS</span>:<span class="variable">$TEZ_HOME</span>/<span class="variable">$jar</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> jar <span class="keyword">in</span> `<span class="built_in">ls</span> <span class="variable">$TEZ_HOME</span>/lib`;<span class="keyword">do</span></span><br><span class="line">        <span class="built_in">export</span> TEZ_JARS=<span class="variable">$TEZ_JARS</span>:<span class="variable">$TEZ_HOME</span>/lib/<span class="variable">$jar</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HIVE_AUX_JARS_PATH=<span class="variable">$HADOOP_HOME</span>/share/hadoop/common/hadoop-lzo-0.4.20.jar<span class="variable">$TEZ_JARS</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>在hive-site.xml中设置引擎为tez。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.execution.engine&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;tez&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在Hive的&#x2F;opt&#x2F;module&#x2F;hive&#x2F;conf下面创建一个tez-site.xml文件，添加如下内容</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xs1&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.lib.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;fs.defaultFS&#125;/tez/apache-tez-0.9.1-bin.tar.gz<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.use.cluster.hadoop-libs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.history.logging.service.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.tez.dag.history.logging.ats.ATSHistoryLoggingService<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>将&#x2F;opt&#x2F;module&#x2F;tez-0.9.1上传到HDFS的&#x2F;tez路径，使所有的hdfs节点都可以使用tez。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">    hadoop fs -mkdir /tez</span><br><span class="line">    hadoop fs -put /opt/software/apache-tez-0.9.1-bin.tar.gz /tez</span><br><span class="line">    hadoop fs -ls /tez</span><br></pre></td></tr></table></figure>
<p>放置的路径需要与tez-site.xml中配置的路径对应</p>
</li>
</ol>
<blockquote>
<p>如果是hadoop3.1.3版本，可以<a target="_blank" rel="noopener" href="https://dlcdn.apache.org/tez/0.10.1/">下载Tez 0.10.1版本</a>进行配置.</p>
</blockquote>
<h4 id="测试-3"><a href="#测试-3" class="headerlink" title="测试"></a>测试</h4><ol>
<li><p>启动Hive</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">nohup</span> hive --service metastore 1&gt;/dev/null 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="built_in">nohup</span> hive --service hiveserver2 1&gt;/dev/null 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line">bin/hive</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建LZO表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create table student(id int,name string);</span><br></pre></td></tr></table></figure>
</li>
<li><p>向表中插入数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert into student values(1,&quot;zhangsan&quot;);</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询数据，如果没有报错就表示成功了</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from student;</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h4><p><strong>运行Tez时检查到用过多内存而被NodeManager杀死进程问题：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Caused by: org.apache.tez.dag.api.SessionNotRunning: TezSession has already shutdown. Application application_1546781144082_0005 failed 2 times due to AM Container for appattempt_1546781144082_0005_000002 exited with  exitCode: -103</span><br><span class="line"></span><br><span class="line">For more detailed output, check application tracking page:http://hadoop103:8088/cluster/app/application_1546781144082_0005Then, click on links to logs of each attempt.</span><br><span class="line"></span><br><span class="line">Diagnostics: Container [pid=11116,containerID=container_1546781144082_0005_02_000001] is running beyond virtual memory limits. Current usage: 216.3 MB of 1 GB physical memory used; 2.6 GB of 2.1 GB virtual memory used. Killing container.</span><br></pre></td></tr></table></figure>

<p>这种问题是从机上运行的Container试图使用过多的内存，而被NodeManager kill掉了。</p>
<p><strong>解决方法：</strong></p>
<ul>
<li><p>方案一：或者是关掉虚拟内存检查。修改yarn-site.xml，修改后一定要分发，并重新启动hadoop集群。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>方案二：mapred-site.xml中设置Map和Reduce任务的内存配置如下(value中实际配置的内存需要根据自己机器内存大小及应用情况进行修改)</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>1536<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.java.opts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>-Xmx1024M<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>3072<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.java.opts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>-Xmx2560M<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-2-9-Azkaban-2-5-0"><a href="#2-2-9-Azkaban-2-5-0" class="headerlink" title="2.2.9 Azkaban 2.5.0"></a>2.2.9 Azkaban 2.5.0</h3><h4 id="应用安装"><a href="#应用安装" class="headerlink" title="应用安装"></a>应用安装</h4><p>将azkaban-web-server-2.5.0.tar.gz，azkaban-executor-server-2.5.0.tar.gz，azkaban-sql-script-2.5.0.tar.gz 安装包放入bigdata1节点的&#x2F;opt&#x2F;software文件夹下；</p>
<p>创建&#x2F;opt&#x2F;module&#x2F;azkaban-2.5.0文件夹；</p>
<p>通过如下命令将安装包解压到&#x2F;opt&#x2F;module&#x2F;azkaban-2.5.0文件夹下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar –zxvf azkaban-web-server-2.5.0.tar.gz -C /opt/module/azkaban-2.5.0</span><br><span class="line">tar –zxvf azkaban-executor-server-2.5.0.tar.gz -C /opt/module/azkaban-2.5.0</span><br><span class="line">tar –zxvf azkaban-sql-script-2.5.0.tar.gz -C /opt/module/azkaban-2.5.0</span><br></pre></td></tr></table></figure>

<p>重命名解压后的文件夹</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mv /opt/module/azkaban-2.5.0/azkaban-web-2.5.0/ /opt/module/azkaban-2.5.0/server</span><br><span class="line">mv /opt/module/azkaban-2.5.0/azkaban-executor-2.5.0/ /opt/module/azkaban-2.5.0/executor</span><br></pre></td></tr></table></figure>



<h4 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -phxr</span><br><span class="line"></span><br><span class="line">mysql&gt; create database azkaban;</span><br><span class="line">mysql&gt; use azkaban;</span><br><span class="line">mysql&gt; source /opt/module/azkaban/azkaban-2.5.0/create-all-sql-2.5.0.sql</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注：source后跟.sql文件，用于批量处理.sql文件中的sql语句。</p>
</blockquote>
<h4 id="生成密钥对和证书"><a href="#生成密钥对和证书" class="headerlink" title="生成密钥对和证书"></a>生成密钥对和证书</h4><p>Keytool是java数据证书的管理工具，使用户能够管理自己的公&#x2F;私钥对及相关证书。</p>
<ol>
<li><p>生成 keystore的密码及相应信息的密钥库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keytool -keystore keystore -alias jetty -genkey -keyalg RSA</span><br></pre></td></tr></table></figure>

<blockquote>
<p>-keystore    指定密钥库的名称及位置(产生的各类信息将存在.keystore文件中)<br>-genkey(或者-genkeypair) 生成密钥对<br>-alias  为生成的密钥对指定别名，如果没有默认是mykey<br>-keyalg  指定密钥的算法 RSA&#x2F;DSA 默认是DSA</p>
</blockquote>
<p>输入完成后即生成秘钥对，可以通过如下命令查看秘钥库中的秘钥信息，有私钥和证书(存有公钥)。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keytool -keystore keystore -list </span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>注意：</strong><br>密钥库的密码至少必须6个字符，可以是纯数字或者字母或者数字和字母的组合等等<br>密钥库的密码最好和<jetty> 的密钥相同，方便记忆</p>
</blockquote>
</li>
<li><p>将keystore 拷贝到 azkaban web服务器根目录中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv keystore /opt/module/azkaban-2.5.0/server/</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="配置文件-7"><a href="#配置文件-7" class="headerlink" title="配置文件"></a>配置文件</h4><ol>
<li><p>Web服务器配置，修改&#x2F;opt&#x2F;module&#x2F;azkaban-2.5.0&#x2F;server&#x2F;conf&#x2F;azkaban.properties文件</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Azkaban Personalization Settings</span></span><br><span class="line"><span class="comment">#服务器UI名称,用于服务器上方显示的名字</span></span><br><span class="line"><span class="attr">azkaban.name</span>=<span class="string">Test</span></span><br><span class="line"><span class="comment">#描述</span></span><br><span class="line"><span class="attr">azkaban.label</span>=<span class="string">My Local Azkaban</span></span><br><span class="line"><span class="comment">#UI颜色</span></span><br><span class="line"><span class="attr">azkaban.color</span>=<span class="string">#FF3601</span></span><br><span class="line"><span class="attr">azkaban.default.servlet.path</span>=<span class="string">/index</span></span><br><span class="line"><span class="comment">#默认web server存放web文件的目录</span></span><br><span class="line"><span class="attr">web.resource.dir</span>=<span class="string">/opt/module/azkaban/server/web/</span></span><br><span class="line"><span class="comment">#默认时区,已改为亚洲/上海 默认为美国</span></span><br><span class="line"><span class="attr">default.timezone.id</span>=<span class="string">Asia/Shanghai</span></span><br><span class="line"><span class="comment">#Azkaban UserManager class</span></span><br><span class="line"><span class="attr">user.manager.class</span>=<span class="string">azkaban.user.XmlUserManager</span></span><br><span class="line"><span class="comment">#用户权限管理默认类（绝对路径）</span></span><br><span class="line"><span class="attr">user.manager.xml.file</span>=<span class="string">/opt/module/azkaban/server/conf/azkaban-users.xml</span></span><br><span class="line"><span class="comment">#Loader for projects</span></span><br><span class="line"><span class="comment">#global配置文件所在位置（绝对路径）</span></span><br><span class="line"><span class="attr">executor.global.properties</span>=<span class="string">/opt/module/azkaban/executor/conf/global.properties</span></span><br><span class="line"><span class="attr">azkaban.project.dir</span>=<span class="string">projects</span></span><br><span class="line"><span class="comment">#数据库类型</span></span><br><span class="line"><span class="attr">database.type</span>=<span class="string">mysql</span></span><br><span class="line"><span class="comment">#端口号</span></span><br><span class="line"><span class="attr">mysql.port</span>=<span class="string">3306</span></span><br><span class="line"><span class="comment">#数据库连接IP</span></span><br><span class="line"><span class="attr">mysql.host</span>=<span class="string">bigdata3</span></span><br><span class="line"><span class="comment">#数据库实例名</span></span><br><span class="line"><span class="attr">mysql.database</span>=<span class="string">azkaban</span></span><br><span class="line"><span class="comment">#数据库用户名</span></span><br><span class="line"><span class="attr">mysql.user</span>=<span class="string">root</span></span><br><span class="line"><span class="comment">#数据库密码</span></span><br><span class="line"><span class="attr">mysql.password</span>=<span class="string">hxr</span></span><br><span class="line"><span class="comment">#最大连接数</span></span><br><span class="line"><span class="attr">mysql.numconnections</span>=<span class="string">100</span></span><br><span class="line"><span class="comment"># Velocity dev mode</span></span><br><span class="line"><span class="attr">velocity.dev.mode</span>=<span class="string">false</span></span><br><span class="line"><span class="comment"># Azkaban Jetty server properties.</span></span><br><span class="line"><span class="comment"># Jetty服务器属性.</span></span><br><span class="line"><span class="comment">#最大线程数</span></span><br><span class="line"><span class="attr">jetty.maxThreads</span>=<span class="string">25</span></span><br><span class="line"><span class="comment">#Jetty SSL端口</span></span><br><span class="line"><span class="attr">jetty.ssl.port</span>=<span class="string">8443</span></span><br><span class="line"><span class="comment">#Jetty端口</span></span><br><span class="line"><span class="attr">jetty.port</span>=<span class="string">8081</span></span><br><span class="line"><span class="comment">#SSL文件名（绝对路径）</span></span><br><span class="line"><span class="attr">jetty.keystore</span>=<span class="string">/opt/module/azkaban/server/keystore</span></span><br><span class="line"><span class="comment">#SSL文件密码</span></span><br><span class="line"><span class="attr">jetty.password</span>=<span class="string">000000</span></span><br><span class="line"><span class="comment">#Jetty主密码与keystore文件相同</span></span><br><span class="line"><span class="attr">jetty.keypassword</span>=<span class="string">000000</span></span><br><span class="line"><span class="comment">#SSL文件名（绝对路径）</span></span><br><span class="line"><span class="attr">jetty.truststore</span>=<span class="string">/opt/module/azkaban/server/keystore</span></span><br><span class="line"><span class="comment">#SSL文件密码</span></span><br><span class="line"><span class="attr">jetty.trustpassword</span>=<span class="string">000000</span></span><br><span class="line"><span class="comment"># Azkaban Executor settings</span></span><br><span class="line"><span class="attr">executor.port</span>=<span class="string">12321</span></span><br><span class="line"><span class="comment"># mail settings</span></span><br><span class="line"><span class="attr">mail.sender</span>=<span class="string"></span></span><br><span class="line"><span class="attr">mail.host</span>=<span class="string"></span></span><br><span class="line"><span class="attr">job.failure.email</span>=<span class="string"></span></span><br><span class="line"><span class="attr">job.success.email</span>=<span class="string"></span></span><br><span class="line"><span class="attr">lockdown.create.projects</span>=<span class="string">false</span></span><br><span class="line"><span class="attr">cache.directory</span>=<span class="string">cache</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Web服务器用户配置，修改&#x2F;opt&#x2F;module&#x2F;azkaban-2.5.0&#x2F;server&#x2F;conf&#x2F;azkaban-users.xml 文件，增加管理员用户</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">azkaban-users</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">user</span> <span class="attr">username</span>=<span class="string">&quot;azkaban&quot;</span> <span class="attr">password</span>=<span class="string">&quot;azkaban&quot;</span> <span class="attr">roles</span>=<span class="string">&quot;admin&quot;</span> <span class="attr">groups</span>=<span class="string">&quot;azkaban&quot;</span> /&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">user</span> <span class="attr">username</span>=<span class="string">&quot;metrics&quot;</span> <span class="attr">password</span>=<span class="string">&quot;metrics&quot;</span> <span class="attr">roles</span>=<span class="string">&quot;metrics&quot;</span>/&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">user</span> <span class="attr">username</span>=<span class="string">&quot;admin&quot;</span> <span class="attr">password</span>=<span class="string">&quot;admin&quot;</span> <span class="attr">roles</span>=<span class="string">&quot;admin,metrics&quot;</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">role</span> <span class="attr">name</span>=<span class="string">&quot;admin&quot;</span> <span class="attr">permissions</span>=<span class="string">&quot;ADMIN&quot;</span> /&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">role</span> <span class="attr">name</span>=<span class="string">&quot;metrics&quot;</span> <span class="attr">permissions</span>=<span class="string">&quot;METRICS&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">azkaban-users</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>执行服务器配置，修改&#x2F;opt&#x2F;module&#x2F;azkaban-2.5.0&#x2F;executor&#x2F;conf&#x2F;azkaban.properties</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Azkaban</span></span><br><span class="line"><span class="comment">#时区</span></span><br><span class="line"><span class="attr">default.timezone.id</span>=<span class="string">Asia/Shanghai</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Azkaban JobTypes Plugins</span></span><br><span class="line"><span class="comment">#jobtype 插件所在位置</span></span><br><span class="line"><span class="attr">azkaban.jobtype.plugin.dir</span>=<span class="string">plugins/jobtypes</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#Loader for projects</span></span><br><span class="line"><span class="attr">executor.global.properties</span>=<span class="string">/opt/module/azkaban-2.5.0/executor/conf/global.properties</span></span><br><span class="line"><span class="attr">azkaban.project.dir</span>=<span class="string">projects</span></span><br><span class="line"></span><br><span class="line"><span class="attr">database.type</span>=<span class="string">mysql</span></span><br><span class="line"><span class="attr">mysql.port</span>=<span class="string">3306</span></span><br><span class="line"><span class="attr">mysql.host</span>=<span class="string">bigdata3</span></span><br><span class="line"><span class="attr">mysql.database</span>=<span class="string">azkaban</span></span><br><span class="line"><span class="attr">mysql.user</span>=<span class="string">root</span></span><br><span class="line"><span class="attr">mysql.password</span>=<span class="string">hxr</span></span><br><span class="line"><span class="attr">mysql.numconnections</span>=<span class="string">100</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Azkaban Executor settings</span></span><br><span class="line"><span class="comment">#最大线程数</span></span><br><span class="line"><span class="attr">executor.maxThreads</span>=<span class="string">50</span></span><br><span class="line"><span class="comment">#端口号(如修改,请与web服务中一致)</span></span><br><span class="line"><span class="attr">executor.port</span>=<span class="string">12321</span></span><br><span class="line"><span class="comment">#线程数</span></span><br><span class="line"><span class="attr">executor.flow.threads</span>=<span class="string">30</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="单点启动-1"><a href="#单点启动-1" class="headerlink" title="单点启动"></a>单点启动</h4><ul>
<li><p>启动<strong>executor</strong>服务器</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/module/azkaban-2.5.0/executor/bin/azkaban-executor-start.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动<strong>web</strong>服务器</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/module/azkaban-2.5.0/server/bin/azkaban-web-start.sh</span><br></pre></td></tr></table></figure></li>
</ul>
<blockquote>
<p>注意：先执行executor，再执行web，避免Web Server会因为找不到执行器启动失败</p>
</blockquote>
<h4 id="Web界面-1"><a href="#Web界面-1" class="headerlink" title="Web界面"></a>Web界面</h4><p>启动完成后，访问<strong><a target="_blank" rel="noopener" href="https://bigdata1:8443/">https://bigdata1:8443</a></strong>，即可访问azkaban服务了。</p>
<p>在登录中输入刚才在azkaban-users.xml文件中新添加的户用名及密码，点击 login。</p>
<h3 id="2-2-10-Flink-1-12-0"><a href="#2-2-10-Flink-1-12-0" class="headerlink" title="2.2.10 Flink 1.12.0"></a>2.2.10 Flink 1.12.0</h3><h4 id="安装应用-7"><a href="#安装应用-7" class="headerlink" title="安装应用"></a>安装应用</h4><p>将flink-1.12.0-bin-scala_2.12.tgz安装包放入bigdata1节点的&#x2F;opt&#x2F;software文件夹下，通过如下命令将安装包解压到&#x2F;opt&#x2F;module文件夹下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar –zxvf flink-1.12.0-bin-scala_2.12.tgz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>重命名解压后的文件为flink-1.12.0</p>
<h4 id="分发Flink到其他节点"><a href="#分发Flink到其他节点" class="headerlink" title="分发Flink到其他节点"></a>分发Flink到其他节点</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsyncmy /opt/module/flink-1.12.0</span><br></pre></td></tr></table></figure>



<h4 id="启动集群-3"><a href="#启动集群-3" class="headerlink" title="启动集群"></a>启动集群</h4><p><strong>必须保证hadoop集群正常运行。</strong></p>
<ol>
<li><p>添加环境变量</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_CLASSPATH=`hadoop classpath`</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动yarn-session</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-session.sh -n 2 -s 2 -jm 1024 -nm test -d</span><br></pre></td></tr></table></figure>

<p>如果调度器中创建了多个队列，需要指定队列</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">nohup</span> ./yarn-session.sh -s 2 -jm 1024 -tm 2048 -nm flink-on-yarn -qu flink -d 1&gt;/opt/module/flink-1.12.0/yarn-session.log 2&gt;/opt/module/flink-1.12.0/yarn-session.err &amp;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>-n（–container）：TaskManager的数量（建议不指定，会动态添加，且flink1.10中已经不再支持）；<br>-s（–slots）：每个TaskManager的slot数量，默认一个slot一个sore，默认每个taskmanager的slot个数为1，有时可以多一些taskmanager，做冗余；<br>-jm：JobManager的内存（MB）；<br>-tm：每个taskmanager的内存（MB）；<br>-nm：yarn的appName（yarn的ui上的名字）；<br>-d：后台执行。</p>
</blockquote>
</li>
<li><p>关闭yarn-session</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 找到flink集群任务的id，然后kill</span><br><span class="line">yarn application -kill application_1616059084025_0002</span><br></pre></td></tr></table></figure>


</li>
<li><p>提交任务(和standalone模式一样)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flink run -c com.iotmars.wecook.StreamWordCount -p 2 /opt/jar/flink-demo-0.0.1-SNAPSHOT-jar-with-dependencies.jar --host localhost --port 6666</span><br></pre></td></tr></table></figure>

<blockquote>
<ul>
<li>-c 表示类路径</li>
<li>-p 表示并行度</li>
<li>然后加上启动jar路径</li>
<li>最后添加参数<br><code>注意：如果slot不够，会导致卡死在分配资源阶段导致最后超时失败。</code></li>
</ul>
</blockquote>
<p>查看任务状态：去yarn控制台查看任务状态<br>取消yarn-session：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn application --kill job_id</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="Web界面-2"><a href="#Web界面-2" class="headerlink" title="Web界面"></a>Web界面</h4><p>可以通过<a target="_blank" rel="noopener" href="http://192.168.32.243:37807/">http://192.168.32.243:37807</a>访问Web页面（每次启动都会变，具体查看&#x2F;opt&#x2F;module&#x2F;flink-1.12.0&#x2F;yarn-session.log）</p>
<h3 id="2-2-11-HBase-1-3-1"><a href="#2-2-11-HBase-1-3-1" class="headerlink" title="2.2.11 HBase 1.3.1"></a>2.2.11 HBase 1.3.1</h3><h4 id="安装应用-8"><a href="#安装应用-8" class="headerlink" title="安装应用"></a>安装应用</h4><p>将hbase-1.3.1-bin.tar.gz安装包放入bigdata1节点的&#x2F;opt&#x2F;software文件夹下，通过如下命令将安装包解压到&#x2F;opt&#x2F;module文件夹下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar –zxvf hbase-1.3.1-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>重命名解压后的文件为hbase-1.3.1</p>
<h4 id="配置文件-8"><a href="#配置文件-8" class="headerlink" title="配置文件"></a>配置文件</h4><ol>
<li><p>修改conf&#x2F;hbase-env.sh文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br><span class="line">export HBASE_MANAGES_ZK=false</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改conf&#x2F;hbase-site.sh文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;     </span><br><span class="line">        &lt;name&gt;hbase.rootdir&lt;/name&gt;     </span><br><span class="line">        &lt;value&gt;hdfs://bigdata1:9000/hbase&lt;/value&gt;   </span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;   </span><br><span class="line">        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">   &lt;!-- 0.98后的新变动，之前版本没有.port,默认端口为60000 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hbase.master.port&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;16000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;   </span><br><span class="line">        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">         &lt;value&gt;bigdata1,bigdata2,bigdata3&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;   </span><br><span class="line">        &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;</span><br><span class="line">         &lt;value&gt;/opt/module/zookeeper-3.4.10/zkData&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>


</li>
<li><p>修改conf&#x2F;regionservers文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bigdata1</span><br><span class="line">bigdata2</span><br><span class="line">bigdata3</span><br></pre></td></tr></table></figure>
</li>
<li><p>软连接hadoop配置文件到hbase</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ln -s /opt/module/hadoop-2.7.2/etc/hadoop/core-site.xml /opt/module/hbase/conf/core-site.xml</span><br><span class="line">ln -s /opt/module/hadoop-2.7.2/etc/hadoop/hdfs-site.xml /opt/module/hbase/conf/hdfs-site.xml</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="分发HBase到其他节点"><a href="#分发HBase到其他节点" class="headerlink" title="分发HBase到其他节点"></a>分发HBase到其他节点</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsyncmy /opt/module/hbase</span><br></pre></td></tr></table></figure>



<h4 id="启动集群-4"><a href="#启动集群-4" class="headerlink" title="启动集群"></a>启动集群</h4><p><strong>必须保证zk和hadoop集群正常运行。</strong></p>
<ul>
<li><p>方式一：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/hbase-daemon.sh start master</span><br><span class="line">bin/hbase-daemon.sh start regionserver</span><br></pre></td></tr></table></figure>
</li>
<li><p>方式二：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/start-hbase.sh</span><br><span class="line">bin/stop-hbase.sh</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="Web界面-3"><a href="#Web界面-3" class="headerlink" title="Web界面"></a>Web界面</h4><p><a target="_blank" rel="noopener" href="http://bigdata1:16010/">http://bigdata1:16010</a></p>
<h3 id="2-2-12-Clickhouse"><a href="#2-2-12-Clickhouse" class="headerlink" title="2.2.12 Clickhouse"></a>2.2.12 Clickhouse</h3><p>见<a target="_blank" rel="noopener" href="https://www.jianshu.com/writer#/notebooks/44861765/notes/82724859">ClickHouse 21.7 基础</a></p>
<h2 id="2-3-辅助框架"><a href="#2-3-辅助框架" class="headerlink" title="2.3 辅助框架"></a>2.3 辅助框架</h2><h3 id="2-3-1-Ganglia"><a href="#2-3-1-Ganglia" class="headerlink" title="2.3.1 Ganglia"></a>2.3.1 Ganglia</h3><h4 id="启动应用"><a href="#启动应用" class="headerlink" title="启动应用"></a>启动应用</h4><p>需要先将容器中&#x2F;etc&#x2F;ganglia&#x2F;文件夹下的配置文件复制出来，再启动。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name ganglia --net=host -v /root/ganglia/conf/:/etc/ganglia/ -v /root/ganglia/lib/:/var/lib/ganglia/ wookietreiber/ganglia</span><br></pre></td></tr></table></figure>



<h4 id="配置文件-9"><a href="#配置文件-9" class="headerlink" title="配置文件"></a>配置文件</h4><p>修改gmond.conf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">cluster &#123;</span><br><span class="line">  name = &quot;bigdata&quot;</span><br><span class="line">  owner = &quot;unspecified&quot;</span><br><span class="line">  latlong = &quot;unspecified&quot;</span><br><span class="line">  url = &quot;unspecified&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">udp_send_channel &#123;</span><br><span class="line">  #bind_hostname = yes # Highly recommended, soon to be default.</span><br><span class="line">                       # This option tells gmond to use a source address</span><br><span class="line">                       # that resolves to the machine&#x27;s hostname.  Without</span><br><span class="line">                       # this, the metrics may appear to come from any</span><br><span class="line">                       # interface and the DNS names associated with</span><br><span class="line">                       # those IPs will be used to create the RRDs.</span><br><span class="line">  #mcast_join = 239.2.11.71</span><br><span class="line">  # 192.168.32.243是bigdata2的ip</span><br><span class="line">  host = 192.168.32.243</span><br><span class="line">  port = 8649</span><br><span class="line">  ttl = 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">udp_recv_channel &#123;</span><br><span class="line">  # mcast_join = 239.2.11.71</span><br><span class="line">  port = 8649</span><br><span class="line">  bind = 192.168.32.243</span><br><span class="line">  retry_bind = true</span><br><span class="line">  # Size of the UDP buffer. If you are handling lots of metrics you really</span><br><span class="line">  # should bump it up to e.g. 10MB or even higher.</span><br><span class="line">  # buffer = 10485760</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>修改gmeta.conf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_source &quot;bigdata&quot; 192.168.32.243:8649</span><br></pre></td></tr></table></figure>

<p>需要再flume配置文件flume-env.sh中添加如下参数将信息发送到ganglia的监控端口，或直接在启动flume时添加如下参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-Dflume.monitoring.type=ganglia -Dflume.monitoring.hosts=192.168.32.243:8649 -Xms100m -Xmx200m&quot;</span><br></pre></td></tr></table></figure>

<p>访问监控UI：192.168.32.243&#x2F;ganglia</p>
<h3 id="2-3-2-Solr-5-2-1"><a href="#2-3-2-Solr-5-2-1" class="headerlink" title="2.3.2 Solr 5.2.1"></a>2.3.2 Solr 5.2.1</h3><h4 id="安装应用-9"><a href="#安装应用-9" class="headerlink" title="安装应用"></a>安装应用</h4><p>将solr-5.2.1.tgz安装包放入bigdata1节点的&#x2F;opt&#x2F;software文件夹下，通过如下命令将安装包解压到&#x2F;opt&#x2F;module文件夹下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar –zxvf solr-5.2.1.tgz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>重命名解压后的文件为solr-5.2.1</p>
<h4 id="配置文件-10"><a href="#配置文件-10" class="headerlink" title="配置文件"></a>配置文件</h4><p>进入solr&#x2F;bin目录，修改solr.in.sh文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ZK_HOST=&quot;hadoop102:2181,hadoop103:2181,hadoop104:2181&quot;</span><br><span class="line">SOLR_HOST=&quot;hadoop102&quot;</span><br><span class="line"># Sets the port Solr binds to, default is 8983</span><br><span class="line">#可修改端口号</span><br><span class="line">SOLR_PORT=8983</span><br></pre></td></tr></table></figure>



<h4 id="分发Solr到其他节点"><a href="#分发Solr到其他节点" class="headerlink" title="分发Solr到其他节点"></a>分发Solr到其他节点</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsyncmy /opt/module/solr-5.2.1</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注：分发完成后，分别对bigdata2、bigdata3主机&#x2F;opt&#x2F;module&#x2F;solr-5.2.1&#x2F;bin下的solr.in.sh文件，修改为SOLR_HOST&#x3D;对应主机名。</p>
</blockquote>
<h4 id="集群启动"><a href="#集群启动" class="headerlink" title="集群启动"></a>集群启动</h4><p>在三台节点上分别启动Solr，这个就是Cloud模式</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/solr start</span><br></pre></td></tr></table></figure>



<h4 id="Web界面-4"><a href="#Web界面-4" class="headerlink" title="Web界面"></a>Web界面</h4><p>访问8983端口，可指定三台节点中的任意一台IP</p>
<p><a target="_blank" rel="noopener" href="http://bigdata1:8983/solr/">http://bigdata1:8983/solr/</a></p>
<p>UI界面出现Cloud菜单栏时，Solr的Cloud模式才算部署成功。</p>
<h3 id="2-3-3-Atlas-0-8-4"><a href="#2-3-3-Atlas-0-8-4" class="headerlink" title="2.3.3 Atlas 0.8.4"></a>2.3.3 Atlas 0.8.4</h3><p>需要提前安装hadoop，hive，zk，kafka，hbase，solr</p>
<h4 id="安装应用-10"><a href="#安装应用-10" class="headerlink" title="安装应用"></a>安装应用</h4><p>将apache-atlas-0.8.4-bin.tar.gz安装包放入bigdata1节点的&#x2F;opt&#x2F;software文件夹下，通过如下命令将安装包解压到&#x2F;opt&#x2F;module文件夹下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar –zxvf apache-atlas-0.8.4-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>重命名解压后的文件为atlas-0.8.4</p>
<h4 id="配置文件-11"><a href="#配置文件-11" class="headerlink" title="配置文件"></a>配置文件</h4><p><strong>Atlas集成Hbase</strong></p>
<ol>
<li><p>修改conf&#x2F;atlas-application.properties</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#修改atlas存储数据主机</span><br><span class="line">atlas.graph.storage.hostname=bigdata1:2181,bigdata2:2181,bigdata3:2181</span><br></pre></td></tr></table></figure>
</li>
<li><p>进入到conf&#x2F;hbase路径，添加Hbase集群的配置文件到${Atlas_Home}</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /opt/module/hbase/conf/ /opt/module/atlas/conf/hbase/</span><br></pre></td></tr></table></figure>
</li>
<li><p>在&#x2F;opt&#x2F;module&#x2F;atlas&#x2F;conf&#x2F;atlas-env.sh中添加HBASE_CONF_DIR</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#添加HBase配置文件路径</span><br><span class="line">export HBASE_CONF_DIR=/opt/module/atlas/conf/hbase/conf</span><br></pre></td></tr></table></figure></li>
</ol>
<p><strong>Atlas集成Solr</strong></p>
<ol>
<li><p>进入&#x2F;opt&#x2F;module&#x2F;atlas&#x2F;conf目录，修改配置文件atlas-application.properties </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#修改如下配置</span><br><span class="line">atlas.graph.index.search.solr.zookeeper-url=bigdata1:2181,bigdata2:2181,bigdata3:2181</span><br></pre></td></tr></table></figure>
</li>
<li><p>将Atlas自带的Solr文件夹拷贝到外部Solr集群的各个节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp -r /opt/module/atlas/conf/solr /opt/module/solr/</span><br></pre></td></tr></table></figure>

<p>进入到&#x2F;opt&#x2F;module&#x2F;solr路径，修改拷贝过来的配置文件名称为atlas_conf</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv solr atlas_conf</span><br></pre></td></tr></table></figure>



<p>在Cloud模式下，启动Solr（需要提前启动Zookeeper集群），并创建collection</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/solr create -c vertex_index -d /opt/module/solr/atlas_conf -shards 3 -replicationFactor 2</span><br><span class="line">bin/solr create -c edge_index -d /opt/module/solr/atlas_conf -shards 3 -replicationFactor 2</span><br><span class="line">bin/solr create -c fulltext_index -d /opt/module/solr/atlas_conf -shards 3 -replicationFactor 2</span><br></pre></td></tr></table></figure>

<blockquote>
<p>-shards 3：表示该集合分片数为3</p>
<p>-replicationFactor 2：表示每个分片数都有2个备份<br>vertex_index、edge_index、fulltext_index：表示集合名称<br>注意：如果需要删除vertex_index、edge_index、fulltext_index等collection可以执行命令<code>bin/solr delete -c $&#123;collection_name&#125;</code>。</p>
</blockquote>
</li>
</ol>
<p><strong>Atlas集成Kafka</strong></p>
<p>进入&#x2F;opt&#x2F;module&#x2F;atlas&#x2F;conf&#x2F;目录，修改配置文件atlas-application.properties<br>vim atlas-application.properties</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#########  Notification Configs  #########</span><br><span class="line">atlas.notification.embedded=false</span><br><span class="line">atlas.kafka.zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181</span><br><span class="line">atlas.kafka.bootstrap.servers=hadoop102:9092,hadoop103:9092,hadoop104:9092</span><br><span class="line">atlas.kafka.zookeeper.session.timeout.ms=4000</span><br><span class="line">atlas.kafka.zookeeper.connection.timeout.ms=2000</span><br><span class="line"></span><br><span class="line">atlas.kafka.enable.auto.commit=true</span><br></pre></td></tr></table></figure>

<p>启动Kafka集群，并创建Topic</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --zookeeper bigdata1:2181, bigdata2:2181, bigdata3:2181 --create --replication-factor 3 --partitions 3 --topic _HOATLASOK</span><br><span class="line">bin/kafka-topics.sh --zookeeper  bigdata1:2181, bigdata2:2181, bigdata3:2181 --create --replication-factor 3 --partitions 3 --topic ATLAS_ENTITIES</span><br></pre></td></tr></table></figure>



<p><strong>Atlas其他配置</strong></p>
<p>进入&#x2F;opt&#x2F;module&#x2F;atlas&#x2F;conf&#x2F;目录，修改配置文件atlas-application.properties<br>vim atlas-application.properties</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#########  Server Properties  #########</span><br><span class="line">atlas.rest.address=http://bigdata1:21000</span><br><span class="line"># If enabled and set to true, this will run setup steps when the server starts</span><br><span class="line">atlas.server.run.setup.on.start=false</span><br><span class="line"></span><br><span class="line">#########  Entity Audit Configs  #########</span><br><span class="line">atlas.audit.hbase.zookeeper.quorum=bigdata1:2181,bigdata2:2181,bigdata3:2181</span><br></pre></td></tr></table></figure>

<p><strong>vim atlas-log4j.xml</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#去掉如下代码的注释</span><br><span class="line">&lt;appender name=&quot;perf_appender&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt;</span><br><span class="line">    &lt;param name=&quot;file&quot; value=&quot;$&#123;atlas.log.dir&#125;/atlas_perf.log&quot; /&gt;</span><br><span class="line">    &lt;param name=&quot;datePattern&quot; value=&quot;&#x27;.&#x27;yyyy-MM-dd&quot; /&gt;</span><br><span class="line">    &lt;param name=&quot;append&quot; value=&quot;true&quot; /&gt;</span><br><span class="line">    &lt;layout class=&quot;org.apache.log4j.PatternLayout&quot;&gt;</span><br><span class="line">        &lt;param name=&quot;ConversionPattern&quot; value=&quot;%d|%t|%m%n&quot; /&gt;</span><br><span class="line">    &lt;/layout&gt;</span><br><span class="line">&lt;/appender&gt;</span><br><span class="line"></span><br><span class="line">&lt;logger name=&quot;org.apache.atlas.perf&quot; additivity=&quot;false&quot;&gt;</span><br><span class="line">    &lt;level value=&quot;debug&quot; /&gt;</span><br><span class="line">    &lt;appender-ref ref=&quot;perf_appender&quot; /&gt;</span><br><span class="line">&lt;/logger&gt;</span><br></pre></td></tr></table></figure>



<p><strong>Atlas集成Hive</strong></p>
<p>进入&#x2F;opt&#x2F;module&#x2F;atlas&#x2F;conf&#x2F;目录，修改配置文件atlas-application.properties<br>vim atlas-application.properties</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">######### Hive Hook Configs #######</span><br><span class="line">atlas.hook.hive.synchronous=false</span><br><span class="line">atlas.hook.hive.numRetries=3</span><br><span class="line">atlas.hook.hive.queueSize=10000</span><br><span class="line">atlas.cluster.name=primary</span><br></pre></td></tr></table></figure>

<p>将atlas-application.properties配置文件加入到atlas-plugin-classloader-1.0.0.jar中<br>zip -u &#x2F;opt&#x2F;module&#x2F;atlas&#x2F;hook&#x2F;hive&#x2F;atlas-plugin-classloader-0.8.4.jar &#x2F;opt&#x2F;module&#x2F;atlas&#x2F;conf&#x2F;atlas-application.properties<br>cp &#x2F;opt&#x2F;module&#x2F;atlas&#x2F;conf&#x2F;atlas-application.properties &#x2F;opt&#x2F;module&#x2F;hive&#x2F;conf&#x2F;</p>
<blockquote>
<p>原因：这个配置不能参照官网，将配置文件考到hive的conf中。参考官网的做法一直读取不到atlas-application.properties配置文件，看了源码发现是在classpath读取的这个配置文件，所以将它压到jar里面。</p>
</blockquote>
<p>在&#x2F;opt&#x2F;module&#x2F;hive&#x2F;conf&#x2F;hive-site.xml文件中设置Atlas hook<br>vim hive-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">      &lt;name&gt;hive.exec.post.hooks&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;org.apache.atlas.hive.hook.HiveHook&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p>修改hive的hive-env.sh文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#在tez引擎依赖的jar包后面追加hive插件相关jar包</span><br><span class="line">export HIVE_AUX_JARS_PATH=/opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-lzo-0.4.20.jar$TEZ_JARS,/opt/module/atlas/hook/hive/atlas-plugin-classloader-0.8.4.jar,/opt/module/atlas/hook/hive/hive-bridge-shim-0.8.4.jar</span><br></pre></td></tr></table></figure>



<h4 id="单点启动-2"><a href="#单点启动-2" class="headerlink" title="单点启动"></a>单点启动</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/atlas_stop.py</span><br><span class="line">bin/atlas_start.py</span><br></pre></td></tr></table></figure>



<h4 id="Web界面-5"><a href="#Web界面-5" class="headerlink" title="Ｗeb界面"></a>Ｗeb界面</h4><p>访问地址：<a target="_blank" rel="noopener" href="http://bigdata1:21000/">http://bigdata1:21000</a><br>错误信息查看路径：&#x2F;opt&#x2F;module&#x2F;atlas&#x2F;logs&#x2F;*.out和application.log</p>
<p>账户：admin<br>密码：admin</p>
<h4 id="测试-4"><a href="#测试-4" class="headerlink" title="测试"></a>测试</h4><p>登录solr web控制台：<a href="#/~cloud">http://hadoop102:8983/solr/#/~cloud</a> 看到如下图显示</p>
<p><img src="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B.assets%5C3f92c743b08548e7852c270f0a5fab8c.png" alt="21580557-6dc93d42eb0cf7d0.png"></p>
<h3 id="2-3-4-Zabbix-4-2-8"><a href="#2-3-4-Zabbix-4-2-8" class="headerlink" title="2.3.4 Zabbix 4.2.8"></a>2.3.4 Zabbix 4.2.8</h3><h4 id="安装应用-11"><a href="#安装应用-11" class="headerlink" title="安装应用"></a>安装应用</h4><ol>
<li><p>每台安装yum的repo文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo rpm -Uvh https://mirrors.aliyun.com/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-2.el7.noarch.rpm</span><br></pre></td></tr></table></figure>
</li>
<li><p>将文件中的镜像域名替换为阿里云</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sed -i &#x27;s/http:\/\/repo.zabbix.com/https:\/\/mirrors.aliyun.com\/zabbix/g&#x27; /etc/yum.repos.d/zabbix.repo</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装</p>
<ul>
<li><p>bigdata1：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y zabbix-server-mysql zabbix-web-mysql zabbix-agent</span><br></pre></td></tr></table></figure>
</li>
<li><p>bigdata2和bigdata3</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bigdata2： sudo yum install -y zabbix-agent</span><br><span class="line">bigdata3： sudo yum install -y zabbix-agent</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>MySQL创建数据库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h 192.168.32.244 -uroot -phxr -e&quot;create database zabbix charset utf8 collate utf8_bin&quot;;</span><br></pre></td></tr></table></figure>

<p>使用zabbix的建表脚本建表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zcat /usr/share/doc/zabbix-server-mysql-4.0.29/create.sql.gz | mysql -h 192.168.32.244 -uroot -phxr zabbix</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置Zabbix_Server<br>在bigdata1中的&#x2F;etc&#x2F;zabbix&#x2F;zabbix_server.conf配置文件中添加</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DBHost=bigdata3</span><br><span class="line">DBName=zabbix</span><br><span class="line">DBUser=root</span><br><span class="line">DBPassword=hxr</span><br></pre></td></tr></table></figure>

<p>在所有节点的&#x2F;etc&#x2F;zabbix&#x2F;zabbix_server.conf配置文件中修改</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 修改</span><br><span class="line">Server=bigdata1</span><br><span class="line"># 注销</span><br><span class="line"># ServerActive=127.0.0.1</span><br><span class="line"># Hostname=Zabbix server</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置Zabbix Web时区<br>在&#x2F;etc&#x2F;httpd&#x2F;conf.d&#x2F;zabbix.conf文件中添加</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">php_value date.timezone Asia/Shanghai</span><br></pre></td></tr></table></figure>


</li>
<li><p>启动Zabbix</p>
<ul>
<li><p>bigdata1启动：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start/stop zabbix-server zabbix-agent httpd     (httpd是访问html等页面的入口)</span><br></pre></td></tr></table></figure>

<p>bigdata1设置开机自启：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl enable/disable zabbix-server zabbix-agent httpd</span><br></pre></td></tr></table></figure>
</li>
<li><p>bigdata2&#x2F;3启动：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start/stop zabbix-agent </span><br></pre></td></tr></table></figure>

<p>设置开机自启：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl enable/disable zabbix-agent</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>访问页面<br><a target="_blank" rel="noopener" href="http://192.168.32.242/zabbix">http://192.168.32.242/zabbix</a><br>在页面中完成对Zabbix_Web的数据库等配置<br>如果配置出现错误，可以在配置文件&#x2F;etc&#x2F;zabbix&#x2F;web&#x2F;zabbix.conf.php中进行修改<br>异常日志可以查看  cat &#x2F;var&#x2F;log&#x2F;zabbix&#x2F;zabbix_server.log</p>
</li>
<li><p>配置主机<br>在配置-&gt; 主机-&gt; 创建主机 中添加需要监控的主机</p>
</li>
<li><p>配置监控项<br>创建完主机后，点击监控项进行监控项的创建<br>如监控datanode进行是否正常运行<br>![image.png](大数据框架安装教程.assetsb6398dc77149fda4ced98ffce4af82.png)</p>
</li>
<li><p>配置触发器<br>点击触发器进行创建<br><img src="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B.assets%5Cd3b120c608914748a8a22e34464471b7.png" alt="image.png"></p>
</li>
<li><p>通知方式设置<br>在管理-&gt; 报警媒介类型 中进行通知报警的配置<br><img src="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B.assets%5C1cd0c6f0c9484773b93225149582bcd0.png" alt="image.png"></p>
</li>
<li><p>创建动作<br>在配置-&gt; 动作中创建动作，为触发器设置动作(发邮件)。<br><img src="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B.assets%5C5c1a884f37a94a7d8ed806e078b60dd7.png" alt="image.png"></p>
</li>
</ol>
<p><img src="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B.assets%5C24ddf364f531478d9aafe456f53309e9.png" alt="image.png"></p>
<ol start="14">
<li><p>为用户配置邮箱<br>在用户的基本资料中配置<br>![image.png](大数据框架安装教程.assets1f883d1b6194d32893c9078bb151b34.png)</p>
</li>
<li><p>使用模版为每个节点进行配置<br>默认有很多框架的模板可以选择，如MySQL、redis等。但是没有hadoop的模板，需要自己配置。<br>在配置-&gt; 模板 中进行模板配置，创建监控项、触发器，然后应用到主机上。<br><img src="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B.assets%5C2fcba79e1fa444be9363eff7be852f7f.png" alt="image.png"><br>注意需要修改动作来为模板的触发器绑定动作。</p>
</li>
</ol>
<br>
# 四、附

<h2 id="4-1-UI界面"><a href="#4-1-UI界面" class="headerlink" title="4.1 UI界面"></a>4.1 UI界面</h2><p>192.168.32.242:50070  192.168.32.243:8088</p>
<p>192.168.32.242:8443 azkaban(admin:admin)</p>
<p><a target="_blank" rel="noopener" href="http://192.168.32.243/ganglia">http://192.168.32.243/ganglia</a> ganglia(监控flume)</p>
<p>192.168.32.242:16010 hbase  192.168.32.242:8983 solr  192.168.32.242:21000 atlas(admin:admin)</p>
<p>192.168.32.244:38682 flink(每次启动都会变，具体查看&#x2F;opt&#x2F;module&#x2F;flink-1.12.0&#x2F;yarn-session.log)</p>
<p><a target="_blank" rel="noopener" href="http://192.168.32.242/zabbix">http://192.168.32.242/zabbix</a> Zabbbix(Admin:zabbix，报警邮箱<a href="mailto:792965772@qq.com">792965772@qq.com</a>)</p>
<p><a target="_blank" rel="noopener" href="http://192.168.101.179:6080/">http://192.168.101.179:6080</a>  Ranger界面（admin&#x2F;bigdata123）</p>
<p><a target="_blank" rel="noopener" href="http://192.168.101.180:9090/">http://192.168.101.180:9090</a> Prometheus界面<br><a target="_blank" rel="noopener" href="http://192.168.101.180:3000/">http://192.168.101.180:3000</a> Grafana界面 (admin&#x2F;admin)<br><a target="_blank" rel="noopener" href="http://192.168.101.180:9363/metrics">http://192.168.101.180:9363/metrics</a> Prometheus监控上报数据</p>
<table>
<thead>
<tr>
<th>页面</th>
<th>地址</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>hdfs页面</td>
<td>192.168.32.242:50070</td>
<td></td>
</tr>
<tr>
<td>yarn页面</td>
<td>192.168.32.243:8088</td>
<td></td>
</tr>
<tr>
<td>azkaban页面</td>
<td>192.168.32.242:8443</td>
<td>admin:admin</td>
</tr>
<tr>
<td>flume监控页面</td>
<td><a target="_blank" rel="noopener" href="http://192.168.32.243/ganglia">http://192.168.32.243/ganglia</a></td>
<td></td>
</tr>
<tr>
<td>flink</td>
<td>192.168.32.244:38682</td>
<td>每次启动都会变，具体查看&#x2F;opt&#x2F;module&#x2F;flink-1.12.0&#x2F;yarn-session.log</td>
</tr>
<tr>
<td>Zabbbix</td>
<td><a target="_blank" rel="noopener" href="http://192.168.32.242/zabbix">http://192.168.32.242/zabbix</a></td>
<td>Admin:zabbix，报警邮箱<a href="mailto:792965772@qq.com">792965772@qq.com</a></td>
</tr>
<tr>
<td>hbase页面</td>
<td>192.168.32.242:16010</td>
<td></td>
</tr>
<tr>
<td>solr页面</td>
<td>192.168.32.242:8983</td>
<td></td>
</tr>
<tr>
<td>Atlas页面</td>
<td>192.168.32.242:21000</td>
<td>admin:admin</td>
</tr>
</tbody></table>
<h2 id="4-2-启动命令"><a href="#4-2-启动命令" class="headerlink" title="4.2 启动命令"></a>4.2 启动命令</h2><table>
<thead>
<tr>
<th>组件</th>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>hdfs</td>
<td>start-dfs.sh</td>
<td>bigdata1节点上执行</td>
</tr>
<tr>
<td>yarn</td>
<td>start-yarn.sh</td>
<td>bigdata2节点上执行</td>
</tr>
<tr>
<td>historyjob</td>
<td>mr-jobhistory-daemon.sh start historyserver</td>
<td>bigdata3节点上执行</td>
</tr>
<tr>
<td>hive</td>
<td>nohup .&#x2F;hive –service metastore &amp;;  nohup .&#x2F;hive –service hiveserver2 &amp;;</td>
<td>bigdata1节点上hive&#x2F;bin目录下执行</td>
</tr>
<tr>
<td>zookeeper</td>
<td>zk-server.sh start</td>
<td>bigdata1节点上执行</td>
</tr>
<tr>
<td>kafka</td>
<td>kafka-server.sh start</td>
<td>bigdata1节点上执行</td>
</tr>
<tr>
<td>flink集群</td>
<td>export HADOOP_CLASSPATH&#x3D;<code>hadoop classpath</code>;  nohup .&#x2F;yarn-session.sh -s 2 -jm 1024 -tm 2048 -nm flink-on-yarn -qu flink -d 1&gt;&#x2F;opt&#x2F;module&#x2F;flink-1.12.0&#x2F;yarn-session.log 2&gt;&#x2F;opt&#x2F;module&#x2F;flink-1.12.0&#x2F;yarn-session.err &amp;;</td>
<td>bigdata1节点上的flink&#x2F;bin目录下执行</td>
</tr>
<tr>
<td>sqoop</td>
<td></td>
<td>在脚本中调用</td>
</tr>
<tr>
<td>azkaban</td>
<td>server&#x2F;bin&#x2F;azkaban-web-start.sh;  executor&#x2F;bin&#x2F;azkaban-executor-start.sh;</td>
<td>bigdata1节点上的azkaban目录下执行</td>
</tr>
<tr>
<td>ganglia</td>
<td>docker start ganglia</td>
<td>bigdata2节点上执行</td>
</tr>
<tr>
<td>zabbix</td>
<td>bigdata1节点上 <code>sudo systemctl start/stop zabbix-server zabbix-agent httpd</code>;  bigdata2&#x2F;3节点上 <code>sudo systemctl start/stop zabbix-agent</code>;</td>
<td></td>
</tr>
<tr>
<td>hbase</td>
<td>bin&#x2F;start-hbase.sh</td>
<td>bigdata1节点上hbase目录下执行</td>
</tr>
<tr>
<td>solr</td>
<td>solr.sh start</td>
<td>bigdata1节点上执行</td>
</tr>
<tr>
<td>atlas</td>
<td>bin&#x2F;atlas_start.py</td>
<td>bigdata1节点上执行</td>
</tr>
<tr>
<td>Prometheus</td>
<td>nohup .&#x2F;prometheus –web.enable-lifecycle –config.file&#x3D;prometheus.yml &gt; .&#x2F;prometheus.log 2&gt;&amp;1 &amp;</td>
<td>bigdata2节点上的Prometheus目录下执行</td>
</tr>
<tr>
<td>Grafana</td>
<td>nohup .&#x2F;bin&#x2F;grafana-server web &gt; .&#x2F;grafana.log 2&gt;&amp;1 &amp;</td>
<td>bigdata2节点上的Grafana目录下执行</td>
</tr>
</tbody></table>
<h2 id="4-3-各jps进程名对应的组件"><a href="#4-3-各jps进程名对应的组件" class="headerlink" title="4.3 各jps进程名对应的组件"></a>4.3 各jps进程名对应的组件</h2><table>
<thead>
<tr>
<th>组件</th>
<th>进程名</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>NameNode  SecondaryNameNode  DataNode</td>
<td></td>
</tr>
<tr>
<td>Yarn</td>
<td>ResourceManager  NodeManager  JobHistoryServer  ApplicationHistoryServer(timelineserver)</td>
<td></td>
</tr>
<tr>
<td>Zookeeper</td>
<td>QuorumPeerMain</td>
<td></td>
</tr>
<tr>
<td>Kafka</td>
<td>Kafka</td>
<td></td>
</tr>
<tr>
<td>Flume</td>
<td>Application</td>
<td></td>
</tr>
<tr>
<td>Hive(hiveserver2&#x2F;metastore)</td>
<td>RunJar</td>
<td></td>
</tr>
<tr>
<td>Azkaban</td>
<td>AzkabanExecutorServer  AzkabanWebServer</td>
<td></td>
</tr>
<tr>
<td>Sqoop</td>
<td>Sqoop</td>
<td></td>
</tr>
<tr>
<td>Flink(standalone)</td>
<td>TaskManagerRunner  StandaloneSessionClusterEntrypoint</td>
<td></td>
</tr>
<tr>
<td>Flink(yarn-session)</td>
<td>FlinkYarnSessionCli  YarnSessionClusterEntrypoint(为FlinkJobManager)  YarnTaskExecutorRunner</td>
<td></td>
</tr>
<tr>
<td>Hbase</td>
<td>HMaster  HRegionServer</td>
<td></td>
</tr>
<tr>
<td>Solr</td>
<td>jar</td>
<td></td>
</tr>
<tr>
<td>Atlas</td>
<td>Atlas</td>
<td></td>
</tr>
<tr>
<td>Ranger Admin</td>
<td>EmbeddedServer</td>
<td></td>
</tr>
<tr>
<td>RangerUsersync</td>
<td>UnixAuthenticationService</td>
<td></td>
</tr>
<tr>
<td>Spark-session</td>
<td>SparkSubmit,ApplicationMaster,YarnCoarseGrainedExecutorBackend</td>
<td></td>
</tr>
</tbody></table>
<h2 id="4-4-常用端口号"><a href="#4-4-常用端口号" class="headerlink" title="4.4 常用端口号"></a>4.4 常用端口号</h2><table>
<thead>
<tr>
<th>组件</th>
<th>端口号</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Hadoop</td>
<td>50070：hdfs.namenode.http-address:  50075：Hdfs.datanode.http-address  50090：SecondaryNameNode辅助名称节点端口号  50010：Hdfs.datanode.address  8088：Yarn.resourcemanager.webapp.address  19888：历史服务器web访问端口  8020：namenode节点active状态下的端口号  9000端口：fileSystem默认的端口号  8032：resourcemanager（jobtracker）的服务端口号</td>
<td></td>
</tr>
<tr>
<td>Zookeeper</td>
<td>2181：zookeeper的端口号  2888：zookeeper之间通讯的端口  3888：zookeeper推选leader的端口  8485：journalnode默认的端口号</td>
<td></td>
</tr>
<tr>
<td>Kafka</td>
<td>9092：kafka端口号  8086：Kafka Monitor的访问网址（可在启动脚本中指定）  9000：Kafka Manager的访问网址，默认是9000，与namenode端口冲突，bin&#x2F;kafka-manager -Dhttp.port&#x3D;9090</td>
<td></td>
</tr>
<tr>
<td>Flume</td>
<td>41414：flume监控的端口</td>
<td></td>
</tr>
<tr>
<td>Hive</td>
<td>9083：hive元数据metastore的端口号(Presto需要读取hive的元数据库)  10000：hive2端口</td>
<td></td>
</tr>
<tr>
<td>Azkaban</td>
<td>8443：所指定的jetty服务器的web端口  8081：通讯端口</td>
<td></td>
</tr>
<tr>
<td>Oozie</td>
<td>11000：Oozie 的web端口号</td>
<td></td>
</tr>
<tr>
<td>Sqoop</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Flink</td>
<td>8081：Flink的standalone模式Web端口号  6123：Flink的jobmanager和taskmanager内部通信端口  37807：Flink的yarn-session模式Web端口号</td>
<td></td>
</tr>
<tr>
<td>Spark</td>
<td>7077：spark的standalone的master端口  4040：local模式spark的driver的web  8080：standalone模式spark的master的web  8088：client模式的web端口  18080：spark的historyserver的web</td>
<td></td>
</tr>
<tr>
<td>Hbase</td>
<td>16010：HBASE的web端口号  16000：HBase的master的通讯端口  16020：regionserver的端口号  16030：regionserver的web端口</td>
<td></td>
</tr>
<tr>
<td>Solr</td>
<td>8983：solr</td>
<td></td>
</tr>
<tr>
<td>Atlas</td>
<td>21000：Atlas</td>
<td></td>
</tr>
<tr>
<td>Clickhouse</td>
<td>9000：TCP端口，Clickhouse client 默认连接端口； 8123：Http端口</td>
<td></td>
</tr>
<tr>
<td>Kettle</td>
<td>8080：kettlemaster节点  8081：kettleslave1节点  8082：kettleslave2节点</td>
<td></td>
</tr>
<tr>
<td>即系查询框架</td>
<td>7070：kylin的web端口  8881：presto的httpserver（即coordinator的端口）  9095： imply的web端口（druid的ui）  21000：impala端口  25010：impala日志网页端口</td>
<td></td>
</tr>
<tr>
<td>数据库</td>
<td>3306：MySQL  1521：Orical  27017：MongoDB</td>
<td></td>
</tr>
<tr>
<td>Redis</td>
<td>6379</td>
<td></td>
</tr>
<tr>
<td>ELK</td>
<td>9300：elasticsearch官方客户端连接、内部通讯端口  9200：elasticsearch集群、控制台和http访问端口  5601：kibana服务端口</td>
<td></td>
</tr>
<tr>
<td>Zabbix</td>
<td>10051：Zabbix_Server通讯端口</td>
<td></td>
</tr>
<tr>
<td>Prometheus</td>
<td>9090：prometheus  9100：node-productor  9104：mysqld-exporter  3000：Grafana</td>
<td></td>
</tr>
<tr>
<td>平台</td>
<td>7180：CDM  8080：HDP  8888：hue未优化，8889：hue优化</td>
<td></td>
</tr>
</tbody></table>
<h2 id="4-5-shell脚本"><a href="#4-5-shell脚本" class="headerlink" title="4.5 shell脚本"></a>4.5 shell脚本</h2><p><strong>xsyncmy</strong>：文件分发脚本</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt 1 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">	<span class="built_in">echo</span> <span class="string">&quot;----- 未进行传参 -----&quot;</span></span><br><span class="line">	<span class="built_in">exit</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> <span class="variable">$@</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">	<span class="keyword">if</span> [ -e <span class="variable">$file</span> ]</span><br><span class="line">	<span class="keyword">then</span></span><br><span class="line">		DIRNAME=`<span class="built_in">cd</span> $(<span class="built_in">dirname</span> <span class="variable">$&#123;file&#125;</span>);<span class="built_in">pwd</span>`</span><br><span class="line">		BASENAME=`<span class="built_in">basename</span> <span class="variable">$&#123;file&#125;</span>`</span><br><span class="line">		USER=`<span class="built_in">whoami</span>`</span><br><span class="line">	</span><br><span class="line">		<span class="keyword">for</span> host <span class="keyword">in</span> bigdata2 bigdata3</span><br><span class="line">		<span class="keyword">do</span></span><br><span class="line">			<span class="built_in">echo</span> ----- 文件 <span class="variable">$DIRNAME</span>/<span class="variable">$BASENAME</span> 传输到<span class="variable">$&#123;host&#125;</span> -----</span><br><span class="line">			rsync -av <span class="variable">$&#123;DIRNAME&#125;</span>/<span class="variable">$&#123;BASENAME&#125;</span> <span class="variable">$&#123;USER&#125;</span>@<span class="variable">$&#123;host&#125;</span>:<span class="variable">$&#123;DIRNAME&#125;</span></span><br><span class="line">		<span class="keyword">done</span></span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		<span class="built_in">echo</span> ----- <span class="variable">$&#123;file&#125;</span>文件不存在 -----</span><br><span class="line">	<span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<p><strong>jps-server.sh</strong>：查看3个节点jps进程脚本</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#jps脚本</span></span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> bigdata1 bigdata2 bigdata3</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">	<span class="built_in">echo</span> ----- <span class="variable">$&#123;host&#125;</span> -----</span><br><span class="line">	ssh <span class="variable">$&#123;host&#125;</span> <span class="string">&quot;jps | grep -iv jps&quot;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<p><strong>zk-server.sh</strong>：zookeeper集群的 启动&#x2F;关闭&#x2F;状态检查 脚本</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#zk启动/停止脚本</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)</span><br><span class="line">	<span class="built_in">echo</span> ----- 开启zookeeper集群 -----</span><br><span class="line">	<span class="keyword">for</span> host <span class="keyword">in</span> bigdata1 bigdata2 bigdata3</span><br><span class="line">	<span class="keyword">do</span>	</span><br><span class="line">		ssh <span class="variable">$&#123;host&#125;</span> <span class="string">&quot;/opt/module/zookeeper-3.4.10/bin/zkServer.sh start&quot;</span></span><br><span class="line">	<span class="keyword">done</span></span><br><span class="line">;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)</span><br><span class="line">	<span class="built_in">echo</span> ----- 关闭zookeeper集群 -----</span><br><span class="line">	<span class="keyword">for</span> host <span class="keyword">in</span> bigdata1 bigdata2 bigdata3</span><br><span class="line">	<span class="keyword">do</span>	</span><br><span class="line">		ssh <span class="variable">$&#123;host&#125;</span> <span class="string">&quot;/opt/module/zookeeper-3.4.10/bin/zkServer.sh stop&quot;</span></span><br><span class="line">	<span class="keyword">done</span></span><br><span class="line">;;</span><br><span class="line"><span class="string">&quot;status&quot;</span>)</span><br><span class="line">	<span class="built_in">echo</span> ----- 查看zookeeper集群状态 -----</span><br><span class="line">	<span class="keyword">for</span> host <span class="keyword">in</span> bigdata1 bigdata2 bigdata3</span><br><span class="line">	<span class="keyword">do</span></span><br><span class="line">		ssh <span class="variable">$&#123;host&#125;</span> <span class="string">&quot;/opt/module/zookeeper-3.4.10/bin/zkServer.sh status&quot;</span></span><br><span class="line">	<span class="keyword">done</span></span><br><span class="line">;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>

<p>**kafka-server.sh (-deamon 效果同 nohup xxx 1&gt;&#x2F;dev&#x2F;null 2&gt;1 &amp;)**：Kafka集群的 启动&#x2F;关闭脚本</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)</span><br><span class="line">	<span class="keyword">for</span> host <span class="keyword">in</span> bigdata1 bigdata2 bigdata3</span><br><span class="line">	<span class="keyword">do</span></span><br><span class="line">		ssh <span class="variable">$&#123;host&#125;</span> <span class="string">&quot;source /etc/profile ; export JMX_PORT=9988 ; nohup /opt/module/kafka-2.11/bin/kafka-server-start.sh /opt/module/kafka-2.11/config/server.properties 1&gt;/dev/null 2&gt;&amp;1 &amp;&quot;</span></span><br><span class="line">		<span class="keyword">if</span> [ $? -eq 0 ]</span><br><span class="line">		<span class="keyword">then</span></span><br><span class="line">			<span class="built_in">echo</span> ----- <span class="variable">$&#123;host&#125;</span> kafka启动成功 -----</span><br><span class="line">		<span class="keyword">fi</span></span><br><span class="line">	<span class="keyword">done</span></span><br><span class="line">;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)</span><br><span class="line">	<span class="keyword">for</span> host <span class="keyword">in</span> bigdata1 bigdata2 bigdata3</span><br><span class="line">	<span class="keyword">do</span></span><br><span class="line">		ssh <span class="variable">$&#123;host&#125;</span> <span class="string">&quot;source /etc/profile ; /opt/module/kafka-2.11/bin/kafka-server-stop.sh&quot;</span></span><br><span class="line">		<span class="keyword">if</span> [ $? -eq 0 ]</span><br><span class="line">		<span class="keyword">then</span></span><br><span class="line">			<span class="built_in">echo</span> ----- <span class="variable">$&#123;host&#125;</span> kafka关闭成功 -----</span><br><span class="line">		<span class="keyword">fi</span></span><br><span class="line">	<span class="keyword">done</span></span><br><span class="line">;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>

<p><strong>flume-server.sh</strong>：Flume的 启动&#x2F;关闭脚本</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)</span><br><span class="line">	<span class="keyword">for</span> host <span class="keyword">in</span> bigdata1 <span class="comment">#bigdata2</span></span><br><span class="line">	<span class="keyword">do</span></span><br><span class="line"><span class="comment">#		ssh $&#123;host&#125; &quot;source /etc/profile ; nohup /opt/module/flume-1.7.0/bin/flume-ng agent -n a1 -c /opt/module/flume-1.7.0/conf -f /opt/module/flume-1.7.0/job/file-kafka-hdfs.conf 1&gt;/dev/null 2&gt;&amp;1 &amp;&quot;</span></span><br><span class="line">		<span class="comment">#ssh $&#123;host&#125; &quot;source /etc/profile ; nohup /opt/module/flume-1.7.0/bin/flume-ng agent -n a1 -c /opt/module/flume-1.7.0/conf -f /opt/module/flume-1.7.0/job/log-kafka.conf 1&gt;/dev/null 2&gt;&amp;1 &amp;&quot;</span></span><br><span class="line">		ssh bigdata1 <span class="string">&quot;source /etc/profile ; nohup /opt/module/flume-1.7.0/bin/flume-ng agent -n a1 -c /opt/module/flume-1.7.0/conf -f /opt/module/flume-1.7.0/job/log-kafka.conf 1&gt;/dev/null 2&gt;&amp;1 &amp;&quot;</span></span><br><span class="line">		<span class="comment">#ssh $&#123;host&#125; &quot;source /etc/profile ; nohup /opt/module/flume-1.7.0/bin/flume-ng agent -n a2 -c /opt/module/flume-1.7.0/conf -f /opt/module/flume-1.7.0/job/kafka-hdfs.conf 1&gt;/dev/null 2&gt;&amp;1 &amp;&quot;</span></span><br><span class="line">		ssh bigdata2 <span class="string">&quot;source /etc/profile ; nohup /opt/module/flume-1.7.0/bin/flume-ng agent -n a2 -c /opt/module/flume-1.7.0/conf -f /opt/module/flume-1.7.0/job/kafka-hdfs.conf 1&gt;/dev/null 2&gt;&amp;1 &amp;&quot;</span></span><br><span class="line">		<span class="keyword">if</span> [ $? -eq 0 ]</span><br><span class="line">		<span class="keyword">then</span></span><br><span class="line">			<span class="built_in">echo</span> ----- <span class="variable">$&#123;host&#125;</span> flume启动成功 -----</span><br><span class="line">		<span class="keyword">fi</span></span><br><span class="line">	<span class="keyword">done</span></span><br><span class="line">;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)</span><br><span class="line">	<span class="keyword">for</span> host <span class="keyword">in</span> bigdata1 <span class="comment">#bigdata2</span></span><br><span class="line">	<span class="keyword">do</span></span><br><span class="line">		ssh <span class="variable">$&#123;host&#125;</span> <span class="string">&quot;source /etc/profile ; ps -ef | awk -F \&quot; \&quot; &#x27;/log-kafka.conf/ &amp;&amp; !/awk/&#123;print \$2&#125;&#x27; | xargs kill &quot;</span></span><br><span class="line">		ssh <span class="variable">$&#123;host&#125;</span> <span class="string">&quot;source /etc/profile ; ps -ef | awk -F \&quot; \&quot; &#x27;/kafka-hdfs.conf/ &amp;&amp; !/awk/&#123;print \$2&#125;&#x27; | xargs kill &quot;</span></span><br><span class="line">		<span class="keyword">if</span> [ $? -eq 0 ]</span><br><span class="line">		<span class="keyword">then</span></span><br><span class="line">			<span class="built_in">echo</span> ----- <span class="variable">$&#123;host&#125;</span> flume关闭成功 -----</span><br><span class="line">		<span class="keyword">fi</span></span><br><span class="line">	<span class="keyword">done</span></span><br><span class="line">;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>

<p><strong>solr-server.sh</strong> ：Solr的 启动&#x2F;关闭脚本</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)&#123;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> bigdata1 bigdata2 bigdata3</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        ssh <span class="variable">$i</span> <span class="string">&quot;/opt/module/solr-5.2.1/bin/solr start&quot;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)&#123;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> bigdata1 bigdata2 bigdata3</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        ssh <span class="variable">$i</span> <span class="string">&quot;/opt/module/solr-5.2.1/bin/solr stop&quot;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>

<p>azkaban-3.84.4 脚本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">start-web()&#123;</span><br><span class="line">    ssh bigdata2 &#x27;cd /opt/module/azkaban-3.84.4/web/;bin/shutdown-web.sh&#x27;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">stop-web()&#123;</span><br><span class="line">    ssh bigdata2 &#x27;cd /opt/module/azkaban-3.84.4/web/;bin/shutdown-web.sh&#x27;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">start-exec()&#123;</span><br><span class="line">    for host in bigdata1 bigdata2 bigdata3;do</span><br><span class="line">        (ssh $&#123;host&#125; &#x27;cd /opt/module/azkaban-3.84.4/exec/;bin/start-exec.sh&#x27;)&amp;</span><br><span class="line">    done</span><br><span class="line">    wait</span><br><span class="line">&#125;</span><br><span class="line">stop-exec()&#123;</span><br><span class="line">    for host in bigdata1 bigdata2 bigdata3;do</span><br><span class="line">        (ssh $&#123;host&#125; &#x27;cd /opt/module/azkaban-3.84.4/exec/;bin/shutdown-exec.sh&#x27;)&amp;</span><br><span class="line">    done</span><br><span class="line">    wait</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">activate-exec()&#123;</span><br><span class="line">    for host in bigdata1 bigdata2 bigdata3;do</span><br><span class="line">        ssh $&#123;host&#125; curl -G &quot;$&#123;host&#125;:12321/executor?action=activate&quot; &amp;&amp; echo</span><br><span class="line">    done</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start-web&quot;)</span><br><span class="line">    start-web</span><br><span class="line">;;</span><br><span class="line">&quot;stop-web&quot;)</span><br><span class="line">    stop-web</span><br><span class="line">;;</span><br><span class="line">&quot;start-exec&quot;)</span><br><span class="line">    start-exec</span><br><span class="line">;;</span><br><span class="line">&quot;stop-exec&quot;)</span><br><span class="line">    stop-exec</span><br><span class="line">;;</span><br><span class="line">&quot;activate-exec&quot;)</span><br><span class="line">    activate-exec</span><br><span class="line">;;</span><br><span class="line">&quot;start&quot;)</span><br><span class="line">    start-exec</span><br><span class="line">    sleep 2</span><br><span class="line">    activate-exec</span><br><span class="line">    if [ &quot;$?&quot; -ne &quot;0&quot; ];then</span><br><span class="line">        stop-exec</span><br><span class="line">    fi</span><br><span class="line">    sleep 1</span><br><span class="line">    start-web</span><br><span class="line">;;</span><br><span class="line">&quot;stop&quot;)</span><br><span class="line">    stop-web</span><br><span class="line">    stop-exec</span><br><span class="line">;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<h2 id="4-6-其他"><a href="#4-6-其他" class="headerlink" title="4.6 其他"></a>4.6 其他</h2><ol>
<li><p>如果hdfs遇到权限问题是因为&#x2F;根目录用户为hxr，两种解决方式①hadoop dfs -chmod -R 777 &#x2F;  将根目录开放给其他用户②在操作时用hxr用户，-DHADOOP_USER_NAME&#x3D;hxr</p>
</li>
<li><p>hdfs dfsadmin -safemode leave   如果进入安全模式，可以通过该命令离开</p>
</li>
<li><p>hadoop checknative -a  查看本地库支持</p>
</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">CJ</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A6%BB%E7%BA%BF/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/">http://example.com/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A6%BB%E7%BA%BF/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Hexo</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A6%BB%E7%BA%BF/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%8D%87%E7%BA%A7/" title="大数据框架升级"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">大数据框架升级</div></div></a></div><div class="next-post pull-right"><a href="/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A6%BB%E7%BA%BF/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E5%85%A8%E8%84%9A%E6%9C%AC/" title="离线数仓全脚本"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">离线数仓全脚本</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">CJ</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">419</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">38</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%9E%B6%E6%9E%84"><span class="toc-number">1.</span> <span class="toc-text">一、架构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%A1%86%E6%9E%B6%E9%83%A8%E7%BD%B2"><span class="toc-number">2.</span> <span class="toc-text">二、框架部署</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E5%87%86%E5%A4%87"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 准备</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-1-%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99"><span class="toc-number">2.1.1.</span> <span class="toc-text">2.1.1 关闭防火墙</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-2-%E5%88%9B%E5%BB%BAhxr%E7%94%A8%E6%88%B7"><span class="toc-number">2.1.2.</span> <span class="toc-text">2.1.2 创建hxr用户</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-3-%E9%85%8D%E7%BD%AEssh%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95"><span class="toc-number">2.1.3.</span> <span class="toc-text">2.1.3 配置ssh免密登录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-4-%E5%AE%89%E8%A3%85jdk%EF%BC%8C%E8%AE%BE%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">2.1.4.</span> <span class="toc-text">2.1.4 安装jdk，设置环境变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-5-%E8%8A%82%E7%82%B9%E9%97%B4%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5"><span class="toc-number">2.1.5.</span> <span class="toc-text">2.1.5 节点间时间同步</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE"><span class="toc-number">2.1.5.1.</span> <span class="toc-text">时间服务器配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E8%8A%82%E7%82%B9%E9%85%8D%E7%BD%AE"><span class="toc-number">2.1.5.2.</span> <span class="toc-text">其他节点配置</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-%E6%A0%B8%E5%BF%83%E6%A1%86%E6%9E%B6"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 核心框架</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-1-Hadoop-2-7-2"><span class="toc-number">2.2.1.</span> <span class="toc-text">2.2.1 Hadoop 2.7.2</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%BA%94%E7%94%A8"><span class="toc-number">2.2.1.1.</span> <span class="toc-text">安装应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">2.2.1.2.</span> <span class="toc-text">定义环境变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">2.2.1.3.</span> <span class="toc-text">配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%8F%91Hadoop%E5%88%B0%E5%85%B6%E4%BB%96%E8%8A%82%E7%82%B9"><span class="toc-number">2.2.1.4.</span> <span class="toc-text">分发Hadoop到其他节点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4"><span class="toc-number">2.2.1.5.</span> <span class="toc-text">启动集群</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Web%E7%95%8C%E9%9D%A2"><span class="toc-number">2.2.1.6.</span> <span class="toc-text">Web界面</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#hadoop%E7%9A%84%E6%9C%80%E7%BB%88%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">2.2.1.7.</span> <span class="toc-text">hadoop的最终配置文件</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-2-Zookeeper-3-4-10"><span class="toc-number">2.2.2.</span> <span class="toc-text">2.2.2 Zookeeper 3.4.10</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%BA%94%E7%94%A8-1"><span class="toc-number">2.2.2.1.</span> <span class="toc-text">安装应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-1"><span class="toc-number">2.2.2.2.</span> <span class="toc-text">配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%8F%91Zookeeper%E5%88%B0%E5%85%B6%E4%BB%96%E8%8A%82%E7%82%B9"><span class="toc-number">2.2.2.3.</span> <span class="toc-text">分发Zookeeper到其他节点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4-1"><span class="toc-number">2.2.2.4.</span> <span class="toc-text">启动集群</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-3-Flume-1-7-0"><span class="toc-number">2.2.3.</span> <span class="toc-text">2.2.3 Flume 1.7.0</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%BA%94%E7%94%A8-2"><span class="toc-number">2.2.3.1.</span> <span class="toc-text">安装应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-2"><span class="toc-number">2.2.3.2.</span> <span class="toc-text">配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1%E6%96%87%E4%BB%B6"><span class="toc-number">2.2.3.3.</span> <span class="toc-text">任务文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%95%E7%82%B9%E5%90%AF%E5%8A%A8"><span class="toc-number">2.2.3.4.</span> <span class="toc-text">单点启动</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-4-Kafka-2-11"><span class="toc-number">2.2.4.</span> <span class="toc-text">2.2.4 Kafka 2.11</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%BA%94%E7%94%A8-3"><span class="toc-number">2.2.4.1.</span> <span class="toc-text">安装应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-3"><span class="toc-number">2.2.4.2.</span> <span class="toc-text">配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%8F%91Kafka%E5%88%B0%E5%85%B6%E4%BB%96%E8%8A%82%E7%82%B9"><span class="toc-number">2.2.4.3.</span> <span class="toc-text">分发Kafka到其他节点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%8B%E6%B5%8B"><span class="toc-number">2.2.4.4.</span> <span class="toc-text">压测</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4-2"><span class="toc-number">2.2.4.5.</span> <span class="toc-text">启动集群</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="toc-number">2.2.4.6.</span> <span class="toc-text">常用命令</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-5-Hive-2-3-6"><span class="toc-number">2.2.5.</span> <span class="toc-text">2.2.5 Hive 2.3.6</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%BA%94%E7%94%A8-4"><span class="toc-number">2.2.5.1.</span> <span class="toc-text">安装应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-4"><span class="toc-number">2.2.5.2.</span> <span class="toc-text">配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95"><span class="toc-number">2.2.5.3.</span> <span class="toc-text">测试</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-6-Sqoop-1-4-6"><span class="toc-number">2.2.6.</span> <span class="toc-text">2.2.6 Sqoop 1.4.6</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%BA%94%E7%94%A8-5"><span class="toc-number">2.2.6.1.</span> <span class="toc-text">安装应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-5"><span class="toc-number">2.2.6.2.</span> <span class="toc-text">配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95-1"><span class="toc-number">2.2.6.3.</span> <span class="toc-text">测试</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-7-%E9%85%8D%E7%BD%AELZO%E6%A0%BC%E5%BC%8F%E5%8E%8B%E7%BC%A9"><span class="toc-number">2.2.7.</span> <span class="toc-text">2.2.7 配置LZO格式压缩</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE"><span class="toc-number">2.2.7.1.</span> <span class="toc-text">配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8D%E5%90%AF%E9%9B%86%E7%BE%A4"><span class="toc-number">2.2.7.2.</span> <span class="toc-text">重启集群</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95-2"><span class="toc-number">2.2.7.3.</span> <span class="toc-text">测试</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-8-TEZ-0-9-1"><span class="toc-number">2.2.8.</span> <span class="toc-text">2.2.8 TEZ 0.9.1</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%BA%94%E7%94%A8-6"><span class="toc-number">2.2.8.1.</span> <span class="toc-text">安装应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-6"><span class="toc-number">2.2.8.2.</span> <span class="toc-text">配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95-3"><span class="toc-number">2.2.8.3.</span> <span class="toc-text">测试</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8C%96"><span class="toc-number">2.2.8.4.</span> <span class="toc-text">优化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-9-Azkaban-2-5-0"><span class="toc-number">2.2.9.</span> <span class="toc-text">2.2.9 Azkaban 2.5.0</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%AE%89%E8%A3%85"><span class="toc-number">2.2.9.1.</span> <span class="toc-text">应用安装</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">2.2.9.2.</span> <span class="toc-text">创建数据库</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E5%AF%86%E9%92%A5%E5%AF%B9%E5%92%8C%E8%AF%81%E4%B9%A6"><span class="toc-number">2.2.9.3.</span> <span class="toc-text">生成密钥对和证书</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-7"><span class="toc-number">2.2.9.4.</span> <span class="toc-text">配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%95%E7%82%B9%E5%90%AF%E5%8A%A8-1"><span class="toc-number">2.2.9.5.</span> <span class="toc-text">单点启动</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Web%E7%95%8C%E9%9D%A2-1"><span class="toc-number">2.2.9.6.</span> <span class="toc-text">Web界面</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-10-Flink-1-12-0"><span class="toc-number">2.2.10.</span> <span class="toc-text">2.2.10 Flink 1.12.0</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%BA%94%E7%94%A8-7"><span class="toc-number">2.2.10.1.</span> <span class="toc-text">安装应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%8F%91Flink%E5%88%B0%E5%85%B6%E4%BB%96%E8%8A%82%E7%82%B9"><span class="toc-number">2.2.10.2.</span> <span class="toc-text">分发Flink到其他节点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4-3"><span class="toc-number">2.2.10.3.</span> <span class="toc-text">启动集群</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Web%E7%95%8C%E9%9D%A2-2"><span class="toc-number">2.2.10.4.</span> <span class="toc-text">Web界面</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-11-HBase-1-3-1"><span class="toc-number">2.2.11.</span> <span class="toc-text">2.2.11 HBase 1.3.1</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%BA%94%E7%94%A8-8"><span class="toc-number">2.2.11.1.</span> <span class="toc-text">安装应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-8"><span class="toc-number">2.2.11.2.</span> <span class="toc-text">配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%8F%91HBase%E5%88%B0%E5%85%B6%E4%BB%96%E8%8A%82%E7%82%B9"><span class="toc-number">2.2.11.3.</span> <span class="toc-text">分发HBase到其他节点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4-4"><span class="toc-number">2.2.11.4.</span> <span class="toc-text">启动集群</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Web%E7%95%8C%E9%9D%A2-3"><span class="toc-number">2.2.11.5.</span> <span class="toc-text">Web界面</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-12-Clickhouse"><span class="toc-number">2.2.12.</span> <span class="toc-text">2.2.12 Clickhouse</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-%E8%BE%85%E5%8A%A9%E6%A1%86%E6%9E%B6"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 辅助框架</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-1-Ganglia"><span class="toc-number">2.3.1.</span> <span class="toc-text">2.3.1 Ganglia</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E5%BA%94%E7%94%A8"><span class="toc-number">2.3.1.1.</span> <span class="toc-text">启动应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-9"><span class="toc-number">2.3.1.2.</span> <span class="toc-text">配置文件</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-2-Solr-5-2-1"><span class="toc-number">2.3.2.</span> <span class="toc-text">2.3.2 Solr 5.2.1</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%BA%94%E7%94%A8-9"><span class="toc-number">2.3.2.1.</span> <span class="toc-text">安装应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-10"><span class="toc-number">2.3.2.2.</span> <span class="toc-text">配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%8F%91Solr%E5%88%B0%E5%85%B6%E4%BB%96%E8%8A%82%E7%82%B9"><span class="toc-number">2.3.2.3.</span> <span class="toc-text">分发Solr到其他节点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8"><span class="toc-number">2.3.2.4.</span> <span class="toc-text">集群启动</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Web%E7%95%8C%E9%9D%A2-4"><span class="toc-number">2.3.2.5.</span> <span class="toc-text">Web界面</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-3-Atlas-0-8-4"><span class="toc-number">2.3.3.</span> <span class="toc-text">2.3.3 Atlas 0.8.4</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%BA%94%E7%94%A8-10"><span class="toc-number">2.3.3.1.</span> <span class="toc-text">安装应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-11"><span class="toc-number">2.3.3.2.</span> <span class="toc-text">配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%95%E7%82%B9%E5%90%AF%E5%8A%A8-2"><span class="toc-number">2.3.3.3.</span> <span class="toc-text">单点启动</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Web%E7%95%8C%E9%9D%A2-5"><span class="toc-number">2.3.3.4.</span> <span class="toc-text">Ｗeb界面</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95-4"><span class="toc-number">2.3.3.5.</span> <span class="toc-text">测试</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-4-Zabbix-4-2-8"><span class="toc-number">2.3.4.</span> <span class="toc-text">2.3.4 Zabbix 4.2.8</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E5%BA%94%E7%94%A8-11"><span class="toc-number">2.3.4.1.</span> <span class="toc-text">安装应用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-UI%E7%95%8C%E9%9D%A2"><span class="toc-number">2.4.</span> <span class="toc-text">4.1 UI界面</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-%E5%90%AF%E5%8A%A8%E5%91%BD%E4%BB%A4"><span class="toc-number">2.5.</span> <span class="toc-text">4.2 启动命令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3-%E5%90%84jps%E8%BF%9B%E7%A8%8B%E5%90%8D%E5%AF%B9%E5%BA%94%E7%9A%84%E7%BB%84%E4%BB%B6"><span class="toc-number">2.6.</span> <span class="toc-text">4.3 各jps进程名对应的组件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4-%E5%B8%B8%E7%94%A8%E7%AB%AF%E5%8F%A3%E5%8F%B7"><span class="toc-number">2.7.</span> <span class="toc-text">4.4 常用端口号</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-5-shell%E8%84%9A%E6%9C%AC"><span class="toc-number">2.8.</span> <span class="toc-text">4.5 shell脚本</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-6-%E5%85%B6%E4%BB%96"><span class="toc-number">2.9.</span> <span class="toc-text">4.6 其他</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/MySQL/%E6%B3%A8%E8%A7%A3@Select%E5%92%8C@Insert/" title="注解@Select和@Insert">注解@Select和@Insert</a><time datetime="2023-05-06T05:48:28.906Z" title="发表于 2023-05-06 13:48:28">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E5%90%8E%E7%AB%AF%E6%A1%86%E6%9E%B6/%E6%B3%A8%E8%A7%A3@EnableAutoConfiguration/" title="注解@EnableAutoConfiguration">注解@EnableAutoConfiguration</a><time datetime="2023-05-06T05:48:06.027Z" title="发表于 2023-05-06 13:48:06">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A6%BB%E7%BA%BF/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7%E6%A1%86%E6%9E%B6/" title="大数据集群监控框架">大数据集群监控框架</a><time datetime="2023-05-06T05:42:56.298Z" title="发表于 2023-05-06 13:42:56">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E9%AB%98%E5%B9%B6%E5%8F%91/HashMap%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98%E5%8F%8AConcurrentHashMap%E5%8E%9F%E7%90%86/" title="HashMap并发问题及ConcurrentHashMap原理">HashMap并发问题及ConcurrentHashMap原理</a><time datetime="2023-05-06T05:31:21.103Z" title="发表于 2023-05-06 13:31:21">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E9%AB%98%E5%B9%B6%E5%8F%91/Stream%E5%8E%9F%E7%90%86/" title="Stream原理">Stream原理</a><time datetime="2023-05-06T05:31:21.103Z" title="发表于 2023-05-06 13:31:21">2023-05-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By CJ</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>