<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>PaddlePaddle | Hexo</title><meta name="author" content="CJ"><meta name="copyright" content="CJ"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="一、搭建Windows下的Conda安装-使用文档-PaddlePaddle深度学习平台 安装PaddleDection开发套件下载PaddleDection包，下载requirement中的模块 pip install -r . equirements.txt  如果cython_bbox安装失败，使用如下命令安装python -m pip install git+https:&#x2F;&#x2F;github.">
<meta property="og:type" content="article">
<meta property="og:title" content="PaddlePaddle">
<meta property="og:url" content="http://example.com/2023/05/06/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/PaddlePaddle/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="一、搭建Windows下的Conda安装-使用文档-PaddlePaddle深度学习平台 安装PaddleDection开发套件下载PaddleDection包，下载requirement中的模块 pip install -r . equirements.txt  如果cython_bbox安装失败，使用如下命令安装python -m pip install git+https:&#x2F;&#x2F;github.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2023-05-06T05:31:21.035Z">
<meta property="article:modified_time" content="2023-05-06T05:31:21.035Z">
<meta property="article:author" content="CJ">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2023/05/06/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/PaddlePaddle/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'PaddlePaddle',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-05-06 13:31:21'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">419</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">38</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Hexo"><span class="site-name">Hexo</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">PaddlePaddle</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-05-06T05:31:21.035Z" title="发表于 2023-05-06 13:31:21">2023-05-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-05-06T05:31:21.035Z" title="更新于 2023-05-06 13:31:21">2023-05-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="PaddlePaddle"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="一、搭建"><a href="#一、搭建" class="headerlink" title="一、搭建"></a>一、搭建</h1><p><a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/install/conda/windows-conda.html#anchor-0">Windows下的Conda安装-使用文档-PaddlePaddle深度学习平台</a></p>
<p><strong>安装PaddleDection开发套件</strong><br>下载PaddleDection包，下载requirement中的模块 <code>pip install -r . equirements.txt</code></p>
<blockquote>
<p>如果cython_bbox安装失败，使用如下命令安装<br><code>python -m pip install git+https://github.com/yanfengliu/cython_bbox.git</code></p>
</blockquote>
<h1 id="二、使用"><a href="#二、使用" class="headerlink" title="二、使用"></a>二、使用</h1><h2 id="2-1-官方demo-识别图片上的数字"><a href="#2-1-官方demo-识别图片上的数字" class="headerlink" title="2.1 官方demo(识别图片上的数字)"></a>2.1 官方demo(识别图片上的数字)</h2><p><a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/beginner/quick_start_cn.html">10分钟快速上手飞桨-使用文档-PaddlePaddle深度学习平台</a></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> paddle.vision.transforms <span class="keyword">import</span> Normalize</span><br><span class="line"></span><br><span class="line">transform = Normalize(mean=[<span class="number">127.5</span>], std=[<span class="number">127.5</span>], data_format=<span class="string">&#x27;CHW&#x27;</span>)</span><br><span class="line"><span class="comment"># 下载数据集并初始化 DataSet</span></span><br><span class="line">train_dataset = paddle.vision.datasets.MNIST(mode=<span class="string">&#x27;train&#x27;</span>, transform=transform)</span><br><span class="line">test_dataset = paddle.vision.datasets.MNIST(mode=<span class="string">&#x27;test&#x27;</span>, transform=transform)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型组网并初始化网络</span></span><br><span class="line">lenet = paddle.vision.models.LeNet(num_classes=<span class="number">10</span>)</span><br><span class="line">model = paddle.Model(lenet)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练的配置准备，准备损失函数，优化器和评价指标</span></span><br><span class="line">model.prepare(paddle.optimizer.Adam(parameters=model.parameters()),</span><br><span class="line">              paddle.nn.CrossEntropyLoss(),</span><br><span class="line">              paddle.metric.Accuracy())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">model.fit(train_dataset, epochs=<span class="number">5</span>, batch_size=<span class="number">64</span>, verbose=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line">model.evaluate(test_dataset, batch_size=<span class="number">64</span>, verbose=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">model.save(<span class="string">&#x27;./output/mnist&#x27;</span>)</span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">model.load(<span class="string">&#x27;output/mnist&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从测试集中取出一张图片</span></span><br><span class="line">img, label = test_dataset[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 将图片shape从1*28*28变为1*1*28*28，增加一个batch维度，以匹配模型输入格式要求</span></span><br><span class="line">img_batch = np.expand_dims(img.astype(<span class="string">&#x27;float32&#x27;</span>), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行推理并打印结果，此处predict_batch返回的是一个list，取出其中数据获得预测结果</span></span><br><span class="line">out = model.predict_batch(img_batch)[<span class="number">0</span>]</span><br><span class="line">pred_label = out.argmax()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;true label: &#123;&#125;, pred label: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(label[<span class="number">0</span>], pred_label))</span><br><span class="line"><span class="comment"># 可视化图片</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.imshow(img[<span class="number">0</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<br>
## 2.2 求解线性模型
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"># 现在面临这样一个任务：</span><br><span class="line"># 乘坐出租车，起步价为10元，每行驶1公里，需要在支付每公里2元</span><br><span class="line"># 当一个乘客坐完出租车后，车上的计价器需要算出来该乘客需要支付的乘车费用</span><br><span class="line"></span><br><span class="line">def calculate_fee(distance_travelled):</span><br><span class="line">    return 10 + 2 * distance_travelled</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for x in [1, 3, 5, 9, 10, 20]:</span><br><span class="line">    print(calculate_fee(x))</span><br><span class="line"></span><br><span class="line"># 结果为</span><br><span class="line"># 12</span><br><span class="line"># 16</span><br><span class="line"># 20</span><br><span class="line"># 28</span><br><span class="line"># 30</span><br><span class="line"># 50</span><br><span class="line"></span><br><span class="line"># 接下来，把问题稍微变换一下，现在知道乘客每次出行的公里数和支付的总费用</span><br><span class="line"># 需要求解乘车的起步价和每公里的费用</span><br><span class="line">import paddle</span><br><span class="line"></span><br><span class="line">x_data = paddle.to_tensor([[1.0], [3.0], [5.0], [9.0], [10.0], [20.0]])</span><br><span class="line">y_data = paddle.to_tensor([[12.0], [16.0], [20.0], [28.0], [30.0], [50.0]])</span><br><span class="line"></span><br><span class="line">linear = paddle.nn.Linear(in_features=1, out_features=1)</span><br><span class="line">w_before_opt = linear.weight.numpy().item()</span><br><span class="line">b_before_opt = linear.bias.numpy().item()</span><br><span class="line">print(w_before_opt, b_before_opt)  # 随机初始化的值</span><br><span class="line"></span><br><span class="line">mse_loss = paddle.nn.MSELoss()</span><br><span class="line">sgd_optimizer = paddle.optimizer.SGD(learning_rate=0.001, parameters=linear.parameters())</span><br><span class="line"></span><br><span class="line">total_epoch = 5000</span><br><span class="line">for i in range(total_epoch):</span><br><span class="line">    y_predict = linear(x_data)</span><br><span class="line">    loss = mse_loss(y_predict, y_data)</span><br><span class="line">    loss.backward()</span><br><span class="line">    sgd_optimizer.step()</span><br><span class="line">    sgd_optimizer.clear_gradients()</span><br><span class="line"></span><br><span class="line">    if i % 1000 == 0:</span><br><span class="line">        print(i, loss.numpy())</span><br><span class="line"></span><br><span class="line">print(&quot;finish training, loss = &#123;&#125;&quot;.format(loss.numpy()))</span><br><span class="line"></span><br><span class="line">w_after_opt = linear.weight.numpy().item()</span><br><span class="line">b_after_opt = linear.bias.numpy().item()</span><br><span class="line">print(w_after_opt, b_after_opt)  # 最终的拟合值</span><br></pre></td></tr></table></figure>

<br>
## 2.3 预测波士顿房价
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br></pre></td><td class="code"><pre><span class="line">import paddle</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 1. 准备数据</span><br><span class="line">def load_data():</span><br><span class="line">    ## 1.1 从文件导入数据</span><br><span class="line">    datafile = &#x27;../dataset/housing.data&#x27;</span><br><span class="line">    data = np.fromfile(datafile, sep=&#x27; &#x27;, dtype=np.float32)</span><br><span class="line">    print(len(data))</span><br><span class="line"></span><br><span class="line">    ## 1.2 数据转换</span><br><span class="line">    # 每条数据包括14项，其中前面13项是影响因素，第14项是相应的房屋价格中位数</span><br><span class="line">    feature_names = [&#x27;CRIM&#x27;, &#x27;ZN&#x27;, &#x27;INDUS&#x27;, &#x27;CHAS&#x27;, &#x27;NOX&#x27;, &#x27;RM&#x27;, &#x27;AGE&#x27;,</span><br><span class="line">                     &#x27;DIS&#x27;, &#x27;RAD&#x27;, &#x27;TAX&#x27;, &#x27;PTRATIO&#x27;, &#x27;B&#x27;, &#x27;LSTAT&#x27;, &#x27;MEDV&#x27;]</span><br><span class="line">    feature_num = len(feature_names)</span><br><span class="line"></span><br><span class="line">    # 将原始数据进行reshape，变成[N, 14]形状</span><br><span class="line">    data = data.reshape([data.shape[0] // feature_num, feature_num])</span><br><span class="line"></span><br><span class="line">    # 将原数据拆分成训练集和测试集</span><br><span class="line">    # 这里使用80%的数据做训练，20%的数据做测试</span><br><span class="line">    # 测试集和训练集必须是没有交集的</span><br><span class="line">    ratio = 0.8</span><br><span class="line">    offset = int(data.shape[0] * ratio)</span><br><span class="line"></span><br><span class="line">    training_data = data[:offset]</span><br><span class="line"></span><br><span class="line">    # 计算train数据集的最大值，最小值，平均值</span><br><span class="line">    maximums, minimums, avgs = training_data.max(axis=0), training_data.min(axis=0), training_data.sum(axis=0) / \</span><br><span class="line">                               training_data.shape[0]</span><br><span class="line"></span><br><span class="line">    # 记录数据的归一化参数，在预测时对数据做归一化</span><br><span class="line">    global max_values</span><br><span class="line">    global min_values</span><br><span class="line">    global avg_values</span><br><span class="line">    max_values = maximums</span><br><span class="line">    min_values = minimums</span><br><span class="line">    avg_values = avgs</span><br><span class="line"></span><br><span class="line">    # 对数据进行归一化处理</span><br><span class="line">    for i in range(feature_num):</span><br><span class="line">        data[:, i] = (data[:, i] - avgs[i]) / (maximums[i] - minimums[i])</span><br><span class="line"></span><br><span class="line">    ## 1.3 训练集和测试集的划分</span><br><span class="line">    training_data = data[:offset]</span><br><span class="line">    test_data = data[offset:]</span><br><span class="line">    return training_data, test_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 2. 模型组网</span><br><span class="line">class Regressor(paddle.nn.Layer):</span><br><span class="line">    # self代表类的实例自身</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Regressor, self).__init__()</span><br><span class="line">        self.linear = paddle.nn.Linear(in_features=13, out_features=1)</span><br><span class="line"></span><br><span class="line">    # 网络前向计算</span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        x = self.linear(inputs)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 声明定义好的线性回归模型</span><br><span class="line">model = Regressor()</span><br><span class="line"></span><br><span class="line"># 3. 数据训练</span><br><span class="line"># 开启模型训练模式</span><br><span class="line">model.train()</span><br><span class="line"># 加载数据</span><br><span class="line">training_data, test_data = load_data()</span><br><span class="line"></span><br><span class="line"># 定义优化算法,使用随机梯度下降SGD，学习率设置为0.01</span><br><span class="line">opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())</span><br><span class="line"></span><br><span class="line">EPOCH_NUM = 10  # 设置外层循环次数</span><br><span class="line">BATCH_SIZE = 10  # 设置batch大小</span><br><span class="line"></span><br><span class="line"># 定义外层循环</span><br><span class="line">for epoch_id in range(EPOCH_NUM):</span><br><span class="line">    # 在每轮迭代开始之前，将训练数据的顺序随机的打乱</span><br><span class="line">    np.random.shuffle(training_data)</span><br><span class="line">    # 将训练数据进行拆分，每个batch包含10条数据</span><br><span class="line">    mini_batches = [training_data[k:k + BATCH_SIZE] for k in range(0, len(training_data), BATCH_SIZE)]</span><br><span class="line">    # 定义内层循环</span><br><span class="line">    for iter_id, mini_batch in enumerate(mini_batches):</span><br><span class="line">        x = np.array(mini_batch[:, :-1])  # 获得当前批次训练数据</span><br><span class="line">        y = np.array(mini_batch[:, -1:])  # 获得当前批次训练标签（真实房价）</span><br><span class="line">        # 将numpy数据转为paddle tensor形式</span><br><span class="line">        house_features = paddle.to_tensor(x)</span><br><span class="line">        prices = paddle.to_tensor(y)</span><br><span class="line"></span><br><span class="line">        # 前向计算</span><br><span class="line">        predicts = model(house_features)</span><br><span class="line"></span><br><span class="line">        # 计算损失</span><br><span class="line">        loss = paddle.nn.functional.square_error_cost(input=predicts, label=prices)</span><br><span class="line">        mse = paddle.mean(loss)</span><br><span class="line">        if iter_id % 20 == 0:</span><br><span class="line">            print(&quot;epoch: &#123;&#125;, iter: &#123;&#125;, loss is: &#123;&#125;&quot;.format(epoch_id, iter_id, mse.numpy()))</span><br><span class="line"></span><br><span class="line">        # 反向传播</span><br><span class="line">        mse.backward()</span><br><span class="line">        # 最小化loss，更新参数</span><br><span class="line">        opt.step()</span><br><span class="line">        # 清除梯度</span><br><span class="line">        opt.clear_grad()</span><br><span class="line"></span><br><span class="line"># 4. 保存模型参数到字典中，将字典落盘为LR_model.pdparams文件</span><br><span class="line">paddle.save(model.state_dict(), &#x27;LR_model.pdparams&#x27;)</span><br><span class="line"></span><br><span class="line"># 读取模型，参数为保存模型参数的文件地址</span><br><span class="line">model_dict = paddle.load(&#x27;LR_model.pdparams&#x27;)</span><br><span class="line">model.load_dict(model_dict)</span><br><span class="line"></span><br><span class="line"># 将该模型及其所有子层设置为预测模式</span><br><span class="line">model.eval()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 5. 预测数据</span><br><span class="line">def load_one_example():</span><br><span class="line">    # 从上边已加载的测试集中，随机选择一条作为测试数据</span><br><span class="line">    idx = np.random.randint(0, test_data.shape[0])</span><br><span class="line">    idx = -10</span><br><span class="line">    one_data, label = test_data[idx, :-1], test_data[idx, -1]</span><br><span class="line">    # 修改该条数据shape为[1,13]</span><br><span class="line">    one_data = one_data.reshape([1, -1])</span><br><span class="line"></span><br><span class="line">    return one_data, label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 将数据转为动态图的variable格式</span><br><span class="line">one_data, label = load_one_example()</span><br><span class="line">one_data = paddle.to_tensor(one_data)</span><br><span class="line">predict = model(one_data)</span><br><span class="line"></span><br><span class="line"># 对结果做反归一化处理</span><br><span class="line">predict = predict * (max_values[-1] - min_values[-1]) + avg_values[-1]</span><br><span class="line"># 对label数据做反归一化处理</span><br><span class="line">label = label * (max_values[-1] - min_values[-1]) + avg_values[-1]</span><br><span class="line"></span><br><span class="line">print(&quot;Inference result is &#123;&#125;, the corresponding label is &#123;&#125;&quot;.format(predict.numpy(), label))</span><br><span class="line"></span><br><span class="line"># 打印结果为</span><br><span class="line">epoch: 0, iter: 0, loss is: [0.2190369]</span><br><span class="line">epoch: 0, iter: 20, loss is: [0.26175416]</span><br><span class="line">epoch: 0, iter: 40, loss is: [0.18272282]</span><br><span class="line">epoch: 1, iter: 0, loss is: [0.20169991]</span><br><span class="line">epoch: 1, iter: 20, loss is: [0.25468302]</span><br><span class="line">epoch: 1, iter: 40, loss is: [0.12643944]</span><br><span class="line">epoch: 2, iter: 0, loss is: [0.07170647]</span><br><span class="line">epoch: 2, iter: 20, loss is: [0.27606457]</span><br><span class="line">epoch: 2, iter: 40, loss is: [0.0587504]</span><br><span class="line">epoch: 3, iter: 0, loss is: [0.08177032]</span><br><span class="line">epoch: 3, iter: 20, loss is: [0.17796104]</span><br><span class="line">epoch: 3, iter: 40, loss is: [0.01438468]</span><br><span class="line">epoch: 4, iter: 0, loss is: [0.14358227]</span><br><span class="line">epoch: 4, iter: 20, loss is: [0.04590528]</span><br><span class="line">epoch: 4, iter: 40, loss is: [0.11086401]</span><br><span class="line">epoch: 5, iter: 0, loss is: [0.0784346]</span><br><span class="line">epoch: 5, iter: 20, loss is: [0.06981862]</span><br><span class="line">epoch: 5, iter: 40, loss is: [0.02968376]</span><br><span class="line">epoch: 6, iter: 0, loss is: [0.05453171]</span><br><span class="line">epoch: 6, iter: 20, loss is: [0.0677472]</span><br><span class="line">epoch: 6, iter: 40, loss is: [0.00175112]</span><br><span class="line">epoch: 7, iter: 0, loss is: [0.01291312]</span><br><span class="line">epoch: 7, iter: 20, loss is: [0.06383369]</span><br><span class="line">epoch: 7, iter: 40, loss is: [0.04227459]</span><br><span class="line">epoch: 8, iter: 0, loss is: [0.01342294]</span><br><span class="line">epoch: 8, iter: 20, loss is: [0.01199431]</span><br><span class="line">epoch: 8, iter: 40, loss is: [0.03285793]</span><br><span class="line">epoch: 9, iter: 0, loss is: [0.02604165]</span><br><span class="line">epoch: 9, iter: 20, loss is: [0.037579]</span><br><span class="line">epoch: 9, iter: 40, loss is: [0.01411492]</span><br><span class="line">Inference result is [[19.120472]], the corresponding label is 19.700000762939453</span><br></pre></td></tr></table></figure>

<br>
## 2.4 预测病理性近视
通过对训练集进行训练得到模型参数。这里使用训练集进行测试，所以准确率仅供参考。
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br></pre></td><td class="code"><pre><span class="line">import paddle</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">import os</span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 对读入的图像数据进行预处理</span><br><span class="line">def transform_img(img):</span><br><span class="line">    # 将图片尺寸缩放到 224x224</span><br><span class="line">    img = cv2.resize(img, (224, 224))</span><br><span class="line">    # 读入的图像数据格式是[H, W, C]</span><br><span class="line">    # 使用转置操作将其变成[C, H ,W]</span><br><span class="line">    img = np.transpose(img, (2, 0, 1))</span><br><span class="line">    img = img.astype(&#x27;float32&#x27;)</span><br><span class="line">    # 将数据范围调整到[-1.0, 1.0]之间</span><br><span class="line">    img = img / 255.</span><br><span class="line">    img = img * 2.0 - 1.0</span><br><span class="line">    return img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义训练集数据读取器</span><br><span class="line">def data_loader(datadir, batch_size=10, mode=&#x27;train&#x27;):</span><br><span class="line">    # 将datadir目录下的文件列出来，每条文件都要读入</span><br><span class="line">    filenames = os.listdir(datadir)</span><br><span class="line"></span><br><span class="line">    def reader():</span><br><span class="line">        if mode == &#x27;train&#x27;:</span><br><span class="line">            # 训练时随机打乱数据顺序</span><br><span class="line">            random.shuffle(filenames)</span><br><span class="line">        batch_imgs = []</span><br><span class="line">        batch_labels = []</span><br><span class="line"></span><br><span class="line">        for name in filenames:</span><br><span class="line">            img_path = os.path.join(datadir, name)</span><br><span class="line">            img = cv2.imread(img_path)</span><br><span class="line">            img = transform_img(img)</span><br><span class="line">            if name[0] == &#x27;H&#x27; or name[0] == &#x27;N&#x27;:</span><br><span class="line">                # H开头的文件名表示高度近视，N开头的文件名表示正常视力</span><br><span class="line">                # 高度近视和正常视力的样本，都不是病理性的，属于负样本，标签为0</span><br><span class="line">                label = 0</span><br><span class="line">            elif name[0] == &#x27;P&#x27;:</span><br><span class="line">                label = 1</span><br><span class="line">            else:</span><br><span class="line">                raise (&#x27;NOT EXCEPTED FILE NAME&#x27;)</span><br><span class="line">            # 每读取一个样本的数据，就将其放入数据列表中</span><br><span class="line">            batch_imgs.append(img)</span><br><span class="line">            batch_labels.append(label)</span><br><span class="line">            if len(batch_imgs) == batch_size:</span><br><span class="line">                # 当数据列表的长度等于batch_size的时候，</span><br><span class="line">                # 把这些数据当作一个mini-batch，并作为数据生成器的一个输出</span><br><span class="line">                imgs_array = np.array(batch_imgs).astype(&#x27;float32&#x27;)</span><br><span class="line">                labels_array = np.array(batch_labels).astype(&#x27;float32&#x27;).reshape(-1, 1)</span><br><span class="line">                yield imgs_array, labels_array</span><br><span class="line">                batch_imgs = []</span><br><span class="line">                batch_labels = []</span><br><span class="line"></span><br><span class="line">        if len(batch_imgs) &gt; 0:</span><br><span class="line">            # 剩余样本数不足一个batch_size的数据，一起打包成一个mini-batch</span><br><span class="line">            imgs_array = np.array(batch_imgs).astype(&#x27;float32&#x27;)</span><br><span class="line">            labels_array = np.array(batch_labels).astype(&#x27;float32&#x27;).reshape(-1, 1)</span><br><span class="line">            yield imgs_array, labels_array</span><br><span class="line"></span><br><span class="line">    return reader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义训练过程</span><br><span class="line">def train_pm(model, optimizer):</span><br><span class="line">    use_gpu = True</span><br><span class="line">    paddle.device.set_device(&#x27;gpu:0&#x27;) if use_gpu else paddle.device.set_device(&#x27;cpu&#x27;)</span><br><span class="line"></span><br><span class="line">    print(&#x27;start training ... &#x27;)</span><br><span class="line">    # 定义数据读取器，训练数据读取器和验证数据读取器</span><br><span class="line">    train_loader = data_loader(DATADIR, batch_size=10, mode=&#x27;train&#x27;)</span><br><span class="line">    for epoch in range(EPOCH_NUM):</span><br><span class="line">        model.train()</span><br><span class="line">        for batch_id, data in enumerate(train_loader()):</span><br><span class="line">            x_data, y_data = data</span><br><span class="line">            imgs = paddle.to_tensor(x_data)</span><br><span class="line">            labels = paddle.to_tensor(y_data)</span><br><span class="line">            # 运行模型前向计算，得到预测值</span><br><span class="line">            predicts = model(imgs)</span><br><span class="line">            loss = paddle.nn.functional.binary_cross_entropy_with_logits(predicts, labels)</span><br><span class="line">            avg_loss = paddle.mean(loss)</span><br><span class="line"></span><br><span class="line">            if batch_id % 20 == 0:</span><br><span class="line">                print(&#x27;epoch: &#123;&#125;, batch_id: &#123;&#125;, loss is: &#123;:.4f&#125;&#x27;.format(epoch, batch_id, float(avg_loss.numpy())))</span><br><span class="line">            avg_loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            optimizer.clear_grad()</span><br><span class="line"></span><br><span class="line">        # 计算准确率</span><br><span class="line">        model.eval()</span><br><span class="line">        accuracies = []</span><br><span class="line">        losses = []</span><br><span class="line">        eval_loader = data_loader(DATADIR, batch_size=10, mode=&#x27;eval&#x27;)</span><br><span class="line">        for batch_id, data in enumerate(eval_loader()):</span><br><span class="line">            x_data, y_data = data</span><br><span class="line">            imgs = paddle.to_tensor(x_data)</span><br><span class="line">            labels = paddle.to_tensor(y_data)</span><br><span class="line">            # 进行模型前向计算，得到预测值</span><br><span class="line">            logits = model(imgs)</span><br><span class="line">            # 计算sigmoid后的预测概率，进行loss计算</span><br><span class="line">            loss = paddle.nn.functional.binary_cross_entropy_with_logits(logits, labels)</span><br><span class="line">            # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别</span><br><span class="line">            predicts2 = paddle.nn.functional.sigmoid(logits)</span><br><span class="line">            predicts3 = predicts2 * (-1.0) + 1.0</span><br><span class="line">            pred = paddle.concat([predicts2, predicts3], axis=1)</span><br><span class="line">            acc = paddle.metric.accuracy(pred, paddle.cast(labels, dtype=&#x27;int64&#x27;))</span><br><span class="line"></span><br><span class="line">            accuracies.append(acc.numpy())</span><br><span class="line">            losses.append(loss.numpy())</span><br><span class="line">        print(&#x27;[validation] accuracy/loss: &#123;:.4f&#125;/&#123;:.4f&#125;&#x27;.format(np.mean(accuracies), np.mean(losses)))</span><br><span class="line"></span><br><span class="line">        paddle.save(model.state_dict(), &#x27;../output/pathologic_myopia/lenet/palm.pdparams&#x27;)</span><br><span class="line">        paddle.save(optimizer.state_dict(), &#x27;../output/pathologic_myopia/lenet/palm.pdopt&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义评估过程</span><br><span class="line">def evaluation(model, params_file_path):</span><br><span class="line">    # 开启0号GPU预估</span><br><span class="line">    use_gpu = True</span><br><span class="line">    paddle.device.set_device(&#x27;gpu:0&#x27;) if use_gpu else paddle.device.set_device(&#x27;cpu&#x27;)</span><br><span class="line"></span><br><span class="line">    print(&#x27;start evaluation ......&#x27;)</span><br><span class="line"></span><br><span class="line">    # 加载参数模型</span><br><span class="line">    model_state_dict = paddle.load(params_file_path)</span><br><span class="line">    model.load_dict(model_state_dict)</span><br><span class="line"></span><br><span class="line">    # 开启评估</span><br><span class="line">    model.eval()</span><br><span class="line">    eval_loader = data_loader(DATADIR, batch_size=10, mode=&#x27;eval&#x27;)</span><br><span class="line"></span><br><span class="line">    acc_set = []</span><br><span class="line">    avg_loss_set = []</span><br><span class="line">    for batch_id, data in enumerate(eval_loader()):</span><br><span class="line">        x_data, y_data = data</span><br><span class="line">        img = paddle.to_tensor(x_data)</span><br><span class="line">        label = paddle.to_tensor(y_data)</span><br><span class="line">        label_64 = paddle.to_tensor(y_data.astype(np.int64))</span><br><span class="line">        # 计算预测和精度(label_64作用???)</span><br><span class="line">        prediction, acc = model(img, label_64)</span><br><span class="line">        # 计算损失函数值</span><br><span class="line">        loss = paddle.nn.functional.binary_cross_entropy_with_logits(prediction, label)</span><br><span class="line">        avg_loss = paddle.mean(loss)</span><br><span class="line">        acc_set.append(float(acc.numpy()))</span><br><span class="line">        avg_loss_set.append(float(avg_loss.numpy()))</span><br><span class="line"></span><br><span class="line">    # 求平均精度</span><br><span class="line">    acc_val_mean = np.array(acc_set).mean()</span><br><span class="line">    avg_loss_val_mean = np.array(avg_loss_set).mean()</span><br><span class="line"></span><br><span class="line">    print(&#x27;loss=&#123;:.4f&#125;, acc=&#123;:.4f&#125;&#x27;.format(avg_loss_val_mean, acc_val_mean))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义模型</span><br><span class="line">class MyLeNet(paddle.nn.Layer):</span><br><span class="line">    def __init__(self, num_classes=1):</span><br><span class="line">        super(MyLeNet, self).__init__()</span><br><span class="line"></span><br><span class="line">        # 创建卷积和池化层块，每个卷积层使用Sigmoid激活函数，后面跟着一个2x2池化层</span><br><span class="line">        self.conv1 = paddle.nn.Conv2D(in_channels=3, out_channels=6, kernel_size=5)</span><br><span class="line">        self.max_pool1 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)</span><br><span class="line">        self.conv2 = paddle.nn.Conv2D(in_channels=6, out_channels=16, kernel_size=5)</span><br><span class="line">        self.max_pool2 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)</span><br><span class="line">        # 创建第三个卷积层</span><br><span class="line">        self.conv3 = paddle.nn.Conv2D(in_channels=16, out_channels=120, kernel_size=4)</span><br><span class="line">        # 创建全连接层，第一个全连接层的输出神经元个数为64</span><br><span class="line">        features_num = pow(((224 - 4) // 2 - 4) // 2 - 3, 2) * 120</span><br><span class="line">        self.fc1 = paddle.nn.Linear(in_features=features_num, out_features=64)</span><br><span class="line">        self.fc2 = paddle.nn.Linear(in_features=64, out_features=num_classes)</span><br><span class="line"></span><br><span class="line">    # 网络前向计算过程</span><br><span class="line">    def forward(self, x, label=None):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = paddle.nn.functional.sigmoid(x)</span><br><span class="line">        x = self.max_pool1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = paddle.nn.functional.sigmoid(x)</span><br><span class="line">        x = self.max_pool2(x)</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        x = paddle.nn.functional.sigmoid(x)</span><br><span class="line">        x = paddle.reshape(x, [x.shape[0], -1])</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = paddle.nn.functional.sigmoid(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        # 如果输入了Label，那么计算acc</span><br><span class="line">        if label is not None:</span><br><span class="line">            acc = paddle.metric.accuracy(input=x, label=label)</span><br><span class="line">            return x, acc</span><br><span class="line">        else:</span><br><span class="line">            return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 查看数据形状</span><br><span class="line">DATADIR = &#x27;../dataset/pathologic_myopia&#x27;</span><br><span class="line"># 设置迭代轮数</span><br><span class="line">EPOCH_NUM = 5</span><br><span class="line"># 创建模型</span><br><span class="line">model = MyLeNet(num_classes=1)</span><br><span class="line"># 启动训练过程</span><br><span class="line">opt = paddle.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameters=model.parameters())</span><br><span class="line">train_pm(model=model, optimizer=opt)</span><br><span class="line">evaluation(model, params_file_path=&#x27;../output/pathologic_myopia/lenet/palm.pdparams&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 打印结果</span><br><span class="line">W1206 14:31:11.494339 42040 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.7, Runtime API Version: 11.6</span><br><span class="line">W1206 14:31:11.496333 42040 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.</span><br><span class="line">start training ... </span><br><span class="line">epoch: 0, batch_id: 0, loss is: 0.7955</span><br><span class="line">epoch: 0, batch_id: 20, loss is: 0.6390</span><br><span class="line">[validation] accuracy/loss: 0.5325/0.6913</span><br><span class="line">epoch: 1, batch_id: 0, loss is: 0.6940</span><br><span class="line">epoch: 1, batch_id: 20, loss is: 0.6598</span><br><span class="line">[validation] accuracy/loss: 0.5325/0.6912</span><br><span class="line">epoch: 2, batch_id: 0, loss is: 0.6852</span><br><span class="line">epoch: 2, batch_id: 20, loss is: 0.6860</span><br><span class="line">[validation] accuracy/loss: 0.5325/0.6915</span><br><span class="line">epoch: 3, batch_id: 0, loss is: 0.6784</span><br><span class="line">epoch: 3, batch_id: 20, loss is: 0.6789</span><br><span class="line">[validation] accuracy/loss: 0.5325/0.6911</span><br><span class="line">epoch: 4, batch_id: 0, loss is: 0.6837</span><br><span class="line">epoch: 4, batch_id: 20, loss is: 0.6994</span><br><span class="line">[validation] accuracy/loss: 0.5325/0.6911</span><br><span class="line">start evaluation ......</span><br><span class="line">loss=0.6911, acc=0.4675</span><br></pre></td></tr></table></figure>
可见改模型的准确率并不高

<p>以下分别对 <strong>AlexNet&#x2F;GoogLeNet&#x2F;残差块</strong> 网络进行测试</p>
<p>使用 AlexNet 网络进行测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"># 优化模型</span><br><span class="line">class MyAlexNet(paddle.nn.Layer):</span><br><span class="line">    def __init__(self, num_classes=1):</span><br><span class="line">        super(MyAlexNet, self).__init__()</span><br><span class="line">        self.conv1 = paddle.nn.Conv2D(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=5)</span><br><span class="line">        self.max_pool1 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)</span><br><span class="line">        self.conv2 = paddle.nn.Conv2D(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2)</span><br><span class="line">        self.max_pool2 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)</span><br><span class="line">        self.conv3 = paddle.nn.Conv2D(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1)</span><br><span class="line">        self.conv4 = paddle.nn.Conv2D(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)</span><br><span class="line">        self.conv5 = paddle.nn.Conv2D(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)</span><br><span class="line">        self.max_pool5 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)</span><br><span class="line"></span><br><span class="line">        self.fc1 = paddle.nn.Linear(in_features=12544, out_features=4096)</span><br><span class="line">        self.drop_ratio1 = 0.5</span><br><span class="line">        self.drop1 = paddle.nn.Dropout(self.drop_ratio1)</span><br><span class="line">        self.fc2 = paddle.nn.Linear(in_features=4096, out_features=4096)</span><br><span class="line">        self.drop_ratio2 = 0.5</span><br><span class="line">        self.drop2 = paddle.nn.Dropout(self.drop_ratio2)</span><br><span class="line">        self.fc3 = paddle.nn.Linear(in_features=4096, out_features=num_classes)</span><br><span class="line"></span><br><span class="line">    def forward(self, x, label=None):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = paddle.nn.functional.relu(x)</span><br><span class="line">        x = self.max_pool1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = paddle.nn.functional.relu(x)</span><br><span class="line">        x = self.max_pool2(x)</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        x = paddle.nn.functional.relu(x)</span><br><span class="line">        x = self.conv4(x)</span><br><span class="line">        x = paddle.nn.functional.relu(x)</span><br><span class="line">        x = self.conv5(x)</span><br><span class="line">        x = paddle.nn.functional.relu(x)</span><br><span class="line">        x = self.max_pool5(x)</span><br><span class="line">        # 全连接层</span><br><span class="line">        x = paddle.reshape(x, [x.shape[0], -1])</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = paddle.nn.functional.relu(x)</span><br><span class="line">        # 在全连接之后使用dropout抑制过拟合</span><br><span class="line">        x = self.drop1(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = paddle.nn.functional.relu(x)</span><br><span class="line">        x = self.drop2(x)</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line"></span><br><span class="line">        # 如果输入了Label，那么计算acc</span><br><span class="line">        if label is not None:</span><br><span class="line">            acc = paddle.metric.accuracy(input=x, label=label)</span><br><span class="line">            return x, acc</span><br><span class="line">        else:</span><br><span class="line">            return x</span><br><span class="line"></span><br><span class="line"># 打印结果</span><br><span class="line">W1206 17:07:48.886270 34060 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.7, Runtime API Version: 11.6</span><br><span class="line">W1206 17:07:48.889235 34060 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.</span><br><span class="line">start training ... </span><br><span class="line">epoch: 0, batch_id: 0, loss is: 0.7389</span><br><span class="line">epoch: 0, batch_id: 20, loss is: 0.4360</span><br><span class="line">[validation] accuracy/loss: 0.8875/0.3465</span><br><span class="line">epoch: 1, batch_id: 0, loss is: 0.4918</span><br><span class="line">epoch: 1, batch_id: 20, loss is: 0.1599</span><br><span class="line">[validation] accuracy/loss: 0.9100/0.2533</span><br><span class="line">epoch: 2, batch_id: 0, loss is: 0.1056</span><br><span class="line">epoch: 2, batch_id: 20, loss is: 0.0493</span><br><span class="line">[validation] accuracy/loss: 0.8950/0.2766</span><br><span class="line">epoch: 3, batch_id: 0, loss is: 0.1250</span><br><span class="line">epoch: 3, batch_id: 20, loss is: 0.0829</span><br><span class="line">[validation] accuracy/loss: 0.9300/0.1978</span><br><span class="line">epoch: 4, batch_id: 0, loss is: 0.1520</span><br><span class="line">epoch: 4, batch_id: 20, loss is: 0.3377</span><br><span class="line">[validation] accuracy/loss: 0.9300/0.1779</span><br><span class="line">start evaluation ......</span><br><span class="line">loss=0.1779, acc=0.4675</span><br></pre></td></tr></table></figure>

<p>使用 vgg模型 进行测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"># 优化模型</span><br><span class="line">class VGG(paddle.nn.Layer):</span><br><span class="line">    def __init__(self, num_classes=None):</span><br><span class="line">        super(VGG, self).__init__()</span><br><span class="line"></span><br><span class="line">        in_channels = [3, 64, 128, 256, 512, 512]</span><br><span class="line">        # 定义第一个block，包含两个卷积</span><br><span class="line">        self.conv1_1 = paddle.nn.Conv2D(in_channels=in_channels[0], out_channels=in_channels[1], kernel_size=3,</span><br><span class="line">                                        padding=1, stride=1)</span><br><span class="line">        self.conv1_2 = paddle.nn.Conv2D(in_channels=in_channels[1], out_channels=in_channels[1], kernel_size=3,</span><br><span class="line">                                        padding=1, stride=1)</span><br><span class="line">        # 定义第二个block，包含两个卷积</span><br><span class="line">        self.conv2_1 = paddle.nn.Conv2D(in_channels=in_channels[1], out_channels=in_channels[2], kernel_size=3,</span><br><span class="line">                                        padding=1, stride=1)</span><br><span class="line">        self.conv2_2 = paddle.nn.Conv2D(in_channels=in_channels[2], out_channels=in_channels[2], kernel_size=3,</span><br><span class="line">                                        padding=1, stride=1)</span><br><span class="line">        # 定义第三个block，包含三个卷积</span><br><span class="line">        self.conv3_1 = paddle.nn.Conv2D(in_channels=in_channels[2], out_channels=in_channels[3], kernel_size=3,</span><br><span class="line">                                        padding=1, stride=1)</span><br><span class="line">        self.conv3_2 = paddle.nn.Conv2D(in_channels=in_channels[3], out_channels=in_channels[3], kernel_size=3,</span><br><span class="line">                                        padding=1, stride=1)</span><br><span class="line">        self.conv3_3 = paddle.nn.Conv2D(in_channels=in_channels[3], out_channels=in_channels[3], kernel_size=3,</span><br><span class="line">                                        padding=1, stride=1)</span><br><span class="line">        # 定义第四个block，包含三个卷积</span><br><span class="line">        self.conv4_1 = paddle.nn.Conv2D(in_channels=in_channels[3], out_channels=in_channels[4], kernel_size=3,</span><br><span class="line">                                        padding=1, stride=1)</span><br><span class="line">        self.conv4_2 = paddle.nn.Conv2D(in_channels=in_channels[4], out_channels=in_channels[4], kernel_size=3,</span><br><span class="line">                                        padding=1, stride=1)</span><br><span class="line">        self.conv4_3 = paddle.nn.Conv2D(in_channels=in_channels[4], out_channels=in_channels[4], kernel_size=3,</span><br><span class="line">                                        padding=1, stride=1)</span><br><span class="line">        # 定义第五个block，包含三个卷积</span><br><span class="line">        self.conv5_1 = paddle.nn.Conv2D(in_channels=in_channels[4], out_channels=in_channels[5], kernel_size=3,</span><br><span class="line">                                        padding=1, stride=1)</span><br><span class="line">        self.conv5_2 = paddle.nn.Conv2D(in_channels=in_channels[5], out_channels=in_channels[5], kernel_size=3,</span><br><span class="line">                                        padding=1, stride=1)</span><br><span class="line">        self.conv5_3 = paddle.nn.Conv2D(in_channels=in_channels[5], out_channels=in_channels[5], kernel_size=3,</span><br><span class="line">                                        padding=1, stride=1)</span><br><span class="line"></span><br><span class="line">        # 使用Sequential 将全连接层和relu组成一个线性结构 (fc + relu)</span><br><span class="line">        # 当输入为244x244时，经过五个卷积块和池化层后，特征维度变为[512x7x7]</span><br><span class="line">        self.fc1 = paddle.nn.Sequential(paddle.nn.Linear(512 * 7 * 7, 4096), paddle.nn.ReLU())</span><br><span class="line">        self.drop1_ratio = 0.5</span><br><span class="line">        self.dropout1 = paddle.nn.Dropout(self.drop1_ratio, mode=&#x27;upscale_in_train&#x27;)</span><br><span class="line">        # 使用Sequential将全连接层和relu组成一个线性结构(fc + relu)</span><br><span class="line">        self.fc2 = paddle.nn.Sequential(paddle.nn.Linear(4096, 4096), paddle.nn.ReLU())</span><br><span class="line">        self.drop2_ratio = 0.5</span><br><span class="line">        self.dropout2 = paddle.nn.Dropout(self.drop2_ratio, mode=&#x27;upscale_in_train&#x27;)</span><br><span class="line">        self.fc3 = paddle.nn.Linear(4096, 1)</span><br><span class="line"></span><br><span class="line">        self.relu = paddle.nn.ReLU()</span><br><span class="line">        self.pool = paddle.nn.MaxPool2D(stride=2, kernel_size=2)</span><br><span class="line"></span><br><span class="line">    def forward(self, x, label=None):</span><br><span class="line">        x = self.relu(self.conv1_1(x))</span><br><span class="line">        x = self.relu(self.conv1_2(x))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line"></span><br><span class="line">        x = self.relu(self.conv2_1(x))</span><br><span class="line">        x = self.relu(self.conv2_2(x))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line"></span><br><span class="line">        x = self.relu(self.conv3_1(x))</span><br><span class="line">        x = self.relu(self.conv3_2(x))</span><br><span class="line">        x = self.relu(self.conv3_3(x))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line"></span><br><span class="line">        x = self.relu(self.conv4_1(x))</span><br><span class="line">        x = self.relu(self.conv4_2(x))</span><br><span class="line">        x = self.relu(self.conv4_3(x))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line"></span><br><span class="line">        x = self.relu(self.conv5_1(x))</span><br><span class="line">        x = self.relu(self.conv5_2(x))</span><br><span class="line">        x = self.relu(self.conv5_3(x))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line"></span><br><span class="line">        x = paddle.flatten(x, 1, -1)</span><br><span class="line">        x = self.dropout1(self.relu(self.fc1(x)))</span><br><span class="line">        x = self.dropout2(self.relu(self.fc2(x)))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line"></span><br><span class="line">        # 如果输入了Label，那么计算acc</span><br><span class="line">        if label is not None:</span><br><span class="line">            acc = paddle.metric.accuracy(input=x, label=label)</span><br><span class="line">            return x, acc</span><br><span class="line">        else:</span><br><span class="line">            return x</span><br><span class="line"></span><br><span class="line"># 打印结果为</span><br><span class="line">W1206 17:31:48.611086 37108 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.7, Runtime API Version: 11.6</span><br><span class="line">W1206 17:31:48.650003 37108 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.</span><br><span class="line">start training ... </span><br><span class="line">epoch: 0, batch_id: 0, loss is: 0.8150</span><br><span class="line">epoch: 0, batch_id: 20, loss is: 0.8149</span><br><span class="line">[validation] accuracy/loss: 0.8775/0.3243</span><br><span class="line">epoch: 1, batch_id: 0, loss is: 0.1642</span><br><span class="line">epoch: 1, batch_id: 20, loss is: 0.2195</span><br><span class="line">[validation] accuracy/loss: 0.9000/0.2934</span><br><span class="line">epoch: 2, batch_id: 0, loss is: 0.2956</span><br><span class="line">epoch: 2, batch_id: 20, loss is: 0.8894</span><br><span class="line">[validation] accuracy/loss: 0.8975/0.2357</span><br><span class="line">epoch: 3, batch_id: 0, loss is: 0.3631</span><br><span class="line">epoch: 3, batch_id: 20, loss is: 0.1797</span><br><span class="line">[validation] accuracy/loss: 0.9125/0.2169</span><br><span class="line">epoch: 4, batch_id: 0, loss is: 0.5968</span><br><span class="line">epoch: 4, batch_id: 20, loss is: 0.0280</span><br><span class="line">[validation] accuracy/loss: 0.9200/0.1935</span><br><span class="line">start evaluation ......</span><br><span class="line">loss=0.1935, acc=0.4675</span><br></pre></td></tr></table></figure>

<p>使用 GoogLeNet模型 测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"># 优化模型</span><br><span class="line"># 定义Inception块</span><br><span class="line">class Inception(paddle.nn.Layer):</span><br><span class="line">    def __init__(self, c0, c1, c2, c3, c4, **kwargs):</span><br><span class="line">        &#x27;&#x27;&#x27;</span><br><span class="line">        Inception模块的实现代码</span><br><span class="line">        :param c0:</span><br><span class="line">        :param c1:图(b)中第一条支路1x1卷积的输出通道数,数据类型是整数</span><br><span class="line">        :param c2:图(b)中第二条支路卷积的输出通道数,数据类型是tuple或list,其中c2[0]是1x1卷积的输出通道数,c2[1]是3x3</span><br><span class="line">        :param c3:图(b)中第三条支路卷积的输出通道数,数据类型是tuple或list,其中c3[0]是1x1卷积的输出通道数,c3[1]是3x3</span><br><span class="line">        :param c4:图(b)中第一条支路1x1卷积的输出通道数,数据类型是整数</span><br><span class="line">        :param kwargs:</span><br><span class="line">        &#x27;&#x27;&#x27;</span><br><span class="line">        super(Inception, self).__init__()</span><br><span class="line">        # 依次创建Inception块每条支路上使用到的操作</span><br><span class="line">        self.p1_1 = paddle.nn.Conv2D(in_channels=c0, out_channels=c1, kernel_size=1, stride=1)</span><br><span class="line"></span><br><span class="line">        self.p2_1 = paddle.nn.Conv2D(in_channels=c0, out_channels=c2[0], kernel_size=1, stride=1)</span><br><span class="line">        self.p2_2 = paddle.nn.Conv2D(in_channels=c2[0], out_channels=c2[1], kernel_size=3, padding=1, stride=1)</span><br><span class="line"></span><br><span class="line">        self.p3_1 = paddle.nn.Conv2D(in_channels=c0, out_channels=c3[0], kernel_size=1, stride=1)</span><br><span class="line">        self.p3_2 = paddle.nn.Conv2D(in_channels=c3[0], out_channels=c3[1], kernel_size=5, padding=2, stride=1)</span><br><span class="line"></span><br><span class="line">        self.p4_1 = paddle.nn.MaxPool2D(kernel_size=3, stride=1, padding=1)</span><br><span class="line">        self.p4_2 = paddle.nn.Conv2D(in_channels=c0, out_channels=c4, kernel_size=1, stride=1)</span><br><span class="line"></span><br><span class="line">        # # 新加一层batchnorm稳定收敛</span><br><span class="line">        # self.batchnorm = paddle.nn.BatchNorm2D(c1+c2[1]+c3[1]+c4)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        # 支路1只包含一个 1x1卷积</span><br><span class="line">        p1 = paddle.nn.functional.relu(self.p1_1(x))</span><br><span class="line">        # 支路2包含 1x1卷积 + 3x3卷积</span><br><span class="line">        p2 = paddle.nn.functional.relu(self.p2_2(paddle.nn.functional.relu(self.p2_1(x))))</span><br><span class="line">        # 支路3包含 1x1卷积 + 5x5卷积</span><br><span class="line">        p3 = paddle.nn.functional.relu(self.p3_2(paddle.nn.functional.relu(self.p3_1(x))))</span><br><span class="line">        # 支路4包含 最大池化 + 1x1卷积</span><br><span class="line">        p4 = paddle.nn.functional.relu(self.p4_2(paddle.nn.functional.relu(self.p4_1(x))))</span><br><span class="line">        # 将每个支路的输出特征图拼接在一起作为最终的输出结果</span><br><span class="line">        return paddle.concat([p1, p2, p3, p4], axis=1)</span><br><span class="line">        # return self.batchnorm()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class GoogleNet(paddle.nn.Layer):</span><br><span class="line">    def __init__(self, num_classes=None):</span><br><span class="line">        super(GoogleNet, self).__init__()</span><br><span class="line">        # GoogleLeNet包含5个模块，每个模块后面紧跟一个池化层</span><br><span class="line">        # 第一个模块包含1个卷积层</span><br><span class="line">        self.conv1 = paddle.nn.Conv2D(in_channels=3, out_channels=64, kernel_size=7, padding=3, stride=1)</span><br><span class="line">        # 3x3最大池化</span><br><span class="line">        self.max_pool1 = paddle.nn.MaxPool2D(kernel_size=3, stride=2, padding=1)</span><br><span class="line">        # 第二个模块包含2个卷积层</span><br><span class="line">        self.conv2_1 = paddle.nn.Conv2D(in_channels=64, out_channels=64, kernel_size=1, stride=1)</span><br><span class="line">        self.conv2_2 = paddle.nn.Conv2D(in_channels=64, out_channels=192, kernel_size=3, padding=1, stride=1)</span><br><span class="line">        # 3x3最大池化</span><br><span class="line">        self.max_pool2 = paddle.nn.MaxPool2D(kernel_size=3, stride=2, padding=1)</span><br><span class="line">        # 第三个模块包含2个Inception块</span><br><span class="line">        self.block3_1 = Inception(192, 64, (96, 128), (16, 32), 32)</span><br><span class="line">        self.block3_2 = Inception(256, 128, (128, 192), (32, 96), 64)</span><br><span class="line">        # 3x3最大池化</span><br><span class="line">        self.max_pool3 = paddle.nn.MaxPool2D(kernel_size=3, stride=2, padding=1)</span><br><span class="line">        # 第四个模块包含5个Inception块</span><br><span class="line">        self.block4_1 = Inception(480, 192, (96, 208), (16, 48), 64)</span><br><span class="line">        self.block4_2 = Inception(512, 160, (112, 224), (24, 64), 64)</span><br><span class="line">        self.block4_3 = Inception(512, 128, (128, 256), (24, 64), 64)</span><br><span class="line">        self.block4_4 = Inception(512, 112, (144, 288), (32, 64), 64)</span><br><span class="line">        self.block4_5 = Inception(528, 256, (160, 320), (32, 128), 128)</span><br><span class="line">        # 3x3 最大池化</span><br><span class="line">        self.max_pool4 = paddle.nn.MaxPool2D(kernel_size=3, stride=2, padding=1)</span><br><span class="line">        # 第五个模块包含2个Inception块</span><br><span class="line">        self.block5_1 = Inception(832, 256, (160, 320), (32, 128), 128)</span><br><span class="line">        self.block5_2 = Inception(832, 384, (192, 384), (48, 128), 128)</span><br><span class="line">        # 全局池化，用的是global_pooling，不需要pool_stride</span><br><span class="line">        self.pool5 = paddle.nn.AdaptiveAvgPool2D(output_size=1)</span><br><span class="line">        self.fc = paddle.nn.Linear(in_features=1024, out_features=1)</span><br><span class="line"></span><br><span class="line">    def forward(self, x, label=None):</span><br><span class="line">        x = self.max_pool1(paddle.nn.functional.relu(self.conv1(x)))</span><br><span class="line">        x = self.max_pool2(paddle.nn.functional.relu(self.conv2_2(paddle.nn.functional.relu(self.conv2_1(x)))))</span><br><span class="line">        x = self.max_pool3(self.block3_2(self.block3_1(x)))</span><br><span class="line">        x = self.block4_3(self.block4_2(self.block4_1(x)))</span><br><span class="line">        x = self.max_pool4(self.block4_5(self.block4_4(x)))</span><br><span class="line">        x = self.pool5(self.block5_2(self.block5_1(x)))</span><br><span class="line">        x = paddle.reshape(x, [x.shape[0], -1])</span><br><span class="line">        x = self.fc(x)</span><br><span class="line"></span><br><span class="line">        # 如果输入了Label，那么计算acc</span><br><span class="line">        if label is not None:</span><br><span class="line">            acc = paddle.metric.accuracy(input=x, label=label)</span><br><span class="line">            return x, acc</span><br><span class="line">        else:</span><br><span class="line">            return x</span><br><span class="line"></span><br><span class="line"># 打印结果为</span><br><span class="line">W1206 19:02:25.166755 16624 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.7, Runtime API Version: 11.6</span><br><span class="line">W1206 19:02:25.169747 16624 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.</span><br><span class="line">start training ... </span><br><span class="line">epoch: 0, batch_id: 0, loss is: 1.1343</span><br><span class="line">epoch: 0, batch_id: 20, loss is: 0.6439</span><br><span class="line">[validation] accuracy/loss: 0.5325/0.6300</span><br><span class="line">epoch: 1, batch_id: 0, loss is: 0.5812</span><br><span class="line">epoch: 1, batch_id: 20, loss is: 0.5121</span><br><span class="line">[validation] accuracy/loss: 0.8350/0.5007</span><br><span class="line">epoch: 2, batch_id: 0, loss is: 0.5198</span><br><span class="line">epoch: 2, batch_id: 20, loss is: 0.5148</span><br><span class="line">[validation] accuracy/loss: 0.8975/0.4222</span><br><span class="line">epoch: 3, batch_id: 0, loss is: 0.4430</span><br><span class="line">epoch: 3, batch_id: 20, loss is: 0.3156</span><br><span class="line">[validation] accuracy/loss: 0.9200/0.2925</span><br><span class="line">epoch: 4, batch_id: 0, loss is: 0.2119</span><br><span class="line">epoch: 4, batch_id: 20, loss is: 0.6766</span><br><span class="line">[validation] accuracy/loss: 0.9300/0.2280</span><br><span class="line">start evaluation ......</span><br><span class="line">loss=0.2280, acc=0.4675</span><br></pre></td></tr></table></figure>

<p>使用 残差块网络 进行测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br></pre></td><td class="code"><pre><span class="line"># ResNet中使用了BatchNorm层，在卷积层的后面加上BatchNorm以提升数值稳定性</span><br><span class="line"># 定义卷积批归一体化</span><br><span class="line">class ConvBNLayer(paddle.nn.Layer):</span><br><span class="line">    def __init__(self, num_channels, num_filters, filter_size, stride=1, groups=1, act=None):</span><br><span class="line">        &#x27;&#x27;&#x27;</span><br><span class="line">        :param num_channels:卷积层的输入通道数</span><br><span class="line">        :param num_filters: 卷积层的输出通道数</span><br><span class="line">        :param filter_size:</span><br><span class="line">        :param stride: 卷积层的步幅</span><br><span class="line">        :param groups: 分组卷积的数组，默认groups=1不使用分组卷积</span><br><span class="line">        :param act:</span><br><span class="line">        &#x27;&#x27;&#x27;</span><br><span class="line">        super(ConvBNLayer, self).__init__()</span><br><span class="line"></span><br><span class="line">        # 创建卷积层</span><br><span class="line">        self._conv = paddle.nn.Conv2D(in_channels=num_channels, out_channels=num_filters, kernel_size=filter_size,</span><br><span class="line">                                      stride=stride, padding=(filter_size - 1) // 2, groups=groups, bias_attr=False)</span><br><span class="line"></span><br><span class="line">        # 创建BatchNorm层</span><br><span class="line">        self._batch_norm = paddle.nn.BatchNorm2D(num_filters)</span><br><span class="line"></span><br><span class="line">        self.act = act</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        y = self._conv(inputs)</span><br><span class="line">        y = self._batch_norm(y)</span><br><span class="line">        if self.act == &#x27;leaky&#x27;:</span><br><span class="line">            y = paddle.nn.functional.leaky_relu(x=y, negative_slope=0.1)</span><br><span class="line">        elif self.act == &#x27;relu&#x27;:</span><br><span class="line">            y = paddle.nn.functional.relu(x=y)</span><br><span class="line"></span><br><span class="line">        return y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义残差块</span><br><span class="line"># 每个残差块会对输入图片做三次卷积，然后跟输入图片进行短接</span><br><span class="line"># 如果残差块中第三次卷积输出特征图的形状与输入不一致，则对输入图片做1x1卷积，将其输出形状调整成一致</span><br><span class="line">class BottleneckBlock(paddle.nn.Layer):</span><br><span class="line">    def __init__(self, num_channels, num_filters, stride, shortcut=True):</span><br><span class="line">        super(BottleneckBlock, self).__init__()</span><br><span class="line">        # 创建第一个卷积层 1x1</span><br><span class="line">        self.conv0 = ConvBNLayer(num_channels=num_channels, num_filters=num_filters, filter_size=1, act=&#x27;relu&#x27;)</span><br><span class="line">        # 创建第二个卷积层 3x3</span><br><span class="line">        self.conv1 = ConvBNLayer(num_channels=num_filters, num_filters=num_filters, filter_size=3, stride=stride,</span><br><span class="line">                                 act=&#x27;relu&#x27;)</span><br><span class="line">        # 创建第三个卷积1x1，但是输出通道数乘以4</span><br><span class="line">        self.conv2 = ConvBNLayer(num_channels=num_filters, num_filters=num_filters * 4, filter_size=1, act=None)</span><br><span class="line"></span><br><span class="line">        # 如果conv2的输出跟此残差块的输入数据形状一致，则shortcut=True</span><br><span class="line">        # 否则shortcut = False，添加1x1的卷积作用在输入数据上，使其形状变成跟conv2一致</span><br><span class="line">        if not shortcut:</span><br><span class="line">            self.short = ConvBNLayer(num_channels=num_channels, num_filters=num_filters * 4, filter_size=1,</span><br><span class="line">                                     stride=stride)</span><br><span class="line"></span><br><span class="line">        self.shortcut = shortcut</span><br><span class="line">        self._num_channels_out = num_filters * 4</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs):</span><br><span class="line">        y = self.conv0(inputs)</span><br><span class="line">        conv1 = self.conv1(y)</span><br><span class="line">        conv2 = self.conv2(conv1)</span><br><span class="line"></span><br><span class="line">        # 如果shortcut=True，直接将inputs跟conv2的输出相加</span><br><span class="line">        # 否则需要对inputs进行一次卷积，将形状调整成跟conv2输出一致</span><br><span class="line">        if self.shortcut:</span><br><span class="line">            short = inputs</span><br><span class="line">        else:</span><br><span class="line">            short = self.short(inputs)</span><br><span class="line"></span><br><span class="line">        y = paddle.add(x=short, y=conv2)</span><br><span class="line">        y = paddle.nn.functional.relu(y)</span><br><span class="line"></span><br><span class="line">        return y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 定义ResNet模型</span><br><span class="line">class ResNet(paddle.nn.Layer):</span><br><span class="line">    def __init__(self, layers=50, class_dim=1):</span><br><span class="line">        &#x27;&#x27;&#x27;</span><br><span class="line"></span><br><span class="line">        :param layers:网络层数，可以是50,101或者152</span><br><span class="line">        :param class_dim: 分类标签的类别数</span><br><span class="line">        &#x27;&#x27;&#x27;</span><br><span class="line">        super(ResNet, self).__init__()</span><br><span class="line">        self.layers = layers</span><br><span class="line">        supported_layers = [50, 101, 152]</span><br><span class="line">        assert layers in supported_layers, &#x27;supporrted layers are &#123;&#125; but input layer is &#123;&#125;&#x27;.format(supported_layers,</span><br><span class="line">                                                                                                   layers)</span><br><span class="line"></span><br><span class="line">        if layers == 50:</span><br><span class="line">            # ResNet50包含多个模块，其中第2到第5个模块分别包含3、4、6、3个残差块</span><br><span class="line">            depth = [3, 4, 6, 3]</span><br><span class="line">        elif layers == 101:</span><br><span class="line">            # ResNet101包含多个模块，其中第2到第5个模块分别包含3、4、23、3个残差块</span><br><span class="line">            depth = [3, 4, 23, 3]</span><br><span class="line">        elif layers == 152:</span><br><span class="line">            # ResNET152包含多个模块，其中第2到第5个模块分别包含3、8、36、3</span><br><span class="line">            depth = [3, 8, 36, 3]</span><br><span class="line"></span><br><span class="line">        # 残差块中使用到的卷积的输出通道</span><br><span class="line">        num_filters = [64, 128, 256, 512]</span><br><span class="line"></span><br><span class="line">        # ResNet的第一个模块，包含1个7x7卷积，后面跟着1个最大池化层</span><br><span class="line">        self.conv = ConvBNLayer(num_channels=3, num_filters=64, filter_size=7, stride=2, act=&#x27;relu&#x27;)</span><br><span class="line">        self.max_pool = paddle.nn.MaxPool2D(kernel_size=3, stride=2, padding=1)</span><br><span class="line"></span><br><span class="line">        # ResNet的第二个到第五个模块c2、c3、c4、c5</span><br><span class="line">        self.bottleneck_block_list = []</span><br><span class="line">        num_channels = 64</span><br><span class="line">        for block in range(len(depth)):</span><br><span class="line">            shortcut = False</span><br><span class="line">            for i in range(depth[block]):</span><br><span class="line">                bottleneck_block = self.add_sublayer(</span><br><span class="line">                    &#x27;bb_%d_%d&#x27; % (block, i),</span><br><span class="line">                    BottleneckBlock(num_channels=num_channels,</span><br><span class="line">                                    num_filters=num_filters[</span><br><span class="line">                                        block],</span><br><span class="line">                                    stride=2 if i == 0 and block != 0 else 1,</span><br><span class="line">                                    shortcut=shortcut)</span><br><span class="line">                )</span><br><span class="line">                num_channels = bottleneck_block._num_channels_out</span><br><span class="line">                self.bottleneck_block_list.append(bottleneck_block)</span><br><span class="line">                shortcut = True</span><br><span class="line"></span><br><span class="line">        # 在c5的输出特征图上使用全局池化</span><br><span class="line">        self.pool2d_avg = paddle.nn.AdaptiveAvgPool2D(output_size=1)</span><br><span class="line"></span><br><span class="line">        # stdv用来作为全连接层随机初始化参数的方差</span><br><span class="line">        import math</span><br><span class="line">        stdv = 1.0 / math.sqrt(2048 * 1.0)</span><br><span class="line"></span><br><span class="line">        # 创建全连接层，输出大小为类别数目，经过残差网络的卷积和全局池化后，卷积特征的维度是[B, 2048, 1, 1]，故最后一层全连接的输入维度是2048</span><br><span class="line">        self.out = paddle.nn.Linear(in_features=2048,</span><br><span class="line">                                    out_features=class_dim,</span><br><span class="line">                                    weight_attr=paddle.ParamAttr(</span><br><span class="line">                                        initializer=paddle.nn.initializer.Uniform(-stdv, stdv))</span><br><span class="line">                                    )</span><br><span class="line"></span><br><span class="line">    def forward(self, inputs, label=None):</span><br><span class="line">        y = self.conv(inputs)</span><br><span class="line">        y = self.max_pool(y)</span><br><span class="line">        for bottleneck_block in self.bottleneck_block_list:</span><br><span class="line">            y = bottleneck_block(y)</span><br><span class="line">        y = self.pool2d_avg(y)</span><br><span class="line">        y = paddle.reshape(y, [y.shape[0], -1])</span><br><span class="line">        y = self.out(y)</span><br><span class="line"></span><br><span class="line">        # 如果输入了Label，那么计算acc</span><br><span class="line">        if label is not None:</span><br><span class="line">            acc = paddle.metric.accuracy(input=inputs, label=label)</span><br><span class="line">            return y, acc</span><br><span class="line">        else:</span><br><span class="line">            return y</span><br><span class="line"></span><br><span class="line"># 打印结果为</span><br><span class="line">W1206 19:58:02.451362 12844 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.7, Runtime API Version: 11.6</span><br><span class="line">W1206 19:58:02.453357 12844 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.</span><br><span class="line">start training ... </span><br><span class="line">F:\miniconda3nvs\paddle23\lib\site-packages\paddle</span><br><span class="line">n\layer</span><br><span class="line">orm.py:654: UserWarning: When training, we now always track global mean and variance.</span><br><span class="line">  &quot;When training, we now always track global mean and variance.&quot;)</span><br><span class="line">epoch: 0, batch_id: 0, loss is: 0.6839</span><br><span class="line">epoch: 0, batch_id: 20, loss is: 0.9671</span><br><span class="line">[validation] accuracy/loss: 0.5575/1.0465</span><br><span class="line">epoch: 1, batch_id: 0, loss is: 0.5888</span><br><span class="line">epoch: 1, batch_id: 20, loss is: 0.3879</span><br><span class="line">[validation] accuracy/loss: 0.6675/0.8323</span><br><span class="line">epoch: 2, batch_id: 0, loss is: 1.0331</span><br><span class="line">epoch: 2, batch_id: 20, loss is: 0.1507</span><br><span class="line">[validation] accuracy/loss: 0.9125/0.3006</span><br><span class="line">epoch: 3, batch_id: 0, loss is: 0.7395</span><br><span class="line">epoch: 3, batch_id: 20, loss is: 0.1936</span><br><span class="line">[validation] accuracy/loss: 0.9200/0.2864</span><br><span class="line">epoch: 4, batch_id: 0, loss is: 0.0622</span><br><span class="line">epoch: 4, batch_id: 20, loss is: 0.1062</span><br><span class="line">[validation] accuracy/loss: 0.8925/0.2969</span><br><span class="line">start evaluation ......</span><br><span class="line">loss=0.2969, acc=0.0000</span><br></pre></td></tr></table></figure>

<p>也可以直接通过<code>from paddle.vision.models import resnet50, vgg16, LeNet</code>来使用封装好的网络模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from paddle.vision.models import resnet50, vgg16, LeNet</span><br><span class="line">......</span><br><span class="line">model = resnet50(pretrained=False, num_classes=1)</span><br></pre></td></tr></table></figure>

<br>
## 2.5 PCB电路板缺陷检测(PaddleDetection)
使用PaddlePaddle的[PaddleDetection](https://github.com/PaddlePaddle/PaddleDetection)来完成。
需要下载项目中。

<p><strong>安装PaddleDection开发套件</strong><br>下载PaddleDection包，下载requirement中的模块 <code>pip install -r . equirements.txt</code></p>
<blockquote>
<p>如果cython_bbox安装失败，使用如下命令安装<br><code>python -m pip install git+https://github.com/yanfengliu/cython_bbox.git</code></p>
</blockquote>
<p>在项目目录下创建work目录，放置开发脚本。</p>
<br>
**数据集中的json文件标签含义**
COCO数据集标注中的annotation标签各个属性含义
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;area&quot;:4012,</span><br><span class="line">    &quot;iscrowd&quot;:0,</span><br><span class="line">    &quot;bbox&quot;:[492, 500, 59, 68],</span><br><span class="line">    &quot;category_id&quot;:3,</span><br><span class="line">    &quot;ignore&quot;:0,</span><br><span class="line">    &quot;segmentation&quot;:[],</span><br><span class="line">    &quot;image_id&quot;:0,</span><br><span class="line">    &quot;id&quot;:1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
>id字段：指的是这个annotation的一个id
>image_id：等同于前面image字段里面的id。
>category_id：类别id
>segmentation：
>area：标注区域面积
>bbox：标注框，依次为标注框左上角横纵坐标，宽和高 (即492和500为标注框的左上角坐标，59是width，68是height)
>iscrowd：决定是RLE格式还是polygon格式。

<p>首先需要检查样本信息，包括 ①样本中标注的种类数量是否相近 ②锚框宽高比 ③锚框占整个图片的比例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">import json</span><br><span class="line">import collections</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line"></span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">首先需要检查样本信息，包括 ①样本中标注的种类数量是否相近 ②锚框宽高比 ③锚框占整个图片的比例</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line"></span><br><span class="line"># 加载解析json文件</span><br><span class="line">with open(&#x27;./PCB_DATASET/Annotations/train.json&#x27;) as f:</span><br><span class="line">    data = json.load(f)</span><br><span class="line"></span><br><span class="line"># 保存图片信息</span><br><span class="line">imgs = &#123;&#125;</span><br><span class="line">for img in data[&#x27;images&#x27;]:</span><br><span class="line">    imgs[img[&#x27;id&#x27;]] = &#123;</span><br><span class="line">        &#x27;height&#x27;: img[&#x27;height&#x27;],</span><br><span class="line">        &#x27;width&#x27;: img[&#x27;width&#x27;],</span><br><span class="line">        &#x27;area&#x27;: img[&#x27;height&#x27;] * img[&#x27;width&#x27;]</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 计算标注信息</span><br><span class="line">hw_ratios = []</span><br><span class="line">area_ratios = []</span><br><span class="line">cate_count = collections.defaultdict(int)</span><br><span class="line">for anno in data[&#x27;annotations&#x27;]:</span><br><span class="line">    hw_ratios.append(anno[&#x27;bbox&#x27;][3] / anno[&#x27;bbox&#x27;][2])</span><br><span class="line">    area_ratios.append(anno[&#x27;area&#x27;] / imgs[anno[&#x27;image_id&#x27;]][&#x27;area&#x27;])</span><br><span class="line">    cate_count[anno[&#x27;category_id&#x27;]] += 1</span><br><span class="line"></span><br><span class="line">print(cate_count, len(data[&#x27;annotations&#x27;])/len(data[&#x27;images&#x27;]))</span><br><span class="line"></span><br><span class="line">plt.hist(hw_ratios, bins=100, range=[0, 2])</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.hist(area_ratios, bins=100, range=[0, 0.005])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>编辑配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br></pre></td><td class="code"><pre><span class="line">metric: COCO    # Label评价指标，coco IoU:0.5:0.95</span><br><span class="line">num_classes: 7  # 类别数量：coco类别比实际类别(voc类别) +1</span><br><span class="line"></span><br><span class="line"># 数据集的位置等信息</span><br><span class="line">TrainDataset:</span><br><span class="line">  !COCODataSet</span><br><span class="line">    image_dir: images</span><br><span class="line">    anno_path: Annotations/train.json</span><br><span class="line">    dataset_dir: D:\ML\Dataset\PCB_DATASET</span><br><span class="line">    data_fields: [&#x27;image&#x27;,&#x27;gt_bbox&#x27;,&#x27;gt_class&#x27;] # &#x27;输入图片，得到输出框和类别&#x27;</span><br><span class="line"></span><br><span class="line">EvalDataset:</span><br><span class="line">  !COCODataSet</span><br><span class="line">    image_dir: images</span><br><span class="line">    anno_path: Annotations/val.json</span><br><span class="line">    dataset_dir: D:\ML\Dataset\PCB_DATASET</span><br><span class="line"></span><br><span class="line">TestDataset:</span><br><span class="line">  !ImageFolder</span><br><span class="line">    anno_path: Annotations/val.json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">use_gpu: False        # 是否开启GPU</span><br><span class="line">log_iter: 10          # 日志窗口的尺度</span><br><span class="line">save_dir: output/     # 输出结果罗盘位置</span><br><span class="line">snapshot_epoch: 1     # 生成快照的频率，即每1个周期生成一次</span><br><span class="line"></span><br><span class="line">epoch: 24             ### 训练周期：24</span><br><span class="line"></span><br><span class="line">LearningRate:         ### 学习率：阶段学习</span><br><span class="line">  base_lr: 0.0025     # 起始学习率：0.0025</span><br><span class="line">  schedulers:</span><br><span class="line">  - !PiecewiseDecay   ## 阶段学习率</span><br><span class="line">    gamma: 0.1        # 每次学习率变化为原来的1/10</span><br><span class="line">    milestones: [16, 22] # 总共进行两次学习率的降低，分别在第16轮和22轮开始时</span><br><span class="line">  - !LinearWarmup     ## 慢启动，共执行200次迭代，学习率为初始学习率的0.1</span><br><span class="line">    start_factor: 0.1</span><br><span class="line">    steps: 200</span><br><span class="line"></span><br><span class="line">OptimizerBuilder:     ### 定义优化器</span><br><span class="line">  optimizer:          ## 基于动量的SGD优化器</span><br><span class="line">    momentum: 0.9</span><br><span class="line">    type: Momentum</span><br><span class="line">  regularizer:        ## 定义正则项</span><br><span class="line">    factor: 0.0001</span><br><span class="line">    type: L2</span><br><span class="line"></span><br><span class="line">architecture: FasterRCNN  # 总框架类型</span><br><span class="line"></span><br><span class="line"># 预训练模型：基于已有的模型进行训练</span><br><span class="line"># pretrain_weights: https://paddledet.bj.bcebos.com/models/pretrained/ResNet50_cos_pretrained.pdparams</span><br><span class="line">pretrain_weights: D:\ML\Project\PaddleDetection-release-2.3\work\output\Resnet50_cos_pretrained.pdparams</span><br><span class="line"></span><br><span class="line">## 检测模型的体系结构，包含骨干、支路、区域建设、BBox头和BBox后处理</span><br><span class="line">FasterRCNN:</span><br><span class="line">  backbone: ResNet          # 主干网络：ResNet</span><br><span class="line">  neck: FPN                 # 特征融合：特征金字塔网络</span><br><span class="line">  rpn_head: RPNHead         # 区域建议头：基于FPN的RPNHead</span><br><span class="line">  bbox_head: BBoxHead       # BBox头：BBoxHead</span><br><span class="line">  # post process</span><br><span class="line">  bbox_post_process: BBoxPostProcess  # BBox后处理器</span><br><span class="line"></span><br><span class="line">## 对定义的RestNet进行详细描述</span><br><span class="line">ResNet:</span><br><span class="line">  depth: 50                 # 深度50，即ResNet50</span><br><span class="line">  norm_type: bn             # 正则化类BN，基本上是唯一选择</span><br><span class="line">  freeze_at: 0              # 冻结部分，ResNet的前两层，不调整参数</span><br><span class="line">  return_idx: [0,1,2,3]     # 提取特征的位置，即用于FPN的特征，其实index为0</span><br><span class="line">  num_stages: 4             # 总共4个阶段</span><br><span class="line"></span><br><span class="line">## 对定义的FPN进行详细描述</span><br><span class="line">FPN:</span><br><span class="line">  out_channel: 256          ## FPN通道数：256</span><br><span class="line"></span><br><span class="line">### 对定义的RPNHead进行描述</span><br><span class="line">RPNHead:</span><br><span class="line">  anchor_generator:                             ## Anchor生成器</span><br><span class="line">    aspect_ratios: [0.5,1.0,2.0]                # Anchor的比例1:2,1:1,2:1</span><br><span class="line">    anchor_sizes: [[32],[64],[128],[256],[512]] # Anchor的尺度比例</span><br><span class="line">    strides: [4,8,16,32,64]                     # Anchor的步长</span><br><span class="line">  rpn_target_assign:                            ## RPN设置</span><br><span class="line">    batch_size_per_im: 256                      # RPN采样数量：256</span><br><span class="line">    fg_fraction: 0.5                            # 正则样本数量：256*0.5=128</span><br><span class="line">    negative_overlap: 0.3                       # 负样本IoU&lt;0.3</span><br><span class="line">    positive_overlap: 0.7                       # 正样本IoU&gt;0.7</span><br><span class="line">    use_random: True</span><br><span class="line">  train_proposal:                               ## 训练建议框设置</span><br><span class="line">    min_size: 0.0</span><br><span class="line">    nms_thresh: 0.7                             # 训练阶段nms阈值</span><br><span class="line">    pre_nms_top_n: 2000                         # 第一阶段nms数量</span><br><span class="line">    post_nms_top_n: 1000                        # 第二阶段nms数量</span><br><span class="line">    topk_after_collect: True</span><br><span class="line">  test_proposal:                                ## 测试建议框设置</span><br><span class="line">    min_size: 0.0</span><br><span class="line">    nms_thresh: 0.7                             # 测试阶段nms阈值</span><br><span class="line">    pre_nms_top_n: 1000                         # 第一阶段nms数量</span><br><span class="line">    post_nms_top_n: 1000                        # 第二阶段nms数量</span><br><span class="line"></span><br><span class="line">## 对定义的BBoxHead进行详细描述</span><br><span class="line">BBoxHead:</span><br><span class="line">  head: TwoFCHead                 ## 两个FC头</span><br><span class="line">  roi_extractor:</span><br><span class="line">    resolution: 7                 # RoIPooling特征层的尺度7x7</span><br><span class="line">    sampling_ratio: 0</span><br><span class="line">    aligned: True                 # 启用RoIAlign</span><br><span class="line">  bbox_assigner: BBoxAssigner</span><br><span class="line"></span><br><span class="line">## 对BBoxHead中定义的BBoxAssigner和TwoFCHead进行详细描述</span><br><span class="line">BBoxAssigner:</span><br><span class="line">  batch_size_per_im: 512    # batch数量：512</span><br><span class="line">  bg_thresh: 0.5            # 背景阈值&lt;0.5</span><br><span class="line">  fg_thresh: 0.5            # 前景阈值&gt;0.5</span><br><span class="line">  fg_fraction: 0.25</span><br><span class="line">  use_random: True</span><br><span class="line"></span><br><span class="line">TwoFCHead:</span><br><span class="line">  out_channel: 1024         # 全连接层特征维度(后面紧跟分类和回归层):1024</span><br><span class="line"></span><br><span class="line">## 对定义的BBoxPostProcess进行详细描述</span><br><span class="line">BBoxPostProcess:</span><br><span class="line">  decode: RCNNBox</span><br><span class="line">  nms:</span><br><span class="line">    name: MultiClassNMS</span><br><span class="line">    keep_top_k: 100</span><br><span class="line">    score_threshold: 0.05</span><br><span class="line">    nms_threshold: 0.5</span><br><span class="line"></span><br><span class="line">## 定义工作并行度</span><br><span class="line">worker_num: 2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 数据读取和预处理(数据增强等)</span><br><span class="line">TrainReader:</span><br><span class="line">  sample_transforms:    # 数据预处理</span><br><span class="line">  - Decode: &#123;&#125;</span><br><span class="line">  - RandomResize: &#123;target_size: [[640,1333],[672,1333],[704,1333],[736,1333],[768,1333],[800,1333]],interp: 2,keep_ratio: True&#125; # 图片随机放大</span><br><span class="line">  - RandomFlip: &#123;prob: 0.5&#125;   # 图片随机翻转</span><br><span class="line">  - NormalizeImage: &#123;is_scale: true, mean: [0.485,0.456,0.406],std: [0.229,0.224,0.225]&#125;  # 图片归一化</span><br><span class="line">  - Permute: &#123;&#125;</span><br><span class="line">  batch_transforms:</span><br><span class="line">  - PadBatch: &#123;pad_to_stride: 32&#125;</span><br><span class="line">  batch_size: 1         # 每批大尺度</span><br><span class="line">  shuffle: true         # 是否打乱顺序</span><br><span class="line">  drop_last: true       # 最后一个batch不是batch_sizes时，是否将多余数据进行丢弃</span><br><span class="line"></span><br><span class="line">EvalReader:</span><br><span class="line">  sample_transforms:</span><br><span class="line">  - Decode: &#123;&#125;</span><br><span class="line">  - Resize: &#123;interp: 2,target_size:[800,1333],keep_ratio: True&#125;</span><br><span class="line">  - NormalizeImage: &#123;is_scale: true,mean: [0.485,0.456,0.406],std:[0.229,0.224,0.225]&#125;</span><br><span class="line">  - Permute: &#123;&#125;</span><br><span class="line">  batch_transforms:</span><br><span class="line">  - PadBatch: &#123;pad_to_stride: 32&#125;</span><br><span class="line">  batch_size: 1</span><br><span class="line">  shuffle: false</span><br><span class="line">  drop_last: false</span><br><span class="line">  drop_empty: false</span><br><span class="line"></span><br><span class="line">TestReader:</span><br><span class="line">  sample_transforms:</span><br><span class="line">  - Decode: &#123;&#125;</span><br><span class="line">  - Resize: &#123;interp: 2,target_size:[800,1333],keep_ratio: True&#125;</span><br><span class="line">  - NormalizeImage: &#123;is_scale: true,mean:[0.485,0.456,0.406],std:[0.229,0.224,0.225]&#125;</span><br><span class="line">  - Permute: &#123;&#125;</span><br><span class="line">  batch_transforms:</span><br><span class="line">  - PadBatch: &#123;pad_to_stride: 32&#125;</span><br><span class="line">  batch_size: 1</span><br><span class="line">  shuffle: false</span><br><span class="line">  drop_last: false</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<br>
**训练模型**
`python -u .	ools	rain.py -c .\work\PCB_faster_rcnn_r50_fpn_3x_coco.yml --eval use_gpu=True`
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">loading annotations into memory...</span><br><span class="line">Done (t=0.02s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">[12/08 17:36:56] ppdet.utils.checkpoint INFO: Finish loading model weights: D:\ML\Project\PaddleDetection-release-2.3\output\PCB_faster_rcnn_r50_fpn_3x_coco .pdparams</span><br><span class="line">[12/08 17:37:05] ppdet.engine INFO: Epoch: [0] [  0/593] learning_rate: 0.000250 loss_rpn_cls: 0.077478 loss_rpn_reg: 0.048770 loss_bbox_cls: 0.151260 loss_bbox_reg: 0.053664 loss: 0.331172 eta: 1 day, 10:05:31 batch_cost: 8.6236 data_cost: 0.0000 ips: 0.1160 images/s</span><br><span class="line">[12/08 17:38:47] ppdet.engine INFO: Epoch: [0] [ 10/593] learning_rate: 0.000363 loss_rpn_cls: 0.087272 loss_rpn_reg: 0.061770 loss_bbox_cls: 0.217608 loss_bbox_reg: 0.207371 loss: 0.706757 eta: 1 day, 15:42:19 batch_cost: 10.1933 data_cost: 0.0002 ips: 0.0981 images/s</span><br><span class="line">[12/08 17:40:51] ppdet.engine INFO: Epoch: [0] [ 20/593] learning_rate: 0.000475 loss_rpn_cls: 0.084982 loss_rpn_reg: 0.087303 loss_bbox_cls: 0.147528 loss_bbox_reg: 0.072444 loss: 0.408839 eta: 1 day, 20:04:12 batch_cost: 12.3873 data_cost: 0.0000 ips: 0.0807 images/s</span><br><span class="line">[12/08 17:42:28] ppdet.engine INFO: Epoch: [0] [ 30/593] learning_rate: 0.000588 loss_rpn_cls: 0.097606 loss_rpn_reg: 0.065509 loss_bbox_cls: 0.215224 loss_bbox_reg: 0.134091 loss: 0.556537 eta: 1 day, 18:10:50 batch_cost: 9.7029 data_cost: 0.0002 ips: 0.1031 images/s</span><br></pre></td></tr></table></figure>
**对模型进行评估**
`python -u .	oolsval.py -c .\work\PCB_faster_rcnn_r50_fpn_3x_coco.yml -o weights=.\output\PCB_faster_rcnn_r50_fpn_3x_cocoest_model.pdparams use_gpu=True`
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[12/08 17:58:43] ppdet.metrics.coco_utils INFO: Start evaluate...</span><br><span class="line">Loading and preparing results...</span><br><span class="line">DONE (t=0.00s)</span><br><span class="line">creating index...</span><br><span class="line">index created!</span><br><span class="line">Running per image evaluation...</span><br><span class="line">Evaluate annotation type *bbox*</span><br><span class="line">DONE (t=0.07s).</span><br><span class="line">Accumulating evaluation results...</span><br><span class="line">DONE (t=0.04s).</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.085</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.024</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.023</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.107</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.115</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.115</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000</span><br><span class="line">[12/08 17:58:44] ppdet.engine INFO: Total sample number: 10, averge FPS: 0.15968471430523315</span><br></pre></td></tr></table></figure>
**使用模型进行推测**
`python -u .	ools\infer.py -c .\work\PCB_faster_rcnn_r50_fpn_3x_coco.yml --infer_img=.\work\PCB_DATASET\images_missing_hole_10.jpg -o weights=.\work\output\PCB_faster_rcnn_r50_fpn_3x_cocoest_model.pdparams use_gpu=True`
查看预测后的图片
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">infer_img = cv2.imread(&quot;D:/ML/Project/PaddleDetection-release-2.3/output/04_missing_hole_10.jpg&quot;)</span><br><span class="line">plt.figure(figsize=(15, 10))</span><br><span class="line">plt.imshow(cv2.cvtColor(infer_img, cv2.COLOR_BGR2RGB))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<br>
## 2.6 车牌识别(PaddleOCR)
使用PaddlePaddle的[PaddleOCR开发套件](https://github.com/PaddlePaddle/PaddleOCR)来完成。

<p><strong>安装PaddleOCR开发套件</strong><br>下载PaddleOCR包，下载requirements中的模块 <code>pip install -r . equirements.txt</code></p>
<p><strong>对数据集进行处理</strong></p>
<pre><code>import os
import cv2

ads = [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;, &#39;J&#39;, &#39;K&#39;, &#39;L&#39;, &#39;M&#39;,
       &#39;N&#39;, &#39;P&#39;, &#39;Q&#39;, &#39;R&#39;, &#39;S&#39;, &#39;T&#39;, &#39;U&#39;, &#39;V&#39;, &#39;W&#39;, &#39;X&#39;, &#39;Y&#39;, &#39;Z&#39;,
       &#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8,&#39;, &#39;9&#39;, &#39;O&#39;]

provinces = [&quot;皖&quot;, &quot;沪&quot;, &quot;津&quot;, &quot;渝&quot;, &quot;冀&quot;, &quot;晋&quot;, &quot;蒙&quot;, &quot;辽&quot;, &quot;吉&quot;, &quot;黑&quot;, &quot;苏&quot;,
             &quot;浙&quot;, &quot;京&quot;, &quot;闽&quot;, &quot;赣&quot;, &quot;鲁&quot;, &quot;豫&quot;, &quot;鄂&quot;, &quot;湘&quot;, &quot;粤&quot;, &quot;桂&quot;, &quot;琼&quot;,
             &quot;川&quot;, &quot;贵&quot;, &quot;云&quot;, &quot;藏&quot;, &quot;陕&quot;, &quot;甘&quot;, &quot;青&quot;, &quot;宁&quot;, &quot;新&quot;, &quot;警&quot;, &quot;学&quot;]

if not os.path.exists(&#39;./img&#39;):
    os.mkdir(&#39;./img&#39;)
## 分为车牌检测和车牌识别
# 转换检测数据
train_det = open(&#39;./train_det.txt&#39;, &#39;w&#39;, encoding=&#39;UTF-8&#39;)
dev_det = open(&#39;./dev_det.txt&#39;, &#39;w&#39;, encoding=&#39;UTF-8&#39;)

# 转换识别数据
train_rec = open(&#39;./train_rec.txt&#39;, &#39;w&#39;, encoding=&#39;UTF-8&#39;)
dev_rec = open(&#39;./dev_rec.txt&#39;, &#39;w&#39;, encoding=&#39;UTF-8&#39;)

# 总样本数
total_num = len(os.listdir(&#39;D:\ML\Dataset\CCPD2019
</code></pre>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">CJ</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2023/05/06/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/PaddlePaddle/">http://example.com/2023/05/06/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/PaddlePaddle/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Hexo</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/05/06/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%A1%86%E6%9E%B6XXL%E4%BD%BF%E7%94%A8/" title="定时任务调度框架XXL使用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">定时任务调度框架XXL使用</div></div></a></div><div class="next-post pull-right"><a href="/2023/05/06/SpringBoot/6%E7%A7%8D@Transactional%E6%B3%A8%E8%A7%A3%E7%9A%84%E5%A4%B1%E6%95%88%E5%9C%BA%E6%99%AF/" title="6种@Transactional注解的失效场景"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">6种@Transactional注解的失效场景</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">CJ</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">419</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">38</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%90%AD%E5%BB%BA"><span class="toc-number">1.</span> <span class="toc-text">一、搭建</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E4%BD%BF%E7%94%A8"><span class="toc-number">2.</span> <span class="toc-text">二、使用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E5%AE%98%E6%96%B9demo-%E8%AF%86%E5%88%AB%E5%9B%BE%E7%89%87%E4%B8%8A%E7%9A%84%E6%95%B0%E5%AD%97"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 官方demo(识别图片上的数字)</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/MySQL/%E6%B3%A8%E8%A7%A3@Select%E5%92%8C@Insert/" title="注解@Select和@Insert">注解@Select和@Insert</a><time datetime="2023-05-06T05:48:28.906Z" title="发表于 2023-05-06 13:48:28">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E5%90%8E%E7%AB%AF%E6%A1%86%E6%9E%B6/%E6%B3%A8%E8%A7%A3@EnableAutoConfiguration/" title="注解@EnableAutoConfiguration">注解@EnableAutoConfiguration</a><time datetime="2023-05-06T05:48:06.027Z" title="发表于 2023-05-06 13:48:06">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A6%BB%E7%BA%BF/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7%E6%A1%86%E6%9E%B6/" title="大数据集群监控框架">大数据集群监控框架</a><time datetime="2023-05-06T05:42:56.298Z" title="发表于 2023-05-06 13:42:56">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E9%AB%98%E5%B9%B6%E5%8F%91/HashMap%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98%E5%8F%8AConcurrentHashMap%E5%8E%9F%E7%90%86/" title="HashMap并发问题及ConcurrentHashMap原理">HashMap并发问题及ConcurrentHashMap原理</a><time datetime="2023-05-06T05:31:21.103Z" title="发表于 2023-05-06 13:31:21">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E9%AB%98%E5%B9%B6%E5%8F%91/Stream%E5%8E%9F%E7%90%86/" title="Stream原理">Stream原理</a><time datetime="2023-05-06T05:31:21.103Z" title="发表于 2023-05-06 13:31:21">2023-05-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By CJ</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>