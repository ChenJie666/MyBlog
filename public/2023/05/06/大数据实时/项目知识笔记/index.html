<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>项目知识笔记 | Hexo</title><meta name="author" content="CJ"><meta name="copyright" content="CJ"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="系统变量：&#x2F;etc&#x2F;profile用户变量：~&#x2F;.bash_profile | ~&#x2F;.bash_login | ~&#x2F;.profile login 和 non-login shelllogin方式加载顺序：etc&#x2F;profile -&gt; &#x2F;.bash_profile | ~&#x2F;.bash_login | ~&#x2F;">
<meta property="og:type" content="article">
<meta property="og:title" content="项目知识笔记">
<meta property="og:url" content="http://example.com/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%97%B6/%E9%A1%B9%E7%9B%AE%E7%9F%A5%E8%AF%86%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="系统变量：&#x2F;etc&#x2F;profile用户变量：~&#x2F;.bash_profile | ~&#x2F;.bash_login | ~&#x2F;.profile login 和 non-login shelllogin方式加载顺序：etc&#x2F;profile -&gt; &#x2F;.bash_profile | ~&#x2F;.bash_login | ~&#x2F;">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2023-05-06T05:31:21.051Z">
<meta property="article:modified_time" content="2023-05-06T05:31:21.051Z">
<meta property="article:author" content="CJ">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%97%B6/%E9%A1%B9%E7%9B%AE%E7%9F%A5%E8%AF%86%E7%AC%94%E8%AE%B0/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '项目知识笔记',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2023-05-06 13:31:21'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">419</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">38</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Hexo"><span class="site-name">Hexo</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">项目知识笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-05-06T05:31:21.051Z" title="发表于 2023-05-06 13:31:21">2023-05-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-05-06T05:31:21.051Z" title="更新于 2023-05-06 13:31:21">2023-05-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%97%B6/">大数据实时</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="项目知识笔记"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>系统变量：&#x2F;etc&#x2F;profile<br>用户变量：~&#x2F;.bash_profile | ~&#x2F;.bash_login | ~&#x2F;.profile</p>
<p>login 和 non-login shell<br>login方式加载顺序：etc&#x2F;profile -&gt; <del>&#x2F;.bash_profile | ~&#x2F;.bash_login | ~&#x2F;.profile(加载时，按照上述顺序进行加载，只要加载到一个文件就停止加载)<br>non-login方式加载顺序：不会加载 etc&#x2F;profile，只会加载</del>&#x2F;.bashrc</p>
<p>常用端口号：</p>
<p>6379：Redis的端口号</p>
<p>3306：Mysql端口号</p>
<p>9000：NN的端口</p>
<p>50070：NN的web端口</p>
<p>50090：2NN的端口</p>
<p>8088：resourcemanager的web端口</p>
<p>8032：resourcemanager（jobtracker）的服务端口</p>
<p>19888：历史服务器web端口</p>
<p>2181：zookeeper的服务端口</p>
<p>2888和3888：内部通讯端口和选举端口</p>
<p>8485：journalnode默认端口</p>
<p>41414：flume监控端口</p>
<p>9092：kafka监控端口</p>
<p>8086：kafka monitoer的web端口</p>
<p>9000：kafka manager的web端口，默认是9000，与namenode端口冲突，bin&#x2F;kafka-manager  -Dhttp.port&#x3D;9090</p>
<p>10000：hive2端口</p>
<p>16010：hbase的web端口号</p>
<p>16000：hbase的master的通讯端口</p>
<p>16020：regionserver的端口号</p>
<p>16030：regionserver的web端口号</p>
<p>11000：oozie的web端口号</p>
<p>8443：azkaban的web端口</p>
<p>8081：azkaban的通讯端口</p>
<p>21000：impala的端口</p>
<p>25010：impala的日志web端口</p>
<p>9083：hive元数据仓库metastore的端口号</p>
<p>8080：kettlemaster节点<br>8081：kettleslave1节点<br>8082：kettleslave2节点</p>
<p>9300：elasticsearch官方客户端连接、内部通讯端口<br>9200：elasticsearch集群、控制台和http访问端口<br>5601：kibana服务端口</p>
<p>1521：orical端口号<br>27017：mongodb端口号</p>
<p>8080：tomcat端口</p>
<p>7180：cdm服务端口	 hadoop102:7180cdm集群</p>
<p>hadoop102:50070		namenode<br>hadoop103:8088		resourcemanager<br>hadoop104:19888		history<br>hadoop102:16010		hbase</p>
<p>hadoop102：11000  		oozie<br><a target="_blank" rel="noopener" href="https://hadoop102:8443/">https://hadoop102:8443</a>	azkaban</p>
<p>hadoop102:7180		cdm集群</p>
<p>配置文件位置<br>&#x2F;etc&#x2F;hosts			hosts ：<br>&#x2F;etc&#x2F;profile 		profile :<br>&#x2F;etc&#x2F;selinux&#x2F;config		setenforce(临时更改指令：sudo setenforce 0)<br>&#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0	网络配置<br>&#x2F;etc&#x2F;udev&#x2F;rules.d&#x2F;7-persistent-net.rules 网卡配置<br>&#x2F;etc&#x2F;sysconfig&#x2F;network	修改主机名<br>&#x2F;etc&#x2F;sudoers		用户权限</p>
<p>&#x2F;etc&#x2F;ntp.conf		ntp时间同步的配置文件<br>&#x2F;etc&#x2F;sysconfig&#x2F;ntpd		设置系统时间与硬件时间同步</p>
<p>&#x2F;etc&#x2F;selinux&#x2F;config		安全系统配置文件disable ，可以用指令sudo setenforce 0使安全防护临时失效（使用ganglia需要将其关闭）</p>
<p>hadoop配置（分布式）：①下载并配置jdk和hadoop路径到&#x2F;etc&#x2F;profile②配置ssh（ssh-keygen -t rsa和ssh-copy-id $hostname）③配置8个配置文件并分发（core-site.xml配置NN的url和存储路径，hdfs-site.xml配置副本数和2nn，mapred-site.xml配置1.运行在yarn上2.历史服务器通讯地址3.历史服务器web地址，yarn-site.xml配置1.在mr中使用自带的shuffle 2.resourcemanager节点 3.历史服务器聚合功能）④集群时间同步：1.安装ntp2.在&#x2F;etc&#x2F;ntp.conf文件中授权同网段的机器可以查询和同步时间，不使用其他互联网上时间，添加server 127.127.1.0和fudge 127.127.1.0 stratum 10  3.硬件时间与系统时间同步 &#x2F;etc&#x2F;sysconfig&#x2F;ntpd文件SYNC_HWCLOCK&#x3D;yes</p>
<p>zookeeper配置（分布式）：①zk根目录创建zkData文件夹，新建文件myid写入本机id号②配置zoo.cfg：修改dataDir路径到zkData文件夹，添加server.id&#x3D;hadoopxxx:2888:3888</p>
<p>flume配置（非分布式）：配置flume-env.sh中export JAVA_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;jdk1.8.0_144</p>
<p>kafka配置（分布式）：配置server.properties中的broker编号、删除topic功能、运行日志存放位置、kafka集群地址</p>
<p>sqoop配置（非分布式）：①sqoop-env.sh配置hadoop、hive、hbase和zookeeper的目录，因为sqoop作用是大数据集群的导入导出。②将mysql-connector的jar包导入到lib目录下，因为sqoop需要连接mysql。</p>
<p>mysql安装：①安装mysql服务端并启动服务②安装客户端，用生成的密码登陆然后修改密码，并修改mysql库中user表的信息，flush privileges</p>
<p>hive配置（借由hdfs实现分布式）：①配置hive-env.sh文件，指明hadoop路径和hive配置文件路径。②mysql驱动jar包复制到hive&#x2F;lib目录下，在hive-site.xml文件中配置mysql。④可以配置表头文件和mysql库的编码⑤hive-log4j.properties中修改log的存放位置。</p>
<p>tez引擎配置：①在hive-env.sh文件中添加tez环境变量配置和依赖包环境变量配置②在hive&#x2F;conf下创建一个tez-site.xml文件，配置tez③将tez文件夹整个上传到hdfs。④如果因为虚拟内存溢出导致kill调container，可以在yarn.site.xml中添加property禁关闭虚拟内存检查。⑤mapred-site.xml中设置map和reduce任务内存配置。</p>
<p>防止metastore中的数据丢失，可以给mysql设置高可用。</p>
<p>azkaban安装（非分布式）：①在mysql中source azkaban自带的建表脚本，创建azkaban数据库和表②生成密钥库（证书和公私钥）③时间需要同步④配置web中的azkaban.properties，增加azkaban-users.xml中的管理员用户⑤配置executor中的azkaban.properties文件</p>
<p>hbase配置：①hbase-env.sh中配置JAVA_HOME，jdk8可以permsize的配置注释掉，将hbase管理zk设为false②regionservers文件中配置regionserver所在的机器③hbase-site.xml中添加hbase和zookeeper的相关信息</p>
<p>③可以将hadoop的配置文件软连接到hbase的conf中，但是配置了hadoop_home可以省略该步骤。④分发hbase</p>
<p>kylin配置①需要hadoop集群、hive和habase②需要在环境变量中配置HADOOP_HOME、HIVE_HOME和HBASE_HOME,kylin会自动读取环境变量。③启动hdfs、历史服务器、yarn和zookeeper，bin&#x2F;kylin.sh start启动kylin</p>
<p>1.沉默用户：筛选出只启动了一次的用户，然后判断启动日期是否是一周前！！</p>
<p>3.流失用户：可以查询出每个mid_id的最大登录时间，判断是否是一周前！！</p>
<p>4.连续三周登陆统计三周内所有的登陆者，以周进行group by，计算mid_id人数，count等于三的是连续三周登录的</p>
<p>SKU&#x3D;Stock Keeping Unit（库存量基本单位）。现在已经被引申为产品统一编号的简称，每种产品均对应有唯一的SKU号。</p>
<p> SPU(Standard Product Unit)：是商品信息聚合的最小单位，是一组可复用、易检索的标准化信息集合。</p>
<p>实体表：存储实体对象的表。</p>
<p>维度表：字段的解释表</p>
<p>事实表：一条数据对应一个事件，每个事件带有可度量属性。</p>
<p>事务型事实表：数据不可变</p>
<p>周期型事实表：数据可变（如订单状态会改变）</p>
<p>每日全量：每天的数据都导入到数仓中。针对数据量较小，一般实体表和纬度表。</p>
<p>每日增量：导入每天新增的数据。针对数据量大且只有新增数据，一般事务型事实表采用。</p>
<p>每日新增及变化量：包括了新增量和变化量</p>
<p>拉链表：导入每日的变化量。数据第一次导入数仓的时候，会将变化字段放入拉链表，并添加上start和end字段（开链和闭链时间 ）记录变化时间。</p>
<p>主键作用是唯一标志一行</p>
<p> 使用范式的根本目的是：</p>
<p>  1）减少数据冗余，尽量让每个数据只出现一次。</p>
<p>  2）保证数据一致性</p>
<p>三范式：①字段的原子性  ②不存在对主键的部分函数依赖③不存在传递函数依赖</p>
<p>关系模型：完全遵循三范式，没有数据冗余，保证数据一致性，但是大量的join操作消耗性能。</p>
<p>维度模型：部分遵循三范式，数据冗余，但是查询性能高。</p>
<p>纬度建模三种模型：</p>
<pre><code>星型模型：事实表的纬度表没有纬度表，性能更好

雪花模型：事实表的纬度表也有纬度表，更靠近三范式，冗余少

星座模型：多个事实表共用纬度表，多个星型和雪花模型组成的模型
</code></pre>
<p>hadoop checknative：检查hadoop支持的压缩格式</p>
<p>sqoop查看mysql中的数据库：bin&#x2F;sqoop list-databases –connect jdbc:mysql:&#x2F;&#x2F;hadoop102:3306 –username root –password abc123</p>
<pre><code>ods层到dwd层进行建模，从dwd层到dws层进行轻微聚合，得到宽表。ads层进行计算时可以直接从dws层拿数据，减少join。
</code></pre>
<p><img src="/../AppData/Roaming/Typora/typora-user-images/1562855754525.png" alt="1562855754525"></p>
<pre><code>图中的$do_date需要加单引号，因为在sql中所有字符串都需要加引号，$do_date得到的是一个字符串，所以需要加引号。

![捕获2](捕获2.PNG)![捕获1](捕获1.PNG)

而对于函数，不需要加引号。如上两图所示。



建表时tblproperties（“parquet.compression&quot;=&quot;snappy&quot;）可以指定表的数据的压缩格式为snappy。snappy不支持切片，所以每个大于128mb的文件不切片，单个maptask执行，不会并行执行。
</code></pre>
<p>在hive中创建临时表(with 临时表名 as 表，每张表之间用逗号连接)</p>
<pre><code>with

tmp_order as (select ... from ...) ,
tmp_payment as (select ... from ...),
...





问题：ods层进行insert into操作，每次因为运行一个reduce，所以都会新建一个文件。这样会造成大量小文件存在，在maptask的时候，会自动对小文件进行合并；但是namenode会①产生大量索引，造成寻址慢。同时占用namenode的内存空间。②浪费了block的空间 ③每个block与namenode通讯，消耗资源。

解决：每隔一段时间对该表进行全表查询然后再插入回原表，然后将小文件删除，就只剩一个大文件了。
</code></pre>
<p>sqoop导出脚本</p>
<p>#&#x2F;bin&#x2F;bash<br>db&#x3D;’gmall’</p>
<p>export_data(){<br>&#x2F;opt&#x2F;module&#x2F;sqoop-2.5.0&#x2F;bin&#x2F;sqoop export <br>–connect “jdbc:mysql:&#x2F;&#x2F;hadoop102:3306&#x2F;$db?useUnicode&#x3D;true&amp;characterEncoding&#x3D;utf-8”<br>–username root<br>–password abc123<br>–table $1 <br>–num-mapper 1 <br>–export-dir &#x2F;warehouse&#x2F;$db&#x2F;ads&#x2F;$1 <br>–input-fields-terminated-by ‘	‘ <br>–update-mode allowinsert <br>–update-key ‘tm_id,category1_id,stat_mn,stat_date’ <br>–input-null-string ‘\N’<br>–input-null-non-string ‘\N’</p>
<p>}</p>
<pre><code>sqoop导出参数：--update-mode allowinsert/updateonly    允许更新和插入/只允许更新    --update-key   指定更新的字段。

hive中的空值就是&#39;\N&#39;，mysql中空值是null,从mysql中导入null的数据如果不替换，就会以字符串null的形式存储在hive中。

hive中的空数据为&#39;\N&#39;，指定--input-null-string &#39;\\N&#39;    字符串类型的\N的到mysql中转成null。  --input-null-non-string  &#39;\\N&#39;   非字符串类型的\N到mysql中也转成null。

从mysql中导入到hive中时指定  --null-string &#39;\\N&#39;    --null-non-string  &#39;\\N&#39;
</code></pre>
<p>keytool -keystore keystore -list查看生成的密钥库keystore。</p>
<pre><code>1.azkaban的job文件中可以传参，用$&#123;变量名&#125;就可以，在web中可以设置该变量的值；如果不需要该变量，则将该变量值设为空，但是不能不设置，会报错。

2.调用脚本时，需要在前面加上sh或bash，因为用户不同，没有执行权限。



mysql中发生增删改查，操作会记录在mysql的日志文件中。通过监控日志文件获取信息。
</code></pre>
<p><img src="/%E4%B8%A2%E6%95%B0%E6%8D%AE.PNG" alt="丢数据"></p>
<pre><code>left join on ... 不会丢失左表的数据，但是用where过滤会导致丢数据。所以把where的判断条件放到on里面。这样左表和右表只有id相同且结束时间满足条件的情况下才会join，左表的数据全都保存下来。
</code></pre>
<p>下载maven依赖包时出现问题，可以删除*lastupdated.properties文件，重新下载依赖包。</p>
<p>掌握kylin纬度表</p>
<p>掌握kylin的定时调用</p>
<p>mr-jobhistory-daemon.sh start historyserver</p>
<p>curl 是发送http请求的指令。</p>
<p>base 64位加密网上搜加密</p>
<p>hbase是按字典序进行存储，所以kylin查询是可以将？？？ 一般一个regionserver配17G-40G内存</p>
<p>kylin查询的三个方法：通过网页、linux命令和jdbc</p>
<p>kylin进程是runjar</p>
<p>11:20 kylin在hive上构建大宽表？？？</p>
<p>unzip  … -d 路径</p>
<p>hive中comment乱码需要配置字符集</p>
<p>b+树写入较慢，读取快，通过b+树建立索引；LSM通过顺序写提高了写入速度，但是是多个有序小块，读取较慢。可以通过bloom filter和定期合并来提高读取效率。</p>
<p>如果kafka和zk非正常关闭导致zk中有kafka的非正常数据，可以将 zk根目录下的brokers的ids删除。</p>
<pre><code>1.Kylin是分布式引擎，提供了**sql查询**接口，多维分析能力，**亚秒内**查询**超大数据集**的表。2.需要进行**预计算**，有layer和inmem两种计算方式，都是基于mapreduce。如果纬度为n，则有2^n-1个cuboid，构成了一个cube。3.可以从hdfs，hive，kafka和rdbms中查询数据，将cube build engine构建后的key Value Data值放在HBase中存储。然后通过REST Server和Query Engine在将sql语句进行翻译后在hbase中查询。**支持多重查询方式**，可以通过web app/rest api（即http请求），BI Tools（可视化工具）、JDBC/ODBC(java和c语言的驱动接口)和zepplin进行sql查询。4.旧版本的Kylin仅支持文件的预计算，所以无法对流数据进行实时处理（新版本支持流式处理，和druid类似），但是亚秒级的查询速度可以提供实时查询。5.一般仅支持所选维度和度量，直接从hbase中查询结果。6.需要依赖zookeeper，默认使用mapreduce计算，也可以用spark引擎计算。



impala也是自己的基于内存的计算引擎。

1.presto是分布式查询引擎，提供了sql接口，提供秒级查询。2.存在一个coordinator和多个worker，查询任务提交给coordinator，然后分发给worker，每个worker赋值执行任务和处理数据，可以连接不同的数据源（如hive、redis、kafka），**跨数据源联表查询**3.自带计算引擎，**基于内存**计算，加载一部分，计算后再清内存，所以要避免联表查询，可以先聚合成宽表。impala查询性能好，但是数据源单一。4.presto对ORC格式支持较好，impala对parquet支持较好。5.join操作时大表放前面，presto会将大表进行切分到多个worker中，然后broadcast右表到每个worker中进行join；如果两张大表，则采用hashjoin，将较小的表的连接列取哈希值然后通过哈希算法放到bucket中，另一张表通过哈希算法进行外键匹配。所以小表放在左边，减少bucket的内存占用。而hive最好将小表放在左边（hashjoin）；



1.druid是列式，分布式，**实时**分析引擎（对流数据进行实时分析），提供毫秒级查询2.基于预计算，有自己的存储系统。2.延迟为亚秒级，可以查询为预计算的数据，延迟秒级。3.支持流式数据和批量数据查询。可以从kafka中读取流，进行实时查询。4.自愈，自平衡，易操作。4.数据结果采用bitmap压缩算法。基于LSM进行存储，逻辑上是一张时间有序的大表。物理上按时间范围切割成segment数据块（相当于分区），每个数据块中采用bitmap压缩格式压缩（数据纵向切割）。
</code></pre>
<p>druid和hbase都是基于LSM（log struct merge）进行存储的，将每条数据顺序写入，按时间进行排序后，达到一定大小写出到磁盘。然后通过merge每个数据块和bloom filter提高查询效率。</p>
<p>获取redis连接池和客户端（spark项目）：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getJedisClient</span></span>: <span class="type">Jedis</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span>(jedisPool==<span class="literal">null</span>)&#123;</span><br><span class="line"><span class="comment">//      println(&quot;开辟一个连接池&quot;)</span></span><br><span class="line">      <span class="keyword">val</span> config = <span class="type">PropertiesUtil</span>.load(<span class="string">&quot;config.properties&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> host = config.getProperty(<span class="string">&quot;redis.host&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> port = config.getProperty(<span class="string">&quot;redis.port&quot;</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> jedisPoolConfig = <span class="keyword">new</span> <span class="type">JedisPoolConfig</span>()</span><br><span class="line">      jedisPoolConfig.setMaxTotal(<span class="number">100</span>)  <span class="comment">//最大连接数</span></span><br><span class="line">      jedisPoolConfig.setMaxIdle(<span class="number">20</span>)   <span class="comment">//最大空闲</span></span><br><span class="line">      jedisPoolConfig.setMinIdle(<span class="number">20</span>)     <span class="comment">//最小空闲</span></span><br><span class="line">      jedisPoolConfig.setBlockWhenExhausted(<span class="literal">true</span>)  <span class="comment">//忙碌时是否等待</span></span><br><span class="line">      jedisPoolConfig.setMaxWaitMillis(<span class="number">500</span>)<span class="comment">//忙碌时等待时长 毫秒</span></span><br><span class="line">      jedisPoolConfig.setTestOnBorrow(<span class="literal">true</span>) <span class="comment">//每次获得连接的进行测试</span></span><br><span class="line"></span><br><span class="line">      jedisPool=<span class="keyword">new</span> <span class="type">JedisPool</span>(jedisPoolConfig,host,port.toInt)</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//    println(s&quot;jedisPool.getNumActive = $&#123;jedisPool.getNumActive&#125;&quot;)</span></span><br><span class="line"> <span class="comment">//   println(&quot;获得一个连接&quot;)</span></span><br><span class="line">    jedisPool.getResource</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>kafka 0.10版本之后的连接方式：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> kafkaParam = <span class="type">Map</span>(</span><br><span class="line">    <span class="string">&quot;bootstrap.servers&quot;</span> -&gt; broker_list,<span class="comment">//用于初始化链接到集群的地址</span></span><br><span class="line">    <span class="string">&quot;key.deserializer&quot;</span> -&gt; classOf[<span class="type">StringDeserializer</span>],</span><br><span class="line">    <span class="string">&quot;value.deserializer&quot;</span> -&gt; classOf[<span class="type">StringDeserializer</span>],</span><br><span class="line">    <span class="comment">//用于标识这个消费者属于哪个消费团体</span></span><br><span class="line">    <span class="string">&quot;group.id&quot;</span> -&gt; <span class="string">&quot;gmall_consumer_group&quot;</span>,</span><br><span class="line">    <span class="comment">//如果没有初始化偏移量或者当前的偏移量不存在任何服务器上，可以使用这个配置属性</span></span><br><span class="line">    <span class="comment">//可以使用这个配置，latest自动重置偏移量为最新的偏移量</span></span><br><span class="line">    <span class="string">&quot;auto.offset.reset&quot;</span> -&gt; <span class="string">&quot;latest&quot;</span>,</span><br><span class="line">    <span class="comment">//如果是true，则这个消费者的偏移量会在后台自动提交,但是kafka宕机容易丢失数据</span></span><br><span class="line">    <span class="comment">//如果是false，会需要手动维护kafka偏移量</span></span><br><span class="line">    <span class="string">&quot;enable.auto.commit&quot;</span> -&gt; (<span class="literal">true</span>: java.lang.<span class="type">Boolean</span>)</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">dStream：<span class="type">InputDStream</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>,<span class="type">String</span>]] = <span class="type">KafkaUtils</span>.createDirectStream(ssc, <span class="type">LocationStrategies</span>.<span class="type">PreferConsistent</span>,<span class="type">ConsumerStrategies</span>.<span class="type">Subscribe</span>[<span class="type">String</span>,<span class="type">String</span>](<span class="type">Array</span>(topic),kafkaParam))</span><br></pre></td></tr></table></figure>



<p>日期工具：<br>org.apache.commons.lang.time	DateUtils.addDays(date,-1)获取昨天的日期</p>
<p>从resources文件夹中读取properties文件</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">static &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="type">InputStream</span> inputStream = <span class="type">ConfigurationManager</span>.<span class="keyword">class</span>.getClassLoader()</span><br><span class="line">          .getResourceAsStream(<span class="string">&quot;comerce.properties&quot;</span>);</span><br><span class="line">      prop.load(inputStream);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (<span class="type">Exception</span> e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>



<p>创建druid连接池</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">public static <span class="type">DataSource</span> dataSource = <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">    static &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">Properties</span> props = <span class="keyword">new</span> <span class="type">Properties</span>();</span><br><span class="line">            props.setProperty(<span class="string">&quot;url&quot;</span>, <span class="type">ConfigurationManager</span>.getProperty(<span class="string">&quot;jdbc.url&quot;</span>));</span><br><span class="line">            props.setProperty(<span class="string">&quot;username&quot;</span>, <span class="type">ConfigurationManager</span>.getProperty(<span class="string">&quot;jdbc.user&quot;</span>));</span><br><span class="line">            props.setProperty(<span class="string">&quot;password&quot;</span>, <span class="type">ConfigurationManager</span>.getProperty(<span class="string">&quot;jdbc.password&quot;</span>));</span><br><span class="line">            props.setProperty(<span class="string">&quot;initialSize&quot;</span>, <span class="string">&quot;5&quot;</span>); <span class="comment">//初始化大小</span></span><br><span class="line">            props.setProperty(<span class="string">&quot;maxActive&quot;</span>, <span class="string">&quot;10&quot;</span>); <span class="comment">//最大连接</span></span><br><span class="line">            props.setProperty(<span class="string">&quot;minIdle&quot;</span>, <span class="string">&quot;5&quot;</span>);  <span class="comment">//最小连接</span></span><br><span class="line">            props.setProperty(<span class="string">&quot;maxWait&quot;</span>, <span class="string">&quot;60000&quot;</span>); <span class="comment">//等待时长</span></span><br><span class="line">            props.setProperty(<span class="string">&quot;timeBetweenEvictionRunsMillis&quot;</span>, <span class="string">&quot;2000&quot;</span>);<span class="comment">//配置多久进行一次检测,检测需要关闭的连接 单位毫秒</span></span><br><span class="line">            props.setProperty(<span class="string">&quot;minEvictableIdleTimeMillis&quot;</span>, <span class="string">&quot;600000&quot;</span>);<span class="comment">//配置连接在连接池中最小生存时间 单位毫秒</span></span><br><span class="line">            props.setProperty(<span class="string">&quot;maxEvictableIdleTimeMillis&quot;</span>, <span class="string">&quot;900000&quot;</span>); <span class="comment">//配置连接在连接池中最大生存时间 单位毫秒</span></span><br><span class="line">            props.setProperty(<span class="string">&quot;validationQuery&quot;</span>, <span class="string">&quot;select 1&quot;</span>);</span><br><span class="line">            props.setProperty(<span class="string">&quot;testWhileIdle&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">            props.setProperty(<span class="string">&quot;testOnBorrow&quot;</span>, <span class="string">&quot;false&quot;</span>);</span><br><span class="line">            props.setProperty(<span class="string">&quot;testOnReturn&quot;</span>, <span class="string">&quot;false&quot;</span>);</span><br><span class="line">            props.setProperty(<span class="string">&quot;keepAlive&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">            props.setProperty(<span class="string">&quot;phyMaxUseCount&quot;</span>, <span class="string">&quot;100000&quot;</span>);</span><br><span class="line"><span class="comment">//            props.setProperty(&quot;driverClassName&quot;, &quot;com.mysql.jdbc.Driver&quot;);</span></span><br><span class="line">            dataSource = <span class="type">DruidDataSourceFactory</span>.createDataSource(props);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (<span class="type">Exception</span> e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>



<p>从本地文件中读取内容：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> source: <span class="type">BufferedSource</span> = io.<span class="type">Source</span>.fromFile(<span class="string">&quot;D:\MyWork\UserBehaviorAnalyze\HotItemsAnalysis\src\main\resources\UserBehavior.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> lineItr: <span class="type">Iterator</span>[<span class="type">String</span>] = source.getLines()</span><br></pre></td></tr></table></figure>





<p>从Kafka中读取数据</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">SparkStreaming</span>：</span><br><span class="line">    <span class="keyword">val</span> inputDS: <span class="type">InputDStream</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]] = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>](ssc, <span class="type">LocationStrategies</span>.<span class="type">PreferConsistent</span>, <span class="type">ConsumerStrategies</span>.<span class="type">Subscribe</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="type">Array</span>(topic), kafkaParam))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">Flink</span>：</span><br><span class="line"><span class="keyword">val</span> dataStream: <span class="type">DataStream</span>[<span class="type">String</span>] = env.addSource(<span class="keyword">new</span> <span class="type">FlinkKafkaConsumer</span>[<span class="type">String</span>](<span class="string">&quot;kafka1&quot;</span>,<span class="keyword">new</span> <span class="type">SimpleStringSchema</span>(),prop))</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">CJ</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%97%B6/%E9%A1%B9%E7%9B%AE%E7%9F%A5%E8%AF%86%E7%AC%94%E8%AE%B0/">http://example.com/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%97%B6/%E9%A1%B9%E7%9B%AE%E7%9F%A5%E8%AF%86%E7%AC%94%E8%AE%B0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Hexo</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%97%B6/%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/" title="遇到的问题"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">遇到的问题</div></div></a></div><div class="next-post pull-right"><a href="/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%97%B6/Spark/" title="Spark"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Spark</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">CJ</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">419</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">38</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/MySQL/%E6%B3%A8%E8%A7%A3@Select%E5%92%8C@Insert/" title="注解@Select和@Insert">注解@Select和@Insert</a><time datetime="2023-05-06T05:48:28.906Z" title="发表于 2023-05-06 13:48:28">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E5%90%8E%E7%AB%AF%E6%A1%86%E6%9E%B6/%E6%B3%A8%E8%A7%A3@EnableAutoConfiguration/" title="注解@EnableAutoConfiguration">注解@EnableAutoConfiguration</a><time datetime="2023-05-06T05:48:06.027Z" title="发表于 2023-05-06 13:48:06">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A6%BB%E7%BA%BF/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7%E6%A1%86%E6%9E%B6/" title="大数据集群监控框架">大数据集群监控框架</a><time datetime="2023-05-06T05:42:56.298Z" title="发表于 2023-05-06 13:42:56">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E9%AB%98%E5%B9%B6%E5%8F%91/HashMap%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98%E5%8F%8AConcurrentHashMap%E5%8E%9F%E7%90%86/" title="HashMap并发问题及ConcurrentHashMap原理">HashMap并发问题及ConcurrentHashMap原理</a><time datetime="2023-05-06T05:31:21.103Z" title="发表于 2023-05-06 13:31:21">2023-05-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/06/%E9%AB%98%E5%B9%B6%E5%8F%91/Stream%E5%8E%9F%E7%90%86/" title="Stream原理">Stream原理</a><time datetime="2023-05-06T05:31:21.103Z" title="发表于 2023-05-06 13:31:21">2023-05-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By CJ</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>